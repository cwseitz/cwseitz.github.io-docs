<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on </title>
        <link>/posts/</link>
        <description>Recent content in Posts on </description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
        <lastBuildDate>Tue, 17 Nov 2020 00:00:00 +0000</lastBuildDate>
        <atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Analog impulse response</title>
            <link>/posts/analog-impulse-response/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/analog-impulse-response/</guid>
            <description>When designing electrical circuits that process input signals, we are always concerned with obtaining an output that suits the purpose of the circuit. In the time domain, we are usually interested in voltage at the output as a function of time. In the frequency domain, we are concerned with the frequency response or transfer function of the circuit.
There are cases where you can write down differential equations for the circuit in the time domain and solve those equations to find the output of your circuit.</description>
            <content type="html"><![CDATA[<p>When designing electrical circuits that process input signals, we are always concerned with obtaining an output that suits the purpose of the circuit. In the time domain, we are usually interested in voltage at the output as a function of time. In the frequency domain, we are concerned with the frequency response or transfer function of the circuit.</p>
<!-- raw HTML omitted -->
<p>There are cases where you can write down differential equations for the circuit in the time domain and solve those equations to find the output of your circuit. However, perhaps a more useful approach is to find the <em>impulse reponse</em> of the system first. The impulse response is the voltage at the output when the input is an impulse or delta function with known amplitude. Once the impulse response $h(t)$ is known, we can convolve the input in the time domain with the impulse function to obtain the output.</p>
<p>\begin{align}
V_{out} = \int h(t)V_{in}dt
\end{align}</p>
<p>Another interesting property of the impulse response is that its fourier transform is the frequency reponse of the system i.e. the transfer function.</p>
<p>\begin{align}
H(\omega) = \mathcal{F}[h(t)]
\end{align}</p>
<p>This property can be very useful if we already know the impulse response and would like to find the transfer function. Ultimately, if we know the impulse response we know pretty much everything we need to know - practically speaking. Let&rsquo;s begin with an RC circuit. If we are probing the RC circuit&rsquo;s capcitor, then the general prescription begins with writing down KVL and KCL:</p>
<p>\begin{align}
V_{in} = IR + \frac{Q}{C}
\end{align}</p>
<p>\begin{align}
I = C\frac{dV_{out}}{dt}
\end{align}</p>
<p>which can be combined to give</p>
<p>\begin{align}
V_{in} = \tau\frac{dV_{out}}{dt} + V_{out}
\end{align}</p>
<p>You can solve this equation by first finding the homogeneous solution when $V_{in} = 0$.</p>
<p>\begin{align}
\tau\frac{dV_{out}}{dt} = - V_{out}
\end{align}</p>
<p>\begin{align}
V_{out} = A(t)e^{\frac{-t}{\tau}}
\end{align}</p>
<p>Plugging that back into our original differential equation we have:</p>
<p>\begin{align}
V_{in} = \tau[A&rsquo;(t)e^{\frac{-t}{\tau}} - \frac{A(t)}{\tau}e^{\frac{-t}{\tau}}]  + A(t)e^{\frac{-t}{\tau}} = \tau A&rsquo;(t)e^{\frac{-t}{\tau}}
\end{align}</p>
<p>At this point, we have to specify our input to move forward. If our input is an impulse, we substitute a delta function $\delta(0)$ for $V_{in}$:</p>
<p>\begin{align}
A(t) = \frac{1}{\tau}\int \delta(0)e^\frac{t}{\tau}dt = \frac{1}{\tau}
\end{align}</p>
<p>\begin{align}
h(t) = \frac{1}{\tau}e^{\frac{-t}{\tau}}
\end{align}</p>
<p>From a previous post on RC frequency response, we already know that the transfer function is:</p>
<p>\begin{align}
H(\omega) = \frac{1}{1 + i\omega RC}
\end{align}</p>
<p>Which we should be able to verify by taking the fourier transform of the impulse response:</p>
<p>\begin{align}
\mathcal{F}[h(t)] = \frac{1}{\tau}\int_{-\infty}^{\infty}e^{-t(i\omega + 1/\tau)}dt = \frac{1}{-(1 + i\omega\tau)}
\end{align}</p>
<p>which only differs by a phase from our original solution. Another route to finding the impulse response would involve taking the inverse fourier transform of the previously found transfer function. This path is rocky however, the integral faced usually requires a table lookup of some kind.</p>
]]></content>
        </item>
        
        <item>
            <title>Attention is all you need</title>
            <link>/posts/attention-is-all-you-need/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/attention-is-all-you-need/</guid>
            <description>Sequence to sequence learning One method developed by Sutskever et al in 2015 is a sequence to sequence (seq2seq) method for machine translation. As will all seq2seq translation tasks, we want to estimate distribution over the output sequence given the input sequence
\begin{eqnarray} P_{\Phi}(w_{1},..,w_{T_{in}}|w_{1},..,w_{T_{in}}) \end{eqnarray}
We usually estimate this probability distribution by using autoregression which is realized with a RNN
\begin{eqnarray} P_{\Phi}(w_{1},..,w_{T_{in}}|w_{1},..,w_{T_{in}}) = \Pi_{t=0}^{T} P_{\Phi}(w_{t}|\overset\leftarrow{h_{in}}[1,J],w_{0}&amp;hellip;w_{t-1}) \end{eqnarray}
Notice there is an unfamiliar term $\overset\leftarrow{h_{in}}[1,J]$ we are conditioning on.</description>
            <content type="html"><![CDATA[<h3 id="sequence-to-sequence-learning">Sequence to sequence learning</h3>
<p>One method developed by Sutskever et al in 2015 is a sequence to sequence (seq2seq) method for machine translation. As will all seq2seq translation tasks, we want to estimate distribution over the output sequence given the input sequence</p>
<p>\begin{eqnarray}
P_{\Phi}(w_{1},..,w_{T_{in}}|w_{1},..,w_{T_{in}})
\end{eqnarray}</p>
<p>We usually estimate this probability distribution by using autoregression which is realized with a RNN</p>
<p>\begin{eqnarray}
P_{\Phi}(w_{1},..,w_{T_{in}}|w_{1},..,w_{T_{in}}) = \Pi_{t=0}^{T} P_{\Phi}(w_{t}|\overset\leftarrow{h_{in}}[1,J],w_{0}&hellip;w_{t-1})
\end{eqnarray}</p>
<p>Notice there is an unfamiliar term $\overset\leftarrow{h_{in}}[1,J]$ we are conditioning on. This brings us to the **encoder**.</p>
<h4 id="the-encoder">The encoder</h4>
<p>Before we can compute the distribution above via autoregression, we encode the sentence into a <strong>thought-vector</strong>. The thought-vector is a vector of numbers meant to represent the meaning of a sequence of words. We assume that it is possible to encode the essence of a sentence - something that is invariant from language to language.</p>
<p>For this architecture, the thought vector representation is computed right-to-left or the last word comes first in the thought vector. As you can see in the equation above we typically represent such a thought vector as $\overset\leftarrow{h_{in}}[1,J]$ and it is the final hidden state in our encoding network.</p>
<h4 id="computing-probabilties">Computing probabilties</h4>
<p>Now that we have established what the thought-vector is and its role, we can move on to actually doing the autoregression. As mentioned above, the autoregression is implemented as an RNN from which we read out probabilities $ P_{\Phi}(w_{t}|\overset\leftarrow{h_{in}}[1,J],w_{0}&hellip;w_{t-1})$ according to</p>
<p>\begin{equation*}
\DeclareMathOperator*{\softmax}{softmax}
P(w_{t_{out}}|\overset\leftarrow{h_{in}}[1,J], w_{1},..,w_{t_{out}-1}) = \underset{w_{t_{out}}}{\softmax} e[w_{t_{out}},J]h_{out}[t_{out}-1,J]
\end{equation*}</p>
<p>where $e$ is the encoding for a particular word and $h$ is the hidden state at that point in the network.</p>
<h4 id="the-decoder">The decoder</h4>
<p>For each element of the sequence, we now have a probability distribution over the possible output words. The output sequence we get depends on how we utilize these probabilities for decoding. One way is called the <strong>greedy-decoder</strong> which is an autoregression conditioned on the thought-vector that selects each word $w_{t}$ in the translation that has the maximum probability.</p>
<p>\begin{eqnarray}
\DeclareMathOperator*{\argmax}{argmax}
w_{t} = \underset{w_{t}}{\argmax}P(w_{t}|\overset\leftarrow{h_{in}}[1,J], w_{1},..,w_{t-1})
\end{eqnarray}</p>
<p>This is distinct from a decoder that would find the sentence with a <em>globally</em> maximum probability.</p>
<h3 id="learning-to-align-and-translate">Learning to align and translate</h3>
<p>In another method, the model above is modified such that the output sequences are <em>aligned</em> with input sequences by a form of <strong>attention</strong>. In the context of alignment, the attention computes the strength of the connection between a word in the output $w_{t_{out}}$ and a word in the input $w_{t_{in}}$. This is especially useful because order is not always preserved from language to language.</p>
<h4 id="the-encoder-1">The encoder</h4>
<p>The model bares similarity in its structure to the one presented above except that the encoder is changed to a bi-directional RNN. In a bi-directional RNN, we run the network left-to-right and right-to-left and concatenate the hidden vectors produced at every $t$ to produce $\overset\leftrightarrow{h_{in}}[t_{in},J]$.</p>
<p>Then, we begin the autoregression by concatenating $\overset\rightarrow{h_{in}}[T_{in},J/2]$ and $\overset\leftarrow{h_{in}}[0,J/2]$ to produce $\overset\rightarrow{h_{in}}[t_{in},J]$ which is fed into the left-to-right RNN similar to the previous model</p>
<h4 id="the-decoder-1">The decoder</h4>
<p>The decoder is where the main differences are because we need a way to implement an attention mechanism that facilitates alignment of the input and output sequence. But first, I will write the general procedure executed by the decoding RNN</p>
<p>\begin{eqnarray}
\DeclareMathOperator*{\RNN}{RNN}
\overset\rightarrow{h_{out}}[t_{out},J] = \RNN(\overset\rightarrow{h_{out}}[t_{out},J], e[w_{t_{out}},I], \color{red}{\hat{h}_{in}[t_{out},J]})
\end{eqnarray}</p>
<p>where $\hat{h}<em>{in}[t</em>{out},J]$ is added to provide information for the alignment. To get that information, we construct the following $\alpha$</p>
<p>\begin{eqnarray}
\DeclareMathOperator*{\softmax}{softmax}
\alpha[t_{in},t_{out}] = \underset{w_{t_{in}}}{\softmax} e[w_{t_{out}},J]\overset\leftrightarrow{h_{in}}[t_{in},J]
\end{eqnarray}</p>
<p>In words, we compute the softmax of the inner product of the embedding of the word we most recently produced $w_{t_{out}}$ and the encoding at all input positions. In effect, this gives us a probability distribution over input positions for each word that we produce at $t_{out}$. Basically that tells us where to look in the input when generating $w_{t_{out}}$.</p>
<p>We then multiply each slice $t_{out}$ of the association matrix with the entire matrix $\overset\leftrightarrow{h_{in}}[T_{in},J]$ from the encoder step to give us a new matrix $\hat{h}_{in}[T_{out},J]$. This is done for every $t_{out}$ giving us the relevant parts of the encoder to produce  $w_{t_{out}}$.</p>
<p>\begin{eqnarray}
\color{red}{\hat{h}<em>{in}[t</em>{out},J]} = \alpha[t_{out},T_{in}]\overset\leftrightarrow{h_{in}}[T_{in},J]
\end{eqnarray}</p>
<h3 id="attention-is-all-you-need">Attention is all you need</h3>
<p>In the paper <em>Attention is all you need</em> published by researchers at Google Brain in 2017, a new architecture called the <strong>transformer</strong> was developed based on this idea of attention. This architecture outperforms LSTMs, recurrent networks, and gated recurrent networks. The primary pitfall of these methods is that they rely on sequential computation lacking any form of a parallelization. On the other hand, the transformer completely scraps the recurrence, relying on attention alone, and allowing for parallelization and improved computation time.</p>
<h3 id="transformer-heads--self-attention">Transformer heads &amp; self-attention</h3>
<p>For each position $t$ or position in the sentence, we construct an <strong>attention</strong> between that position and the other positions in the sentence. You can think of this as a weighted graph between the positions in the sentence. We store this information in the tensor $\alpha[k,t_{1},t_{2}]$ - which contains the weight of attention from words $t_{1}$ to $t_{2}$ with **head label** $k$. The head is just a label that describes their relationship.</p>
<h3 id="the-encoder-2">The encoder</h3>
<p>Each layer in the transformer has the same shape $L[T,J]$ which contains a time index which could be a particular word in a sentence and for each word we have the vector $L[t,J]$. It is pretty efficient on a modern machine because the transfomer can compute layer $L_{l+1}[T,J]$ from $L_{l}[T,J]$ in $O(\ln(TI))$ time by using a tree of additions.</p>
<h3 id="the-decoder-2">The decoder</h3>
<p>Each layer in the transformer has the same shape $L[T,J]$ which contains a time index which could be a particular word in a sentence and for each word we have the vector $L[t,J]$. It is pretty efficient on a modern machine because the transfomer can compute layer $L_{l+1}[T,J]$ from $L_{l}[T,J]$ in $O(\ln(TI))$ time by using a tree of additions.</p>
<h3 id="query-key-attention">Query-key attention</h3>
<p>With query-key attention, for each of our words $t$ and each of its heads $k$, we compute</p>
<p>\begin{eqnarray}
\DeclareMathOperator*{\Query}{Query}
\DeclareMathOperator*{\Key}{Key}
\Query_{l+1}[k,t,i] &amp;=&amp; W_{\mathcal{l}+1}^{Q}[k,i,J]L_{l}[t,J] \<br>
\Key_{l+1}[k,t,i] &amp;=&amp; W_{l+1}^{K}[k,i,J]L_{l}[t,J] \<br>
\end{eqnarray}</p>
]]></content>
        </item>
        
        <item>
            <title>Backpropagation</title>
            <link>/posts/deep-learning-backprop/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/deep-learning-backprop/</guid>
            <description>A deep learning framework is a high-level interface that allows the user to define a model $\Phi$. That model produces an output for a given input according to it&amp;rsquo;s mathematical definition. It is the job of the framework to to optimize the model by minimizing a particular loss function $\mathcal{L}$.
\begin{equation*} \DeclareMathOperator*{\argmin}{argmin} \Phi^{*} = \underset{\Phi}{\argmin} E_{(x,y)}\mathcal{L(x,y)} \end{equation*}
The are many deep learning frameworks in use today such as Tensorflow (Google), PyTorch (Facebook, Academics), Microsoft Cognitive Toolkit, Chainer, etc.</description>
            <content type="html"><![CDATA[<p>A deep learning framework is a high-level interface that allows the user to define a model $\Phi$. That model produces an output for a given input according to it&rsquo;s mathematical definition. It is the job of the framework to to optimize the model by minimizing a particular loss function $\mathcal{L}$.</p>
<p>\begin{equation*}
\DeclareMathOperator*{\argmin}{argmin}
\Phi^{*} = \underset{\Phi}{\argmin} E_{(x,y)}\mathcal{L(x,y)}
\end{equation*}</p>
<p>The are many deep learning frameworks in use today such as Tensorflow (Google), PyTorch (Facebook, Academics), Microsoft Cognitive Toolkit, Chainer, etc. Rather than jump straight into using one of these frameworks, we can learn a lot about how they work by building a stripped down version ourselves. In the end, we want to use that framework to make predictions on the classic MNIST dataset of handwritten digits. We will build a multi-layer perceptron (MLP) to do that.</p>
<h3 id="multi-layer-perceptron-mlp">Multi-layer perceptron (MLP)</h3>
<p>The MLP is defined by the following equations</p>
<p>\begin{equation*}
\DeclareMathOperator*{\softmax}{softmax}
h = \sigma(W^{0}x - b^{0}) \<br>
s = \sigma(W^{1}h - b^{1}) \<br>
P_{\Phi}[\hat{y}] = \underset{\hat{y}}{\softmax s[\hat{y}]}
\end{equation*}</p>
<p>This is a MLP with two layers. The first layer takes an input vector $x$ and multiples it by a matrix $W^{0}$ and subtracts a <em>threshold</em> vector $b^{0}$. The result is the argument of our activation function $\sigma$ which, in this case, is a sigmoid function. The sigmoid acts on each of the vector individually. The same operation happens at the second layer except that the input is the output of the first layer and we use a different matrix and bias vector. Sometimes this sequence is referred to as a <strong>computational graph</strong>. Anyway, the softmax function then maps the output scores to probabilities.</p>
<p>If our framework is any good, it will minimize the loss $\mathcal{L}$ by gradient descent. This entails computing $\nabla\mathcal{L}$ with respect to the model $\Phi = (W^{0},b^{0},W^{1},b^{1})$. To be specific, deep learning frameworks use stochastic gradient descent to minimize the loss function. However, I am going to ignore those deatils and focus mainly on the algorithm that actually finds $\Phi^{*}$: backpropagation.</p>
<h3 id="backpropagation">Backpropagation</h3>
<p>Backpropagation is the process that frameworks use to minimize loss, that is approximate $\nabla\mathcal{L} = 0$. We will see the backpropagation is actually pretty simple and is ultimately just a exercise in using the chain rule.</p>
<h3 id="scalar-loss">Scalar loss</h3>
<p>Typically our inputs and outputs in a network are vectors but backpropagation is easier to understand if we start by using scalar functions. Since they are only scalars, the computational graph is nothing but a sequence of multiplications and additions. But first, let&rsquo;s address how we calculate the loss. In general, our loss function is some arbitrary composite function of the input and output pair $(x,y)$.</p>
<p>\begin{eqnarray}
y &amp;=&amp; f(x) \<br>
z &amp;=&amp; g(x,y) \<br>
u &amp;=&amp; h(z) \<br>
\mathcal{L} &amp;=&amp; u
\end{eqnarray}</p>
<p>but notice the first line where $y = f(x)$. When computing the loss we have to remember that the output is some function of the input. If you wanted to use the chain rule to calculate the gradient of $\mathcal{L}$, you would use</p>
<p>\begin{equation*}
\frac{\partial \mathcal{L}}{\partial x} = \frac{\partial \mathcal{L}}{\partial u}\frac{\partial u}{\partial z}(\frac{\partial z}{\partial x} +\frac{\partial z}{\partial y}\frac{\partial y}{\partial x})
\end{equation*}</p>
<p>The backprop algorithm just computes this value.</p>
<h3 id="tensor-inputs">Tensor inputs</h3>
<p>Returning to the definition of our MLP</p>
<p>\begin{equation*}
s = \sigma(Wh - B)
\end{equation*}</p>
<p>we want to now consider the case where the $h$ and threshold $b$ are vectors. Of course, this requires that $W$ be a matrix and we need to determine how to perform backpropagation on that matrix. That is to say we need to figure how to compute gradient $\nabla_{W}\mathcal{L}$. To see how this is done, we first define $\hat{s} = Wh$ so we are just considering subtraction of two vectors before piping it through the non-linearity $s = \sigma(\hat{s} - B)$. As in the scalar case, we can compute the gradient of the loss w.r.t a function of the input and use the chain rule to determine the gradient w.r.t the input itself. We can easily measure $\partial_{s}\mathcal{L}$ and it&rsquo;s then straightforward to calculate $\partial_{\hat{s}}\mathcal{L}$ and $\partial_{B}\mathcal{L}$.</p>
<p>\begin{equation*}
\frac{\partial\mathcal{L}}{\partial \hat{s}_{j}} = \frac{\partial\mathcal{L}}{\partial s_{j}}\frac{\partial s_{j}}{\partial \hat{s}_{j}} = \frac{\partial\mathcal{L}}{\partial s_{j}}\frac{\partial}{\partial \hat{s}_{j}} \sigma(\hat{s}_{j} - B_{j})
\end{equation*}</p>
<p>\begin{equation*}
\frac{\partial\mathcal{L}}{\partial B_{j}} = \frac{\partial\mathcal{L}}{\partial s_{j}}\frac{\partial s_{j}}{\partial B_{j}} = \frac{\partial\mathcal{L}}{\partial s_{j}}\frac{\partial}{\partial B_{j}} \sigma(\hat{s}_{j} - B_{j})
\end{equation*}</p>
<p>Notice that we have indexed these vectors indicating that we are backpropagating on elements of the vectors (scalar values).
Moving forward, let&rsquo;s continue the chain and calculate $\partial_{W}\mathcal{L}$ and $\partial_{h}\mathcal{L}$.</p>
<p>\begin{equation*}
\frac{\partial\mathcal{L}}{\partial W_{i,j}} = \frac{\partial\mathcal{L}}{\partial \hat{s}_{j}}\frac{\partial\hat{s}_{j}}{\partial W_{i,j}} = \frac{\partial\mathcal{L}}{\partial \hat{s}_{j}}h_{j}
\end{equation*}</p>
<p>\begin{equation*}
\frac{\partial\mathcal{L}}{\partial h_{j}} = \frac{\partial\mathcal{L}}{\partial \hat{s}_{j}}\frac{\partial\hat{s}_{j}}{\partial h_{j}} = \frac{\partial\mathcal{L}}{\partial \hat{s}_{j}}W_{i,j}
\end{equation*}</p>
<p>Again, we can&rsquo;t actually calculate this on a vector or a matrix. The actual calculations are made by looping over the vector and matrices according to standard matrix multiplication.</p>
]]></content>
        </item>
        
        <item>
            <title>Basic information theory</title>
            <link>/posts/information-theory-basics/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/information-theory-basics/</guid>
            <description>Information theory Information entropy is an information theoretic concept introduced by Claude Shannon in a paper titled A mathematical theory of communication published in 1948. At it&amp;rsquo;s core, information entropy tells us how much information is contained in the distribution of a variable. Bits are chosen as the unit of measure because information theory was originally devised to describe the novel communication systems of the mid 20th century: digital systems.</description>
            <content type="html"><![CDATA[<h2 id="information-theory">Information theory</h2>
<p>Information entropy is an information theoretic concept introduced by Claude Shannon in a paper titled <em>A mathematical theory of communication</em> published in 1948. At it&rsquo;s core, information entropy tells us how much information is contained in the distribution of a variable. Bits are chosen as the unit of measure because information theory was originally devised to describe the novel communication systems of the mid 20th century: digital systems.</p>
<h3 id="entropy">Entropy</h3>
<p>Similar to statistical mechanics, information entropy $\mathbf{H}$ is a measure of uncertainty. In information theory, it is the average number of bits it takes to encode all possible states of the &ldquo;system&rdquo; $\chi$ given some probability distribution over those states $P(x)$. An example provides the quickest route to intuition so here is the definition straight away</p>
<p>\begin{equation*}
\textbf{H} = -\sum_{x\in \chi} P(x)\log_{2} P(x)
\end{equation*}</p>
<p>Note that you can use a $\log$ with whatever base you like as long as the units are noted. I use units of bits because this is intuitive but you can equivalently use a natural logarithm and units of &lsquo;nats&rsquo;.</p>
<pre><code class="language-code" data-lang="code">import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches

p = np.linspace(1e-3, 1, 100)
y1 = -np.log2(p)
y2 = p*y1

fig, ax1 = plt.subplots()
ax1.set_xlabel('p')
ax1.set_ylabel('log2 p [bits]', color='red')
ax1.plot(p, y1, color='red')

ax2 = ax1.twinx()
color = 'tab:blue'
ax2.set_ylabel('plog2p [bits]', color='blue')
ax2.plot(p, y2, color='blue')

fig.tight_layout()
plt.show()
</code></pre><p><img src="information-theory-basics_files/information-theory-basics_2_0.png" alt="png"></p>
<p>The plot in blue shows the contribution to the entropy in bits for a particular value of $p$. The total entropy is then found by sampling the blue curve according to the particular distribution $p(x)$ and adding up the samples.</p>
<h3 id="an-example">An example</h3>
<p>Consider a horse race where the horses are equally likely to win. For the sake of generality let&rsquo;s assume there are $N$ horses and we want to send someone a binary string that tells them which horse won the race. The entropy is</p>
<p>\begin{equation*}
\textbf{H} = \log_{2}N
\end{equation*}</p>
<p>So, in general, it will take you $\log_{2}N$ bits to describe the winner. For two horses, you only need one bit, for three horses, you need ~1.6 bits and so on. Notice that the calculation simplied significantly under the assumption that $P(x)$ was uniform or *flat*. You might guess that a uniform distribution provides the highest entropy, and you would be correct. Also, from an optimization perspective, the entropy defines a lower bound on the number of bits we need to describe $\chi$. You simply can&rsquo;t do better.</p>
<p>Typically things are not this simple and you have to compute $\textbf{H}$ for a more complicated distribution. To deal with that more general case, it helps to realize that the space of states $\chi$ is fixed for a given scenario. Our job is to best approximate the distribution on that space (which is not always easy apriori). For a given $\chi$, <strong>the distribution P(x) is what determines the entropy</strong>. To illustrate, consider another case where $P(x)$ is a delta function at $x_{0}$. Plugging that in to the definition above will yield $\textbf{H} = 0$ meaning there is no uncertainty in $x$ at all.</p>
<h3 id="cross-entropy-and-kl-divergence">Cross-Entropy and KL-Divergence</h3>
<p>Above we discussed that the entropy lies somewhere between zero and the entropy of a uniform distribution. There is another interesting measure in information theory referred to as the <em>cross-entropy</em>. The cross-entropy is a measure of the degree of similarity between two distributions of the same variable $P(x)$ and $Q(x)$.</p>
<p>\begin{equation*}
\textbf{H}(P,Q) = -\sum P\log_{2} Q
\end{equation*}</p>
<p>Notice that if the distributions are the same, then the cross-entropy is equivalent to the entropy. The cross-entropy also has an optimization interpretation. Let&rsquo;s say we know the entropy of a &ldquo;good&rdquo; distribution $P(x)$. Then we have another $Q(x)$ for which the entropy is higher. If we can in such a way transform $Q(x)$ to look like $P(x)$, we have optimized it. In other words, as $Q$ deviates from $P$, the cross-entropy becomes greater than the entropy. This leads us to the definition of KL-divergence:</p>
<p>\begin{equation*}
\textbf{KL}(P,Q) = \textbf{H}(P,Q) - \textbf{H}(P) \geq 0
\end{equation*}</p>
<p>Using the original definition of entropy gives us another very useful form:</p>
<p>\begin{equation*}
\textbf{KL}(P,Q) = -\sum P(x)\ln \frac{P(x)}{Q(x)}
\end{equation*}</p>
<p>The KL-Divergence is simply the difference between the cross-entropy and the entropy. As our predicted distribution gets closer to the actual distribution, the KL-Divergence tends to zero. Eventually, we will use these tools to understand a very common loss function in deep learning: cross-entropy loss.</p>
<h3 id="unmeasurability-of-kl-divergence">Unmeasurability of KL-Divergence</h3>
<p>The definition of KL-divergence indicates that that in order to minimize it, we need to minimize the cross-entropy. That is a single $\Phi$ will minimize both measures.</p>
<p>\begin{equation*}
\DeclareMathOperator*{\argmin}{argmin}
\Phi^{*} = \underset{\Phi}{\argmin} H(P, Q_{\Phi}) = \underset{\Phi}{\argmin} KL(P, Q_{\Phi})
\end{equation*}</p>
<p>which must be true because $H(P)$ is not dependent on $\Phi$.</p>
<p>\begin{equation*}
\DeclareMathOperator*{\argmin}{argmin}
\Phi^{*} = \underset{\Phi}{\argmin} H(P, Q_{\Phi})
\Phi^{*} = \underset{\Phi}{\argmin} H(Q_{\Phi}, P)
\end{equation*}</p>
<p>At the same time, we cannot actually measure the KL-divergence because we can&rsquo;t actually measure $H(P)$.</p>
<h3 id="asymmetry-of-kl-divergence-and-cross-entropy">Asymmetry of KL-divergence and cross-entropy</h3>
<p>There are two possible arrangements when computing cross-entropy or KL-divergence. The first is where we are tuning the distribution that defines the number of bits assigned to each $x$. The second is where we are tuning the distribution that assigns weights to each number of bits.</p>
<p>\begin{eqnarray}
\Phi^{*} &amp;=&amp; \underset{\Phi}{\argmin} H(P, Q_{\Phi})\<br>
\end{eqnarray}</p>
<p>In the first scenario, you tune $Q_{\Phi}$ until it covers all the support of $P$. In the second scenario, tuning $P_{\Phi}$ to minimize $H(P_{\Phi},Q)$ will result in all mass on the $x$ that maximizes $Q$. This can be shown as follows</p>
<p>\begin{eqnarray}
\Phi^{*} &amp;=&amp; \underset{\Phi}{\argmin} H(P_{\Phi}, Q)
\end{eqnarray}</p>
<p>Consider the case where $P = \delta(x-x^{<em>})$ where $x^{</em>}$ maximizes $Q$.</p>
<p>\begin{eqnarray}
P(y^{<em>}) &amp;\leq&amp; P(y) \<br>
\ln P(y^{</em>}) &amp;\leq&amp; \ln P(y) \<br>
Q\ln P(y^{<em>}) &amp;\leq&amp; Q\ln P(y) \<br>
H(P^{</em>}, Q) &amp;\leq&amp; H(P, Q) \<br>
\end{eqnarray}</p>
<p>So this minimization operation is sensitive to whether you are tuning the $P(x)$ term or the $Q(x)$ term in the original definition of cross-entropy. This has another very important implication. It shows us that the $Q$ term in $H(P,Q)$ will be the minimizer for the KL-divergence. The KL-divergence was an average over terms like $\frac{P(x)}{Q(x)}$ so if we tried to minimize by tuning $P$, we would end up with a single non-zero term $\frac{1}{Q(x^{*})}$.</p>
<h3 id="shannons-measures-of-information">Shannon&rsquo;s measures of information</h3>
<p>Shannon developed four basic measures of information: entropy, joint entropy, conditional entropy and mutual information. We can visualize these in a venn-diagram format. For two related variables $x$ and $y$, each has its own entropy $H(x)$ and $H(y)$ with their union being the join entropy $H(x,y)$. Then, we have the conditional entropies $H(x|y)$ and $H(y|x)$ being the regions that exclude the intersection. Finally the mutual information is the intersecting region $I(x,y)$.</p>
<!-- raw HTML omitted -->
<h3 id="joint-and-conditional-entropy">Joint and conditional entropy</h3>
<p>In the diagram above, we saw that the joint entropy was equal to the entropy of one variable plus the conditional entropy of another given that first variable. Let&rsquo;s prove the following relationship between the joint and conditional entropy $\textbf{H}(x,y) = H(x) + H(y|x)$</p>
<p>\begin{eqnarray}
\textbf{H}(x,y) &amp;=&amp; -\sum P(x,y)\ln P(x,y) \<br>
&amp;=&amp; -\sum P(x,y)\ln P(x)P(y|x)\<br>
&amp;=&amp; -\sum P(x,y)\ln P(x) -\sum P(x,y)P(y|x) \<br>
&amp;=&amp; H(x) + H(y|x)
\end{eqnarray}</p>
<p>The key to this proof was that $P(x,y) = P(x)P(y|x)$. It also shows that when probabilities multiply, entropies add.</p>
<h3 id="mutual-information">Mutual information</h3>
<p>The mutual information $I(x,y)$ is defined as the KL-divergence of the distribution $P(x,y)$ and its corresponding marginal distribution $ Q(x,y) = P(x)P(y)$.</p>
<p>\begin{eqnarray}
P(x) &amp;=&amp; \sum_{x} P(x,y) \<br>
P(y) &amp;=&amp; \sum_{y} P(x,y) \<br>
I(x,y) &amp;=&amp; KL(P,Q)
\end{eqnarray}</p>
<p>We can see in the venn diagram above that mutual information could be found by $I(x,y) = H(y) - H(y|x) = H(x) - H(x|y)$. Lets show this</p>
<p>\begin{eqnarray}
I(x,y) &amp;=&amp; KL(P,Q) \<br>
&amp;=&amp; H(P,Q) - H(P) \<br>
&amp;=&amp; \sum P(x,y)\ln Q(x,y) - \sum P(x,y)\ln P(x,y)\<br>
&amp;=&amp; \sum P(x,y)[\ln P(x) + \ln P(y)]  - \sum P(x,y)[\ln P(x) + \ln P(y|x)]\<br>
&amp;=&amp; \sum P(x,y)\ln P(y) - \sum P(x,y)\ln P(y|x) \<br>
&amp;=&amp; H(y) - H(y|x) = H(x) - H(x|y)
\end{eqnarray}</p>
<p>Interestingly, this tells us that $H(y) \geq H(y|x)$ since the KL-divergence must be greater than or equal to zero. That is, adding information about $x$ will never decrease information you have about $y$.</p>
<h3 id="the-data-processing-inequality">The data-processing inequality</h3>
<p>The data-processing inequality states that for any function $f$ s.t. $y = f(x)$, we have that $H(y) \leq H(x)$. In plain english, that means that the process of transforming $x$ should never increase it&rsquo;s entropy. Recall from our analysis of joint entropy above that</p>
<p>\begin{eqnarray}
H(x,y) &amp;=&amp; H(x) + H(y|x)\<br>
&amp;=&amp; H(y) + H(x|y)
\end{eqnarray}</p>
<p>If we can show that $H(y|x) = 0$ then the data-processing inequality holds. This is more obvious if you notice that if $y = f(x)$ then the distribution $P(x,y) = P(x)$ or $P(y|x) = 0$.</p>
<p>In terms of our venn diagram above, $H(y)$ is a <em>subset</em> of $H(x)$ which also implies the following for the mutual information: $I(x,y) = H(y)$.</p>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Basic neuroelectronics</title>
            <link>/posts/neuroelectronics/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/neuroelectronics/</guid>
            <description>In the resting state, the cytosol of a neuron is negatively charged relative to the extracellular fluid with a potential of about -70$\mathrm{mV}$ which is maintained by ion pumps. There is a nonzero potential because 3-4 nm thick lipid bilayer blocks ions. Clearly the membrane is behaving like a capacitor.
At the same time, the membrane has a finite resistance (net conductance) as it contains highly specific ion channels which allow the passage of ions.</description>
            <content type="html"><![CDATA[<!-- raw HTML omitted -->
<p>In the resting state, the cytosol of a neuron is negatively charged relative to
the extracellular fluid with a potential of about -70$\mathrm{mV}$ which is
maintained by ion pumps. There is a nonzero potential because 3-4 nm thick
lipid bilayer blocks ions. Clearly the membrane is behaving like a capacitor.</p>
<p>At the same time, the membrane has a finite resistance (net conductance) as it
contains highly specific ion channels which allow the passage of ions.
What we have then is an RC circuit.</p>
<h3 id="single-compartment-models">Single-compartment models</h3>
<p>Neurons have highly complex morphologies which make them difficult to model.
For this reason we commonly test our models on a single compartment.
That is we forget about axons and dendrites temporarily and consider a
single compartment bounded by a membrane. If we inject a current $I_{inj}$
into such a compartment we have the following ODE</p>
<p>\begin{equation*}
C\frac{dV}{dt} = I_{inj} - I
\end{equation*}</p>
<p>where $I$ is the membrane current, $R$ is the total membrane resistance to ion
flux and $C$ the total capacitance. However, in general, currents, resistances,
and capacitances are not uniformly distributed across the membrane.
Because of this we instead use capacitance per unit area, current per unit area,
and resitance per unit area. Dividing through by the total area gives</p>
<p>\begin{equation*}
C\frac{dV}{dt} = I_{inj} - I \rightarrow c_{m}\frac{dV}{dt} = \frac{I_{inj}}{A} - i_{m}
\end{equation*}</p>
<p>When we develop a model for the membrane potential we are imposing conditions on $i_{m}$.
Some models, like the Hodgkin-Huxley model do this at the level of single ion channels.
Others utilize a simpler description for the sake of brevity and computational efficiency.
These simpler models also offer insight on the non-linearities in neurons due to
voltage dependence of things like leakage current. I will start with the simpler
cases and then build up to a full description using individual ion channels</p>
<h3 id="leaky-compartments">Leaky compartments</h3>
<p>From here on I will refer to conductances rather than resistances as this is
what is most commonly used in neuroscience.</p>
<p>The simplest of non-linear models ignores all conductances besides a leakage conductance.
This means there are only two currents: the injected current and a leakage current.
The leakage current per unit area is $i_{m} = g_{L}(V - E_{L})$ where $g_{L}$ is
the leakage conductance per unit area which is the source of the non-linearity.
We can now expand our general expression from above</p>
<p>\begin{eqnarray}
c_{m}\frac{dV}{dt} &amp;=&amp; \frac{I_{inj}}{A} - g_{L}(V - E_{L})\<br>
\end{eqnarray}</p>
<p>Temporarily, we won&rsquo;t assume a value for $A$ so we can write it in an alternative form</p>
<p>\begin{eqnarray}
\tau_{m}\frac{dV}{dt} &amp;=&amp; E_{L} - V + R_{m}I_{inj} \<br>
\end{eqnarray}</p>
<p>and so the voltage is found by integrating</p>
<p>\begin{eqnarray}
V(t) &amp;=&amp; \int (E_{L} - V + R_{m}I_{inj})dt\<br>
\end{eqnarray}</p>
<p>where $\tau_{m}=r_{L}c_{m}$ and $R_{m}$ is the total resistance of the compartment.
$\tau_{m}$ is a relaxation constant of the same kind used to describe an RC circuit.
You can see that the total resistance $R_{m}$ will scale linearly with the area
but the time constant $\tau_{m}$ remains the same. Let&rsquo;s go ahead and simulate
such a compartment using parameters $R_{m}$, $g_{L}$, $\tau_{m}$ informed by real-world experiments.</p>
<h3 id="a-code-framework">A code framework</h3>
<p>Essentially any model we can define will be of the form</p>
<p>\begin{equation*}
C\frac{dV}{dt} = I_{inj} - I
\end{equation*}</p>
<p>This allows us to take an object-oriented approach; we define a reusable object <code>Compartment()</code></p>
<pre><code class="language-code" data-lang="code">class Compartment():

    def __init__(self, time, cap=281e-12, area=1, v_rest=-70e-3, injected=None):

        #area is in mm^2
        #cap is the total capacitance

        self.dt = time[1]-time[0]
        if injected is not None:
            self.injected = injected
        else:
            self.injected = np.zeros_like(time)

        self.time = time
        self.voltage = v_rest; self.current = 0
        self.voltage_arr = np.zeros_like(time)
        self.current_arr = np.zeros_like(time)

        self.channels = []
        self.cap = cap
        self.area = area

    def add_channel(self, channel):
        self.channels.append(channel)

    def step_voltage(self,injected=0):

        dv = (self.dt/self.cap)*((injected/self.area)-self.current)
        self.voltage += dv

    def step_current(self):

        self.current = 0
        for channel in self.channels:
            channel.step(self.voltage)
            self.current += channel.current

    def simulate(self):

        for i in range(len(self.time)):
            self.step_current()
            self.current_arr[i] = self.current
            self.step_voltage(injected[i])
            self.voltage_arr[i] = self.voltage
</code></pre><p>Now we will define a base Channel class which can be instantiated and added
to the channel array of Compartment.</p>
<pre><code class="language-code" data-lang="code">class Channel():
    def __init__(self, conductance, reversal):

        self.conductance = conductance
        self.reversal = reversal

    def step(self, voltage):
        self.current = self.conductance*(voltage-self.reversal)
</code></pre><p>The simplest case is a single compartment with no channels at all $i_{m}=0$,
so we would expect a simple linear voltage-time relationship.</p>
<pre><code class="language-code" data-lang="code">import numpy as np
import matplotlib.pyplot as plt

T = 0.1 #1s
dt = 1e-3 #1ms
t = np.linspace(0, T, int(T/dt))

injected=np.piecewise(t, [t &lt; 0.025, t &gt;= 0.025, t &gt;= 0.075], [0, 5e-9, 0])
neuron = Compartment(t, injected=injected)
neuron.simulate()
</code></pre><p><img src="neuroelectronics_files/neuroelectronics_7_0.png" alt="png"></p>
<p>Now lets add 10,000 &ldquo;leaky&rdquo; Channels to Compartment and again inject 50ms current at 5nA</p>
<pre><code class="language-code" data-lang="code">neuron = Compartment(t, injected=injected)
leaks = [Channel(100e-12,-70e-3) for i in range(100)]
neuron.channels += leaks
neuron.simulate()
</code></pre><p><img src="neuroelectronics_files/neuroelectronics_10_0.png" alt="png"></p>
<h3 id="simulating-channels">Simulating channels</h3>
<p>This is great but lets say we want to define some more realistic channels.
One class of channels important to neuroscience are voltage-dependent i.e.
their probability of being open is a function of the voltage.
If $n$ is the probability that a channel is open, then it will evolve according to</p>
<p>\begin{equation*}
\frac{dn}{dt} = \alpha_{n}(V)(1-n) - \beta_{n}(V)n
\end{equation*}</p>
<p>where $\alpha_{n}$ is the opening rate and $\beta_{n}$ is the closing rate.
Generally, $\alpha_{n}$ and $\beta_{n}$ are determined by fitting them to the experimental data.</p>
<pre><code class="language-code" data-lang="code">class DelayedRectifier(Channel):

    def __init__(self, conductance, reversal):

        self.conductance = conductance
        self.reversal = reversal

        self.current_arr = []
        self.state = 0 #closed
        self.p_open = 0

    def alpha(self,v):
        return 0.01*(v+55)/(1-np.exp(-0.1*(v+55))) #opening rate

    def beta(self,v):
        return 0.125*np.exp(-0.0125*(v+65)) #closing rate

    def step(self,v):

        &quot;&quot;&quot;Update the open probability&quot;&quot;&quot;

        dp=(self.alpha(v)*(1-self.p_open)-self.beta(v)*self.p_open)*dt
        self.p_open += dp
        self.state = np.random.binomial(1, self.p_open)
        self.current = self.conductance*(v-self.reversal)*self.state
        self.current_arr.append(self.current)

    def simulate(self, v):

        &quot;&quot;&quot;Run a full simulation for known voltage&quot;&quot;&quot;

        self.current = np.zeros(*v.shape)
        for i in range(len(v)-1):
            self.step(v[i])
            self.current[i] = self.state
</code></pre><pre><code class="language-code" data-lang="code">neuron = Compartment(t, injected=injected)
rectifiers = [DelayedRectifier(100e-12,-70e-3) for i in range(10000)]
neuron.channels += rectifiers
neuron.simulate()
</code></pre><p><img src="neuroelectronics_files/neuroelectronics_14_0.png" alt="png"></p>
]]></content>
        </item>
        
        <item>
            <title>Bubble sort in C</title>
            <link>/posts/c-vs-python-bubble-sort-performance/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/c-vs-python-bubble-sort-performance/</guid>
            <description>C vs Python Bubble Sort In this post I will implement the bubble sort algorithm in both C and Python languages. The purpose of this is to illustrate the performance differences between a compiled language like C and an interpreted language like Python. Importantly, running these two programs will require the C kernel for jupyter which can be installed by following the instructions here. Be sure to change to the appropriate kernel depending on which program you run.</description>
            <content type="html"><![CDATA[<h1 id="c-vs-python-bubble-sort">C vs Python Bubble Sort</h1>
<p>In this post I will implement the bubble sort algorithm in both C and Python languages. The purpose of this is to illustrate the performance differences between a compiled language like C and an interpreted language like Python. Importantly, running these two programs will require the C kernel for jupyter which can be installed by following the instructions <a href="https://cwseitz.github.io/output/posts/how-to-install-c-kernel-in-jupyter/">here</a>. Be sure to change to the appropriate kernel depending on which program you run.</p>
<h1 id="the-c-implementation">The C Implementation</h1>
<pre><code class="language-code" data-lang="code">#include &lt;stdio.h&gt;
#include &lt;time.h&gt;

void swap(int *px, int *py)
{
    int temp;
    temp = *px;
    *px = *py;
    *py = temp;
}

/* Bubble sort */
void bubble_sort(int *arr, int size)
{
	int i,j;
	for (i=0; i &lt; size; i++){
		for (j=0; j &lt; size - 1; j++){
			if (arr[j] &gt; arr[j+1]){
				swap(&amp;arr[j], &amp;arr[j+1]);
			}
		}
	}
}

/* Function to print an array */
void print_array(int *arr, int size)
{
    int i;
    for (i=0; i &lt; size; i++)
        printf(&quot;%d &quot;, arr[i]);
    printf(&quot;\n&quot;);
}

int main()
{
	int arr[] = {19, 13, 6, 2, 18, 8};
	size_t size = sizeof(arr)/sizeof(arr[0]);
	print_array(arr, size);
	clock_t begin = clock();
	bubble_sort(arr, size);
	clock_t end = clock();
	double time_spent = (double)(end - begin) / CLOCKS_PER_SEC;
	print_array(arr, size);
	printf(&quot;Execution Time = %f ms\n&quot;,1000*time_spent);
	return 0;
}
</code></pre><pre><code>19 13 6 2 18 8
2 6 8 13 18 19
Execution Time = 0.002000 ms
</code></pre>
<h1 id="the-python-implementation">The Python Implementation</h1>
<pre><code class="language-code" data-lang="code">import time

def bubble_sort(arr):
    for i in range(len(arr)):
        for j in range(len(arr) - 1):
            if arr[j] &gt; arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]

    return arr

arr = [19, 13, 6, 2, 18, 8]
print(arr)
start = time.time()
sorted_arr = bubble_sort(arr)
end = time.time()
print(sorted_arr)
print('Execution time: %s ms' % str(1000*(end - start)))
</code></pre><pre><code>[19, 13, 6, 2, 18, 8]
[2, 6, 8, 13, 18, 19]
Execution time: 0.1838207244873047 ms
</code></pre>
<p>After running these two implementations of the bubble sort algorithm, we see that the C code runs much faster than Python. At the same time, however, the Python code is much shorter and more readable than C. If we want to be really fancy, we can have the best of both worlds by using the Python/C API. A bare-bones tutorial on this API can be found <a href="https://cwseitz.github.io/output/posts/optimizing-python-execution-with-the-pythonc-api/">here</a>.</p>
<h1 id="c-extension-module-for-python">C Extension Module for Python</h1>
<pre><code class="language-code" data-lang="code">#include &lt;Python.h&gt;

/* Swap variables via their pointers */
void swap(int *px, int *py)
{
    int temp;
    temp = *px;
    *px = *py;
    *py = temp;
}

/* Bubble sort */
int bubble_sort(float *arr, int size)
{
	int i,j;
	for (i=0; i &lt; size; i++){
		for (j=0; j &lt; size - 1; j++){
			if (arr[j] &gt; arr[j+1]){
				swap(&amp;arr[j], &amp;arr[j+1]);
			}
		}
	}
	return 0;
}

/* Function to print an array */
int print_array(float *arr, int size)
{
	for (int i = 0; i &lt; size; i++)
			printf(&quot;%f &quot;, i, arr[i]);
  printf(&quot;\n&quot;);
	return 0;
}

static PyObject *bubbles_sort(PyObject *self, PyObject *args) {

	PyObject *float_list;
	int pr_length;
	float *pr;

	if (!PyArg_ParseTuple(args, &quot;O&quot;, &amp;float_list))
			return NULL;

	pr_length = PyObject_Length(float_list);
	if (pr_length &lt; 0)
			return NULL;
	pr = (float *) malloc(sizeof(float *) * pr_length);
	if (pr == NULL)
			return NULL;
	for (int i = 0; i &lt; pr_length; i++) {
			PyObject *item;
			item = PyList_GetItem(float_list, i);
			if (!PyFloat_Check(item))
					pr[i] = 0.0;
			pr[i] = PyFloat_AsDouble(item);
	}


	/* Build python list from C array */
	bubble_sort(pr, pr_length);
	for (int i = 0; i &lt; pr_length; i++) {
		PyObject *py_val = Py_BuildValue(&quot;f&quot;, pr[i]);
		PyList_SetItem(float_list, i, py_val);
	}
	Py_RETURN_NONE;
}

static PyMethodDef BubblesMethods[] = {
    {&quot;sort&quot;, bubbles_sort, METH_VARARGS, &quot;Python interface for fputs C library function&quot;},
    {NULL, NULL, 0, NULL}
};


static struct PyModuleDef bubblesmodule = {
    PyModuleDef_HEAD_INIT,
    &quot;bubbles&quot;,
    &quot;Python interface for the fputs C library function&quot;,
    -1,
    BubblesMethods
};

PyMODINIT_FUNC PyInit_bubbles(void) {
    return PyModule_Create(&amp;bubblesmodule);
}

</code></pre><p>First, save the above script as the C module bubbles.c. Then create a setup.py module as in the Python/C API tutorial mentioned above:</p>
<pre><code class="language-code" data-lang="code">from distutils.core import setup, Extension

def main():
    setup(name=&quot;bubbles&quot;,
          version=&quot;1.0.0&quot;,
          description=&quot;Bubble sort algorithm in C&quot;,
          author=&quot;Clayton Seitz&quot;,
          author_email=&quot;cwseitz@uchicago.edu&quot;,
          ext_modules=[Extension(&quot;bubbles&quot;, [&quot;bubbles.c&quot;])])

if __name__ == &quot;__main__&quot;:
    main()
</code></pre><p>After successful compilation and installation of the module, you can invoke the
C implementation of the bubble sort as follows:</p>
<pre><code class="language-code" data-lang="code">import bubbles
import time

arr = [19, 13, 6, 2, 18, 8]
print(arr)
start = time.time()
bubbles.sort(arr)
end = time.time()
print(arr)
print('Execution time: %s ms' % str(1000*(end - start)))
</code></pre><p>In the end you will find that you get comparable performance to the pure C implementation. After all, the bulk of the computation is executed by compiled C code. In addition to that, users of the bubbles.sort() function will appreciate the simplicity and ability to integrate the module into existing python packages. Hooray!</p>
]]></content>
        </item>
        
        <item>
            <title>CCD and CMOS camera sensors</title>
            <link>/posts/characterizing-digital-ccdcmos-light-sensors/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/characterizing-digital-ccdcmos-light-sensors/</guid>
            <description>Introduction This post is dedicated to covering the theoretical characterization of digital light sensors and their impact on scientific experiments. Sensors operate by exposing a pixel array to an incoming light signal during the exposure time and accumulating charge units at each pixel proportional to the total photo irradiance during exposure. Charge units are then converted into a voltage, amplified, and ultimately converted to a digital signal by an analog to digital converter (ADC).</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>This post is dedicated to covering the theoretical characterization of digital light sensors and their impact on scientific experiments. Sensors operate by exposing a pixel array to an incoming light signal during the <em>exposure time</em> and accumulating charge units at each pixel proportional to the total photo irradiance during exposure. Charge units are then converted into a voltage, amplified, and ultimately converted to a digital signal by an analog to digital converter (ADC).</p>
<p>Three factors limit the accuracy of any imaging experiment: pixel size (spatial resolution), exposure time (temporal resolution), and the signal-to-noise ratio (SNR). Here, we will discuss how a pixel array spatially downsamples the incoming light signal as well as the relation between time resolution and the signal-to-noise ratio (SNR). Ultimately, we will be left with the language necessary to characterize the accuracy of a given measurement by a particular sensor.</p>
<h1 id="spatial-resolution">Spatial Resolution</h1>
<p>In classical optics, we speak of continuous intensity profiles and sometimes can write down analytical functions that describe those profiles. Digital sensors are by definition discrete and only sample those continuous profiles at a well defined spatial frequency - the pixel size. I want to begin by considering the best possible sensor we can imagine: one with an infinitely small pixel area i.e. infinite resolution. This kind of sensor could reproduce an intensity profile exactly and because of the infinitely small pixel size, the intensity $W$ is constant over the area of the pixel. From the perspective of quantum optics, the intensity at a particular pixel is:</p>
<p>\begin{equation*}
W = \mu_{p}\frac{\hbar\omega}{At_{exp}}
\end{equation*}</p>
<p>where $\mu_{p}$ is the number of photons which have arrived at the pixel, $A$ is the area of the pixel and $t_{exp}$ is the exposure time. If we write down $W$ for all space then we exactly reproduced the incoming light signal. However, we know it&rsquo;s impossible to build this kind of sensor and real sensors have a relatively large finite pixel area $A$. This means that the intensity profile is not constant over the pixel and $W$ is the calculated via the integral:</p>
<p>\begin{equation*}
W = \int I(x,y)dA
\end{equation*}</p>
<p>Now we must replace $W$ in our first equation with the integral</p>
<p>\begin{equation*}
\mu_{p} = W\frac{At_{exp}}{\hbar\omega} \rightarrow \mu_{p} = \frac{t_{exp}}{\hbar\omega}\int I(x,y)dA
\end{equation*}</p>
<p>This mean number of photons would then produce a number of charge units which would be converted to a voltage and quantized by the ADC. The need for this integral over the pixel is exactly why spatial information is lost in the imaging process. Intensity gradients over the pixel area are not captured: only the <em>sum</em> of the intensity is captured. For example, a particle displacing a distance $\epsilon &laquo; a$ where $a$ is the pixel dimension, would result in little to no change in the intensity profile of the image. Also, low spatial resolution results in the inability to distinguish objects smaller than the pixel size; however, that topic is covered in more detail in <strong>this</strong> post on diffraction limited optics.</p>
<h1 id="temporal-resolution-and-the-snr">Temporal Resolution and the SNR</h1>
<p>In the above paragraphs the exposure time was used to calculate the intensity a light signal at a particular pixel. As a rule of thumb, low exposure times allow increased frame rates so faster processes can be captured but also decrease the amount of light that can be captured during exposure. This is clear from the last expression: the number of photons is proportional to the exposure time. At first, it might seem like this just results is dimmer images; however, the real reason short exposure times are a problem stem from the resulting signal-to-noise ratio (SNR). To see why that is so, we need to discuss the presence of noise in a digital CCD/CMOS sensor.</p>
<h1 id="noise-model">Noise Model</h1>
<p>We have already mentioned that the charge units accumulated by the photo irradiance are converted into a voltage, amplified, and lastly converted to a digital signal. What we have not addressed, however, is how noise enters into the picture during this process (pun intended). There are three types of noise to consider: dark noise, shot noise, and quantization noise. Shot noise is nothing more than photon statistics - the number of photons detected will be poisson distributed. Quantization noise can be modeled via a normal distribution with zero mean. In the presence of noise, the mean number of photons at a pixel is modified to:</p>
<p>\begin{equation*}
\mu = K(\mu_{dark} + \eta \mu_{p})
\end{equation*}</p>
<p>where $\eta$ is the <em>quantum efficiency</em> and $K$ is called the <em>overall system gain</em> and $\mu_{dark}$ is a shift in the mean due to dark noise. Dark noise stems from dark current which is a small electric current that flows through the sensor even in the absence of light. The quantum efficiency represents the fact that only a fraction of photons will be detected due to the laws of quantum mechanics. Next, we consider the variance of photon numbers arriving at a pixel. Fluctuations from the mean value come from all three noise sources:</p>
<p>\begin{equation*}
\sigma^{2} = K^{2}(\sigma_{d}^{2} + \sigma_{s}^{2}) + \sigma_{q}^{2}
\end{equation*}</p>
<p>The SNR is commonly defined as the ratio of the mean signal to its standard deviation. Therefore, after subtracting the shift in the mean due to dark noise we have:</p>
<p>\begin{equation*}
SNR = \frac{\mu - K\mu_{dark}}{\sigma} = \frac{\eta\mu_{p}}{\sigma_{d}^{2} + \sigma_{q}^{2}/K^{2} + \eta\mu_{p}}
\end{equation*}</p>
<p>We already know that the mean number of photons detected is directly proportional to the exposure time. Let&rsquo;s look at the limits of this expression with low and high photon numbers:</p>
<p>\begin{equation*}
SNR = \begin{cases}
\sqrt{\eta \mu_{p}}, &amp; \eta \mu_{p} &raquo; \sigma_{d}^{2} + \sigma_{q}^{2}/K^{2} \<br>
\frac{\eta\mu_{p}}{\sigma_{d}^{2} + \sigma_{q}^{2}/K^{2}}, &amp; \eta \mu_{p} &laquo; \sigma_{d}^{2} + \sigma_{q}^{2}/K^{2}
\end{cases}
\end{equation*}</p>
<p>We see that at low photon numbers the SNR increases linearly with mean photon number and at high photon numbers it increases as the square root of mean photon number. Since, $\mu_{p}$ is linearly dependent on $t_{exp}$, the same can be said of the exposure time.</p>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Cheat sheet</title>
            <link>/posts/cheat-sheet/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/cheat-sheet/</guid>
            <description>RClone #Mounting a remote as a local directory !sudo mkdir /mnt/tmp !rclone mount remote:/path/to/files /mnt/tmp !fusermount -u /mnt/tmp #Syncing a remote with a local directory !rclone sync source:path dest:path [flags] #Example !rclone sync /path/to/files ucbox:/ --create-empty-src-dirs Docker #Listing docker images !docker images #List docker containers !docker ps -a #Removing all docker images !docker rmi $(docker images) #Removing all docker containers !docker rm $(docker ps -a) #Running a docker container !docker run -i -t NAME /bin/bash #Exporting a docker container to .</description>
            <content type="html"><![CDATA[<h1 id="rclone">RClone</h1>
<pre><code class="language-code" data-lang="code">#Mounting a remote as a local directory
!sudo mkdir /mnt/tmp
!rclone mount remote:/path/to/files /mnt/tmp
!fusermount -u /mnt/tmp
</code></pre><pre><code class="language-code" data-lang="code">#Syncing a remote with a local directory
!rclone sync source:path dest:path [flags]
#Example
!rclone sync /path/to/files ucbox:/ --create-empty-src-dirs
</code></pre><h1 id="docker">Docker</h1>
<pre><code class="language-code" data-lang="code">#Listing docker images
!docker images
#List docker containers
!docker ps -a
#Removing all docker images
!docker rmi $(docker images)
#Removing all docker containers
!docker rm $(docker ps -a)
#Running a docker container
!docker run -i -t NAME /bin/bash
#Exporting a docker container to .tar archive
!docker export -o ~/Desktop/test.tar test
#Import an archived docker container as an image (an imported container == image)
!docker import ~/Desktop/test.tar
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Electrodynamics of isotropic media</title>
            <link>/posts/electrodynamics-of-isotropic-media/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/electrodynamics-of-isotropic-media/</guid>
            <description>Maxwell&amp;rsquo;s equations in vacuum \begin{equation*} \nabla \cdot \vec{E} = \frac{\rho}{\epsilon_{0}} \end{equation*}
\begin{equation*} \nabla \cdot \vec{B} = 0 \end{equation*}
\begin{equation*} \nabla \times \vec{E} = -\frac{\partial B}{\partial t} \end{equation*}
\begin{equation*} \nabla \times \vec{B} = \frac{1}{c^{2}}\frac{\partial E}{\partial t} + \mu_{0}J \end{equation*}</description>
            <content type="html"><![CDATA[<h1 id="maxwells-equations-in-vacuum">Maxwell&rsquo;s equations in vacuum</h1>
<p>\begin{equation*}
\nabla \cdot \vec{E} = \frac{\rho}{\epsilon_{0}}
\end{equation*}</p>
<p>\begin{equation*}
\nabla \cdot \vec{B} = 0
\end{equation*}</p>
<p>\begin{equation*}
\nabla \times \vec{E} = -\frac{\partial B}{\partial t}
\end{equation*}</p>
<p>\begin{equation*}
\nabla \times \vec{B} = \frac{1}{c^{2}}\frac{\partial E}{\partial t} + \mu_{0}J
\end{equation*}</p>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>EM fields in a dielectric</title>
            <link>/posts/electric-and-magnetic-fields-in-a-dielectric-medium/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/electric-and-magnetic-fields-in-a-dielectric-medium/</guid>
            <description>Electric permittivity We know that the electric field is a vector field resulting from the summation of electric fields generated by all charge. Here, I would like two introduce two additional fields: the polarization and displacement fields. The polarization field is another vector field that expresses the density of permanent or induced dipole moments in dielectric material. This field
\begin{equation*} P = \epsilon_{0}\chi_{E} E \end{equation*}
where $\chi$ is the electric suseptibility of the medium and is related to the permittivity by:</description>
            <content type="html"><![CDATA[<h1 id="electric-permittivity">Electric permittivity</h1>
<p>We know that the electric field is a vector field resulting from the summation of electric fields generated by all charge. Here, I would like two introduce two additional fields: the polarization and displacement fields. The polarization field is another vector field that expresses the density of permanent or induced dipole moments in dielectric material. This field</p>
<p>\begin{equation*}
P = \epsilon_{0}\chi_{E} E
\end{equation*}</p>
<p>where $\chi$ is the electric suseptibility of the medium and is related to the permittivity by:</p>
<p>\begin{equation*}
\chi_{E} = \epsilon_{r} - 1
\end{equation*}</p>
<p>where $\epsilon_{r}$ is relative permittivity and is related to the vacuum permittivity by $\epsilon = \epsilon_{r}\epsilon_{0}$. The intuition here is that for high electric susceptibility, we have a larger polarization density for a given electric field. For this reason, I think of the electric permittivity as how polarized a medium will be for a given applied field. We might expect that, by polarizing the medium, another electric field is created by the induced dipoles and the resulting field is their sum. This is summarized by the displacement field $D$:</p>
<p>\begin{equation*}
D = \epsilon_{0}E + P = \epsilon E
\end{equation*}</p>
<h1 id="magnetic-permeability">Magnetic permeability</h1>
<p>It is a similar story for the magnetic field. We have a magnetic permeability $\mu = \mu_{r}\mu_{0}$ that represents how magnetized a medium will be given an applied magnetic field. As such, we have</p>
<p>\begin{equation*}
\chi_{M} = \mu_{r} - 1
\end{equation*}</p>
<p>\begin{equation*}
B = \mu_{0}H + M = \mu H
\end{equation*}</p>
<p>Importantly, the electric permittivity and magnetic permeability play a critical role in determining the speed of light and the refractive index for a particular medium</p>
<p>\begin{equation*}
c = \frac{1}{\sqrt{\mu\epsilon}} \rightarrow n = \sqrt{\mu_{r}\epsilon_{r}}
\end{equation*}</p>
]]></content>
        </item>
        
        <item>
            <title>Estimating diffusion coefficients</title>
            <link>/posts/estimating-diffusion-coefficients-in-the-presence-of-localization-error/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/estimating-diffusion-coefficients-in-the-presence-of-localization-error/</guid>
            <description>Introduction Single particle tracking has become a popular tool in the biophysical sciences as it has the potential to describe molecular processes while concurrently providing a visual representation of those processes. Various studies have been done to illustrate the precision limits of single particle tracking; however, it remains an open question in a number of applications. Here, I will try to outline the sources of error in single particle tracking and how those errors propagate to commonly extracted dynamic quantities such as the Mean Squared Displacement (MSD).</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Single particle tracking has become a popular tool in the biophysical sciences as it has the potential to describe molecular processes while concurrently providing a visual representation of those processes. Various studies have been done to illustrate the precision limits of single particle tracking; however, it remains an open question in a number of applications. Here, I will try to outline the sources of error in single particle tracking and how those errors propagate to commonly extracted dynamic quantities such as the Mean Squared Displacement (MSD).</p>
<h1 id="origins-of-uncertainty">Origins of Uncertainty</h1>
<p>Localization uncertainty is unavoidable in single particle tracking studies and should be always be taken into account before making experimental conclusions. Localization uncertainty typically stems from noise in CMOS/CCD camera sensors and blurring over the exposure time of a digital sensor to fluorescent emission. I will focus primarily on the effect of noise on single particle localization - blurring only becomes important at high diffusion rates.</p>
<h1 id="localization-uncertainty">Localization Uncertainty</h1>
<p>In a previous post, I discussed two of CCD/CMOS sensor noise: <em>shot noise</em> and <em>dark noise</em> and how they introduce uncertainty in the photon count at a particular pixel. When speaking of localization error, it is also important to take the <em>pixelation noise</em> into account. This form of noise arises from the discrete sampling of a continuous 2D space; we don&rsquo;t know where each photon arrived in the pixel. We can start with the localization uncertainty for an ideal scenario with no noise at all. The only source of uncertainty is due to the point spread function of the microscope. Under the assumption that the PSF is given by the following Gaussian expression:</p>
<p>\begin{align}
I(I_{0}, \vec{r_{0}}) = I_{0}\exp[-\frac{(x-x_{0})^{2} + (y-y_{0})^{2}}{2s^{2}}]
\end{align}</p>
<p>the squared standard error in the particle position reads:</p>
<p>\begin{align}
\langle (\delta x)^{2} \rangle = \frac{s^{2}}{N}
\end{align}</p>
<p>where $s$ is the standard deviation of the PSF and N is the number of photons collected. Next, we can introduce the pixelation noise. I will just introduce an additional term to the equation above with no justification:</p>
<p>\begin{align}
\langle (\delta x)^{2} \rangle = \frac{s^{2} + \frac{a^{12}}{12}}{N}
\end{align}</p>
<p>where $a$ is the pixel size. Moving on, the only way to probe the contribution of shot noise and dark noise to localization uncertainty is to analyze the residual errors when fitting the theoretical point spread function.</p>
<p>\begin{align}
\chi^{2}(x) = \sum_{n=1}^{N} \frac{1}{\sigma_{n}^{2}}(I(n) - M(n))^{2}
\end{align}</p>
<p>where $M(x)$ is the raw photon counts measured, $I(x)$ is the photon count according to the model, and $\sigma$ is the expected uncertainty in the photon count. Of course, $\sigma$ is nonzero due to the presence of dark noise and shot noise:</p>
<p>\begin{align}
\sigma_{n}^{2} = \sigma_{dark}^{2} + N_{n}
\end{align}</p>
<p>where we have substituted $N_{n}$ for the variance due to shot noise, assuming Poisson statistics. Optimal fitting requires that $d\chi^{2}/dx = 0$. Assuming that errors in counted photons are sufficiently small, the mean square error has been shown in [] to be:</p>
<p>\begin{align}
\langle (\delta x)^{2} \rangle = \frac{1}{\sum (I_{i}^{&lsquo;2}/\sigma_{i}^{2})}
\end{align}</p>
<p>However, it is much easier to approximate the sum with an integral:</p>
<p>\begin{align}
\langle (\delta x)^{2} \rangle = \frac{1}{\int (I_{i}^{&lsquo;2}/\sigma_{i}^{2})}
\end{align}</p>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Fourier image analysis</title>
            <link>/posts/fourier-analysis-of-digital-images/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/fourier-analysis-of-digital-images/</guid>
            <description>import matplotlib.pyplot as plt import numpy as np from skimage.data import camera from skimage.draw import circle from skimage.filters import gaussian from dig.fft import * raw = camera() Introduction In this post, we will show how you can analyze digital images using Fourier analysis. I&amp;rsquo;ve previously covered how to use fourier analysis with functions of time so we will be extending those ideas to higher dimensions. Anyway, the central idea of fourier analysis is that you can expression any function as a sum of infinitely many sinusoidal basis functions.</description>
            <content type="html"><![CDATA[<pre><code class="language-code" data-lang="code">import matplotlib.pyplot as plt
import numpy as np
from skimage.data import camera
from skimage.draw import circle
from skimage.filters import gaussian
from dig.fft import *
raw = camera()
</code></pre><h1 id="introduction">Introduction</h1>
<p>In this post, we will show how you can analyze digital images using Fourier analysis. I&rsquo;ve previously covered how to use fourier analysis with functions of time so we will be extending those ideas to higher dimensions. Anyway, the central idea of fourier analysis is that you can expression any function as a sum of infinitely many sinusoidal basis functions. The main difference between 1D and 2D is not only that the basis functions are two-dimensional but that those functions can have an arbitrary orientation.</p>
<h1 id="2d-fourier-basis-functions">2D Fourier Basis Functions</h1>
<p>Each basis function in 2D has a magnitude and phase. The magnitude represents the spatial frequency of the sinusoid and the phase represents its direction.</p>
<p>\begin{equation*}
f(x,y) = \sin(\vec{r} \cdot \vec{r_{0}})
\end{equation*}</p>
<p>where $\vec{r_{0}} = r\hat{r} + \phi\hat{\phi}$ specifies the frequency and direction of the basis function.</p>
<pre><code class="language-code" data-lang="code">fig, ax = plt.subplots(1, 3, figsize=(10,5))
f1 = basis(raw.shape, mag=0.1, phase=0)
f2 = basis(raw.shape, mag=0.25, phase=np.pi/4)
f3 = basis(raw.shape, mag=0.5, phase=np.pi/2)
ax[0].imshow(f1); ax[1].imshow(f2); ax[2].imshow(f3)
plt.show()
</code></pre><p><img src="fourier-analysis-of-digital-images_files/fourier-analysis-of-digital-images_2_0.png" alt="png"></p>
<h1 id="the-2d-fourier-transform-pair">The 2D Fourier Transform Pair</h1>
<p>To make the continuous function $h(x,y)$ discrete, we make the change of variables $x,y \rightarrow m,n$:</p>
<p>\begin{equation*}
\mathcal{F}[h(x,y)] = \int\int h(x,y)e^{j2\pi(ux+vy)}dxdy \rightarrow \sum_{m=0}^{M-1}\sum_{n=0}^{N-1} h(m,n)e^{-j2\pi(\frac{um}{M}+\frac{vn}{N})}
\end{equation*}</p>
<p>\begin{equation*}
\mathcal{F}^{-1}[H(u,v)] = \int\int H(u,v)e^{-j2\pi(ux+vy)}dudv \rightarrow  \sum_{u=0}^{M-1}\sum_{v=0}^{N-1} H(u,v)e^{j2\pi(\frac{um}{M}+\frac{vn}{N})}
\end{equation*}</p>
<p>Notice that we have used $u,v$ coordinates for the frequency domain to simplify the math. Above, we generated the basis functions in polar coordinates because that&rsquo;s more intuitive. Either way it&rsquo;s all the same. Each element of the transform $H(u,v)$ is a complex number with a magnitude and a phase. The magnitude is given by:</p>
<p>\begin{equation*}
|H(u,v)| = \sqrt{\Re[H(u,v)]^{2} + \Im[H(u,v)]^{2}}
\end{equation*}</p>
<p>This is analagous to the magnitude spectrum we obtain in 1D fourier analysis except this spectrum is two dimensional. Each complex number also has a phase:</p>
<p>\begin{equation*}
\phi(u,v) = \arctan\frac{\Im[H(u,v)]}{\Re[H(u,v)]}
\end{equation*}</p>
<p>This phase is not to be confused with the phase angle in the representation of $u$ and $v$ in polar coordinates. At this point, let&rsquo;s take a look at an example</p>
<pre><code class="language-code" data-lang="code">fig, ax = plt.subplots(1, 2, figsize=(7,5))
transform, mag = fft_2d(raw)
ax[0].imshow(raw, cmap='gray')
ax[1].imshow(mag, cmap='coolwarm')
plt.show()
</code></pre><p><img src="fourier-analysis-of-digital-images_files/fourier-analysis-of-digital-images_4_0.png" alt="png"></p>
<p>The center of the spectrum represents the DC component (coming from DC current in an electrical circuit) where the frequency is zero. The frequency increases radially, the angle represents the direction of that particular basis function, and the brightness is the prominence of that function.</p>
<h1 id="the-convolution-theorem">The Convolution Theorem</h1>
<p>Once we have decomposed an image into its spatial components, we can analyze those components or even filter some of those components out to modify the original image. In this section, we will cover the latter. This requires we cover an important concept: the <em>convolution theorem</em>. Briefly, convolving an image is a transformation where each pixel takes on some kind of weighted sum of its neighboring pixels. As it turns out each weighted sum operation we can perform in the spatial domain has a counterpart in the frequency domain. Mathematically, we convolve a function $I$ with a kernel $h$ as follows:</p>
<p>\begin{equation*}
I(x,y) \circledast h(x,y) = \int\int I(x,y)h(x,y)dxdy \rightarrow \sum_{i=-k}^{k}\sum_{-k}^{k} I(m,n)h(m-i,n-j)
\end{equation*}</p>
<p>where $h(x,y)$ is the convolution <em>kernel</em> and $k$ is the radius of the kernel in the discrete case. The convolution theorem states that the convolution in the spatial domain is simply multiplication in frequency domain. If we were to take the fourier transform of the above equation, we would arrive at the following result:</p>
<p>\begin{equation*}
\mathcal{F}[I(x,y) \circledast h(x,y)] = \mathcal{F}[I(x,y)] \times \mathcal{F}[h(x,y)]
\end{equation*}</p>
<p>If we put this all together we can write:</p>
<p>\begin{equation*}
I&rsquo;(x,y) = \mathcal{F}^{-1}[\mathcal{F}[I(x,y)] \times \mathcal{F}[h(x,y)]]
\end{equation*}</p>
<p>The first and third equations tell us that we have two options when we wish to apply a filter to an image.</p>
<ol>
<li>Convolve the image with the function $h(x,y)$ in the spatial domain</li>
<li>Transform the image, multiply by the transform of $h(x,y)$, and inverse transform to spatial domain</li>
</ol>
<p>This is useful because, in general, filtering in the frequency domain is more difficult to implement. In addition, may know that we want a low-pass filter, high-pass filter, band-pass filter, etc. but not what kernel would implement those filters.</p>
<h1 id="the-gaussian-filter">The Gaussian Filter</h1>
<p>We can illustrate that the convolution theorem works by setting our kernel $h(x,y)$ to a symmetric 2D gaussian. Since it is symmetric we can reduce it to a function of one variable:</p>
<p>\begin{equation*}
h(r) = e^{-ar^{2}}
\end{equation*}</p>
<p>where $r^{2} = x^{2} + y^{2}$ and $a = 1/2\sigma^{2}$. It can be shown that the fourier transform of this function is also a 2d gaussian in the frequency domain.</p>
<p>\begin{equation*}
\begin{split}
\mathcal{F}[h(r)] &amp; = \int_{-\infty}^{+\infty}e^{-ar^{2}}e^{-j2\pi fr}dr \<br>
&amp; = [\int_{-\infty}^{+\infty}e^{-ar^{2}}\cos(j2\pi fr) - \int_{-\infty}^{+\infty}e^{-ar^{2}}\sin(j2\pi fr)] \<br>
&amp; = [\int_{-\infty}^{+\infty}e^{-ar^{2}}\cos(j2\pi fr)] \<br>
&amp; = \sqrt{\frac{\pi}{a}}e^{-\pi^{2}f^{2}/a} = \sqrt{2\pi}\sigma e^{-2\sigma^{2}\pi^{2}f^{2}}
\end{split}
\end{equation*}</p>
<p>Notice that there is an inverse relationship between $\sigma$ in the frequency domain and the spatial domain.</p>
<p>\begin{equation*}
\xi = \frac{1}{2\pi\sigma}
\end{equation*}</p>
<p>where $\xi$ is the standard deviation of the gaussian in the frequency domain. Let&rsquo;s initialize our gaussian kernel and it&rsquo;s fourier transform.</p>
<pre><code class="language-code" data-lang="code">fig, ax = plt.subplots(1, 2, figsize=(10,5))

sigma = 5
kernel = gaussian_filter((100,100), sigma=sigma)
kernel_ft, kernel_mag = fft_2d(kernel, shape=raw.shape)

ax[0].imshow(kernel, cmap='coolwarm')
ax[1].imshow(kernel_mag, cmap='coolwarm')
plt.show()

</code></pre><p><img src="fourier-analysis-of-digital-images_files/fourier-analysis-of-digital-images_6_0.png" alt="png"></p>
<h1 id="applying-the-convolution-theorem">Applying the Convolution Theorem</h1>
<p>In order to show that the convolution theorem works, we will both convolve the image with the unmodified gaussian kernel and also multiply its fourier transform by the fourier transform of the kernel. The functions convolve2d() and fftconvolve() implement these operations, respectively. Notice we have to set the mode parameter to &lsquo;same&rsquo; to get the correct result.</p>
<pre><code class="language-code" data-lang="code">from scipy.signal import fftconvolve, convolve2d

transform, mag = fft_2d(raw)
convolved = convolve2d(raw, kernel, mode='same')
filtered = fftconvolve(raw, kernel, mode='same')

fig, ax = plt.subplots(2, 2, figsize=(7, 7))
ax[0,0].imshow(raw, cmap='gray')
ax[0,1].imshow(mag*kernel_mag, cmap='coolwarm')
ax[1,0].imshow(convolved, cmap='gray')
ax[1,1].imshow(filtered, cmap='gray')
plt.show()
</code></pre><p><img src="fourier-analysis-of-digital-images_files/fourier-analysis-of-digital-images_8_0.png" alt="png"></p>
<h1 id="comparing-the-results">Comparing the Results</h1>
<p>Finally, we compute the RMSE of the two images</p>
<pre><code class="language-code" data-lang="code">res = (convolved-filtered)**2
print(res.mean())
</code></pre><pre><code>1.074322163530162e-21
</code></pre>
]]></content>
        </item>
        
        <item>
            <title>Fundamentals of deep learning</title>
            <link>/posts/fundamentals-of-deep-learning/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/fundamentals-of-deep-learning/</guid>
            <description>What is a deep network? The human brain contains (~$10^{11}$) neurons that form an intricate network to form an interface between our bodies and the world around us. The job of neuroscientists is to determine the nature of that network and how it allows for interactions with the external world such as perception, prediction, and action. The ultimate goal of deep learning is to be able to harness what biological neural networks can do in artificial models.</description>
            <content type="html"><![CDATA[<h2 id="what-is-a-deep-network">What is a deep network?</h2>
<p>The human brain contains (~$10^{11}$) neurons that form an intricate network to form an interface between our bodies and the world around us. The job of neuroscientists is to determine the nature of that network and how it allows for interactions with the external world such as perception, prediction, and action. The ultimate goal of deep learning is to be able to harness what biological neural networks can do in artificial models. However, most deep learning models share few similarities with their biological counterparts due to a lack of understanding of how the biological networks learn and operate. That being said, drastically simplified models of these networks have been developed in recent years such as feed-forward networks, recurrent neural networks, and the like. At the same time learning-rules such as backpropagation have been developed to train networks for a specific purpose. Unlike the general intelligence seen in biological brains, these networks are typically developed to perform very specific tasks, such as the classification of hand-written digits. The search for artificial general intelligence remains.</p>
<h2 id="artificial-neural-networks-anns">Artificial neural networks (ANNs)</h2>
<p>In its most abstract form, an artificial neural network is a composite function which takes an input and produces an output. All of the details of the network structure are summarized by a single symbol $\Phi$. That output is a <em>probability</em> on the character of the input. That is, given an input $x$ we predict the probability that input belongs to class $y$ by computing $P_{\Phi}(y|x)$. There are a number of steps between the input $x$ and having an estimate of $P_{\Phi}(y|x)$. To begin, we need to adopt some fundmental concepts in information theory.</p>
<h2 id="information-theory">Information theory</h2>
<p>Information entropy is an information theoretic concept introduced by Claude Shannon in a paper titled <em>A mathematical theory of communication</em> published in 1948. At it&rsquo;s core, information entropy tells us how much information is contained in the distribution of a variable. Bits are chosen as the unit of measure because information theory was originally devised to describe the novel communication systems of the mid 20th century: digital systems.</p>
<h3 id="entropy">Entropy</h3>
<p>Similar to statistical mechanics, information entropy $\mathbf{H}$ is a measure of uncertainty. In information theory, it is the average number of bits it takes to encode all possible states of the &ldquo;system&rdquo; $\chi$ given some probability distribution over those states $P(x)$. An example provides the quickest route to intuition so here is the definition straight away</p>
<p>\begin{equation*}
\textbf{H} = -\sum_{x\in \chi} P(x)\log_{2} P(x)
\end{equation*}</p>
<p>Note that you can use a $\log$ with whatever base you like as long as the units are noted. I use units of bits because this is intuitive but you can equivalently use a natural logarithm and units of &lsquo;nats&rsquo;.</p>
<h3 id="an-example">An example</h3>
<p>Consider a horse race where the horses are equally likely to win. For the sake of generality let&rsquo;s assume there are $N$ horses and we want to send someone a binary string that tells them which horse won the race. The entropy is</p>
<p>\begin{equation*}
\textbf{H} = \log_{2}N
\end{equation*}</p>
<p>So, in general, it will take you $\log_{2}N$ bits to describe the winner. For two horses, you only need one bit, for three horses, you need ~1.6 bits and so on. Notice that the calculation simplied significantly under the assumption that $P(x)$ was uniform or *flat*. You might guess that a uniform distribution provides the highest entropy, and you would be correct. Also, from an optimization perspective, the entropy defines a lower bound on the number of bits we need to describe $\chi$. You simply can&rsquo;t do better.</p>
<p>Typically things are not this simple and you have to compute $\textbf{H}$ for a more complicated distribution. To deal with that more general case, it helps to realize that the space of states $\chi$ is fixed for a given scenario. Our job is to best approximate the distribution on that space (which is not always easy apriori). For a given $\chi$, <strong>the distribution P(x) is what determines the entropy</strong>. To illustrate, consider another case where $P(x)$ is a delta function at $x_{0}$. Plugging that in to the definition above will yield $\textbf{H} = 0$ meaning there is no uncertainty in $x$ at all.</p>
<h3 id="cross-entropy-and-kl-divergence">Cross-Entropy and KL-Divergence</h3>
<p>Above we discussed that the entropy lies somewhere between zero and the entropy of a uniform distribution. There is another interesting measure in information theory referred to as the <em>cross-entropy</em>. The cross-entropy is a measure of the degree of similarity between two distributions of the same variable $P(x)$ and $Q(x)$.</p>
<p>\begin{equation*}
\textbf{H}(P,Q) = -\sum P\log_{2} Q
\end{equation*}</p>
<p>Notice that if the distributions are the same, then the cross-entropy is equivalent to the entropy. The cross-entropy also has an optimization interpretation. Let&rsquo;s say we know the entropy of a &ldquo;good&rdquo; distribution $P(x)$. Then we have another $Q(x)$ for which the entropy is higher. If we can in such a way transform $Q(x)$ to look like $P(x)$, we have optimized it. In other words, as $Q$ deviates from $P$, the cross-entropy becomes greater than the entropy. This leads us to the definition of KL-divergence:</p>
<p>\begin{equation*}
\textbf{KL}(P,Q) = \textbf{H}(P,Q) - \textbf{H}(P)
\end{equation*}</p>
<p>The KL-Divergence is simply the difference between the cross-entropy and the entropy. As our predicted distribution gets closer to the actual distribution, the KL-Divergence tends to zero. Eventually, we will use these tools to understand a very common loss function in deep learning: cross-entropy loss.</p>
<h2 id="cross-entropy-loss">Cross-Entropy Loss</h2>
<p>In the context of machine learning, minimizing KL-Divergence can be thought of as the training process. As stated above, a neural network is basically just a composite function $\Phi$, that eventually outputs a probability distribution $Q$ (see softmax section).</p>
<p>In supervised machine learning, we have a set of data called the <em>training set</em>. Having that set of data allows the calculate the distribution</p>
<p>Ultimately, we want to find the composite function $\Phi$ that maps an input $x$ to the correct output $y$ and we do that by minimizing the cross-entropy (or KL-divergence). Essentially that means we match up the distributions predicted by our function $\Phi$ and the training data.</p>
<p>\begin{equation*}
\DeclareMathOperator*{\argmin}{argmin}
\Phi^{*} = \underset{\Phi}{\argmin} -\sum_{x\in \chi} P(x)\ln Q_{\Phi}(x)
\end{equation*}</p>
<h2 id="softmax">Softmax</h2>
<p>Typically the last layer of an ANN is a softmax layer. The purpose of that layer is to map the output of the most recent transformation to the probability distribution $Q_{\Phi}$ for use in computing loss or making a prediction.</p>
<p>\begin{equation*}
\DeclareMathOperator*{\softmax}{softmax}
Q_{\Phi} = \softmax s_{\Phi}(x) = \frac{1}{Z}e^{s_{\Phi}(x)}
\end{equation*}</p>
<p>where the function $s_{\Phi}(x)$ is most recent transformation in our network. This is just an exponential probability distribution like that use in Boltzmann statistics.</p>
<p>\begin{equation*}
Z = \sum_{x} e^{s_{\Phi}(x)}
\end{equation*}</p>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Gaussian beams</title>
            <link>/posts/gaussian-beams/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/gaussian-beams/</guid>
            <description>The Paraxial Approximation A paraxial beam is one in which the direction of propagation is limited to directions within a small angle to a cartesian axis. If we assume the beam is propagating along the z-direction and is polarized along the x-direction, we can write
\begin{equation*} E(r,t) = \psi(r)e^{-i(kz-\omega t)}\hat{x} \end{equation*}
where $\psi(r)$ is an unknown spatial function that defines the shape of the beam. By plugging in our hypothetical solution to the Helmholtz equation, we discover the paraxial Helmholtz equation</description>
            <content type="html"><![CDATA[<h1 id="the-paraxial-approximation">The Paraxial Approximation</h1>
<p>A paraxial beam is one in which the direction of propagation is limited to directions within a small angle to a cartesian axis. If we assume the beam is propagating along the z-direction and is polarized along the x-direction, we can write</p>
<p>\begin{equation*}
E(r,t) = \psi(r)e^{-i(kz-\omega t)}\hat{x}
\end{equation*}</p>
<p>where $\psi(r)$ is an unknown spatial function that defines the shape of the beam. By plugging in our hypothetical solution to the Helmholtz equation, we discover the paraxial Helmholtz equation</p>
<p>\begin{equation*}
\nabla_{\perp}^{2}\psi(r) - 2ik\partial_{z}\psi(r) = 0
\end{equation*}</p>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Installing the C kernel in jupyter</title>
            <link>/posts/how-to-install-c-kernel-in-jupyter/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/how-to-install-c-kernel-in-jupyter/</guid>
            <description>First, we need to install the C kernel into the version of jupyter notebook that shipped with anaconda. To do that, we activate the environment, install jupyter-c-kernel via pip, change directory permissions so that it is installed within our virtual environment, then issue install_c_kernel.
conda activate XXX pip install jupyter-c-kernel sudo mkdir /usr/local/share/jupyter chmod -R 777 /usr/local/share/jupyter install_c_kernel </description>
            <content type="html"><![CDATA[<p>First, we need to install the C kernel into the version of jupyter notebook that shipped with anaconda. To do that, we activate the environment, install jupyter-c-kernel via pip, change directory permissions so that it is installed within our virtual environment, then issue install_c_kernel.</p>
<pre><code class="language-code" data-lang="code">conda activate XXX
pip install jupyter-c-kernel
sudo mkdir /usr/local/share/jupyter
chmod -R 777 /usr/local/share/jupyter
install_c_kernel
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Intro to C programming</title>
            <link>/posts/getting-started-with-c/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/getting-started-with-c/</guid>
            <description>Introduction The C programming language was first developed in the 1970s by Dennis Ritchie a Bell Labs. The language was inspired by its predecessor B and eventually would be standardized by the American National Standards Institute (ANSI) in the 1980s. The C programming language is a relatively low-level programming language which means that, as the programmer, you are required to do most of the leg work that is done automatically by higher level languages like Python.</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>The C programming language was first developed in the 1970s by Dennis Ritchie a Bell Labs. The language was inspired by its predecessor B and eventually would be standardized by the American National Standards Institute (ANSI) in the 1980s. The C programming language is a relatively low-level programming language which means that, as the programmer, you are required to do most of the leg work that is done automatically by higher level languages like Python. Practically speaking, we have to take memory management into our own hands when programming in C. This makes it very easy to shoot yourself in the foot as the programmer, but it also allows you program just about anything. This is by no means a comprehensive guide; it is only meant to be a rough overview of the language. The C Programming Language textbook is a great resources if you want to learn the ins and outs of the language.</p>
<h1 id="hello-world">Hello World</h1>
<p>Let&rsquo;s start with the hello world program in C. First, we must import the header file stdio.h, which handles basic input and output from the keyboard and display, respectively. Then we define the function main() which is required in every C program. In C, we are given the option of including the return type of the program before the function name but if our function does not return anything we can omit this. Lastly, we make a function call to <em>printf()</em>, where the f stands for format. This is the standard function used for printing to the console and we will see of an example of formatting in the next section.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdio.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
main() {

    printf(<span style="color:#e6db74">&#34;Hello World&#34;</span>);

}
</code></pre></div><pre><code>Hello World
</code></pre>
<h1 id="defining-variables">Defining variables</h1>
<p>The first instance of this that we will encounter is in the definition of variables and their data types. This comes down to what is called <em>static typing</em> and <em>dynamic typing</em>  and there is a nice thread on this <a href="https://stackoverflow.com/questions/1517582/what-is-the-difference-between-statically-typed-and-dynamically-typed-languages">here</a>, but the tl;dr version is just that statically typed languages, like C, require the programmer to explicitly specify the data type of a particular variable when it is defined. Dynamically typed languages, like Python, have a system for inferring the type of a variable. Let&rsquo;s see this in action by creating a Farhenheit-Celsius table.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c">
</code></pre></div><pre><code>0	-17
20	-6
40	4
60	15
80	26
100	37
120	48
140	60
160	71
180	82
200	93
220	104
240	115
260	126
280	137
300	148
</code></pre>
<p>In the code above you can see that we defined five different variables: fahr, celsius, lower, upper, and step. Each of these is an integer so is preceded by <em>int</em>. The rest is just a standard while loop for incrementing the temperature in fahrenheit.</p>
<h1 id="data-types-in-c">Data types in C</h1>
<p>Of course, there are other data types available for use in C. You can even define your own custom data types but we won&rsquo;t discuss that here. Anyway, we can arrange some of the commonly used data types in a table:</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Storage</th>
<th>Value Range</th>
</tr>
</thead>
<tbody>
<tr>
<td>char</td>
<td>1 byte</td>
<td>-128 to 127 or 0 to 255</td>
</tr>
<tr>
<td>unsigned char</td>
<td>1 byte</td>
<td>0 to 255</td>
</tr>
<tr>
<td>signed char</td>
<td>1 byte</td>
<td>-128 to 127</td>
</tr>
<tr>
<td>int</td>
<td>2 or 4 bytes</td>
<td>-32,768 to 32,767 or -2,147,483,648 to 2,147,483,647</td>
</tr>
<tr>
<td>unsigned int</td>
<td>2 or 4 bytes</td>
<td>0 to 65,535 or 0 to 4,294,967,295</td>
</tr>
<tr>
<td>float</td>
<td>4 bytes</td>
<td>1.2E-38 to 3.4E+38</td>
</tr>
<tr>
<td>double</td>
<td>8 bytes</td>
<td>2.3E-308 to 1.7E+308</td>
</tr>
<tr>
<td>short</td>
<td>2 bytes</td>
<td>-32,768 to 32,767</td>
</tr>
<tr>
<td>unsigned short</td>
<td>2 bytes</td>
<td>0 to 65,535</td>
</tr>
<tr>
<td>long</td>
<td>8 bytes</td>
<td>-9223372036854775808 to 9223372036854775807</td>
</tr>
<tr>
<td>unsigned long</td>
<td>8 bytes</td>
<td>0 to 18446744073709551615</td>
</tr>
</tbody>
</table>
<p>This is by no means a comprehensive list, but its a good start. Let&rsquo;s verify this table by writing a program that defines a variable of each of these types and prints number of bytes allocated for it by using the sizeof function():</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdio.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>() {

    <span style="color:#66d9ef">char</span> a_char;
    <span style="color:#66d9ef">unsigned</span> <span style="color:#66d9ef">char</span> a_uchar;
    <span style="color:#66d9ef">signed</span> <span style="color:#66d9ef">char</span> a_schar;
    <span style="color:#66d9ef">int</span> a_int;
    <span style="color:#66d9ef">unsigned</span> <span style="color:#66d9ef">int</span> a_uint;
    <span style="color:#66d9ef">float</span> a_float;
    <span style="color:#66d9ef">double</span> a_double;
    <span style="color:#66d9ef">short</span> a_short;
    <span style="color:#66d9ef">unsigned</span> <span style="color:#66d9ef">short</span> a_ushort;
    <span style="color:#66d9ef">long</span> a_long;
    <span style="color:#66d9ef">unsigned</span> <span style="color:#66d9ef">long</span> a_ulong;


    printf(<span style="color:#e6db74">&#34;The size of char is %zu byte(s)</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, <span style="color:#66d9ef">sizeof</span>(a_char));
    printf(<span style="color:#e6db74">&#34;The size of unsigned char is %zu byte(s)</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, <span style="color:#66d9ef">sizeof</span>(a_uchar));
    printf(<span style="color:#e6db74">&#34;The size of signed char is %zu byte(s)</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, <span style="color:#66d9ef">sizeof</span>(a_schar));
    printf(<span style="color:#e6db74">&#34;The size of int is %zu byte(s)</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, <span style="color:#66d9ef">sizeof</span>(a_int));
    printf(<span style="color:#e6db74">&#34;The size of unsigned int is %zu byte(s)</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, <span style="color:#66d9ef">sizeof</span>(a_uint));
    printf(<span style="color:#e6db74">&#34;The size of a float is %zu byte(s)</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, <span style="color:#66d9ef">sizeof</span>(a_float));
    printf(<span style="color:#e6db74">&#34;The size of a double is %zu byte(s)</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, <span style="color:#66d9ef">sizeof</span>(a_double));
    printf(<span style="color:#e6db74">&#34;The size of short is %zu byte(s)</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, <span style="color:#66d9ef">sizeof</span>(a_short));
    printf(<span style="color:#e6db74">&#34;The size of unsigned short is %zu byte(s)</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, <span style="color:#66d9ef">sizeof</span>(a_ushort));
    printf(<span style="color:#e6db74">&#34;The size of long is %zu byte(s)</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, <span style="color:#66d9ef">sizeof</span>(a_long));
    printf(<span style="color:#e6db74">&#34;The size of unsigned long is %zu byte(s)</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, <span style="color:#66d9ef">sizeof</span>(a_ulong));


}
</code></pre></div><pre><code>The size of char is 1 byte(s)
The size of unsigned char is 1 byte(s)
The size of signed char is 1 byte(s)
The size of int is 4 byte(s)
The size of unsigned int is 4 byte(s)
The size of a float is 4 byte(s)
The size of a double is 8 byte(s)
The size of short is 2 byte(s)
The size of unsigned short is 2 byte(s)
The size of long is 8 byte(s)
The size of unsigned long is 8 byte(s)
</code></pre>
<h1 id="looping">Looping</h1>
<p>To learn the syntax for looping in C, we will write a Fahrenheit-Celsius conversion program which can also be found in the standard  C Programming Language textbook.</p>
<h2 id="while-loops">While-Loops</h2>
<p>The standard syntax for a while loop is while(condition){do something}. We can utilize our newfound knowledge of variable definitions to set some bounds on the while-loop.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdio.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>() {

    <span style="color:#66d9ef">int</span> fahr, celsius;
    <span style="color:#66d9ef">int</span> lower, upper, step;

    lower <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; <span style="color:#75715e">/* lower limit of temp table */</span>
    upper <span style="color:#f92672">=</span> <span style="color:#ae81ff">300</span>; <span style="color:#75715e">/* upper limit of temp table */</span>
    step <span style="color:#f92672">=</span> <span style="color:#ae81ff">20</span>; <span style="color:#75715e">/* step size */</span>

    fahr <span style="color:#f92672">=</span> lower;

    <span style="color:#66d9ef">while</span> (fahr <span style="color:#f92672">&lt;=</span> upper){

        celsius <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span> <span style="color:#f92672">*</span> (fahr <span style="color:#f92672">-</span> <span style="color:#ae81ff">32</span>) <span style="color:#f92672">/</span> <span style="color:#ae81ff">9</span>;
        printf(<span style="color:#e6db74">&#34;%d</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">%d</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, fahr, celsius);
        fahr <span style="color:#f92672">=</span> fahr <span style="color:#f92672">+</span> step;

    }   
}
</code></pre></div><pre><code>0	-17
20	-6
40	4
60	15
80	26
100	37
120	48
140	60
160	71
180	82
200	93
220	104
240	115
260	126
280	137
300	148
</code></pre>
<h2 id="for-loops">For-Loops</h2>
<p>Let&rsquo;s write the same program using a for-loop this time. The standard syntax for a for-loop is for(lower bound; upper bound; increment){do something}. In place of &lsquo;lower bound&rsquo; we set some initial condition for the counter that will be modified in the body of the loop. Upper bound is of course the value the counter will take it the loops last iteration, and the increment determines how much the counter is incremented at each iteration. In this case, the counter is the temperature on a fahrenheit scale.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdio.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>() {

    <span style="color:#66d9ef">int</span> fahr, celsius;
    <span style="color:#66d9ef">int</span> lower, upper, step;

    lower <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; <span style="color:#75715e">/* lower limit of temp table */</span>
    upper <span style="color:#f92672">=</span> <span style="color:#ae81ff">300</span>; <span style="color:#75715e">/* upper limit of temp table */</span>
    step <span style="color:#f92672">=</span> <span style="color:#ae81ff">20</span>; <span style="color:#75715e">/* step size */</span>

    fahr <span style="color:#f92672">=</span> lower;

    <span style="color:#66d9ef">for</span> (fahr <span style="color:#f92672">=</span> lower; fahr <span style="color:#f92672">&lt;=</span> upper; fahr <span style="color:#f92672">=</span> fahr <span style="color:#f92672">+</span> step){

        celsius <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span> <span style="color:#f92672">*</span> (fahr <span style="color:#f92672">-</span> <span style="color:#ae81ff">32</span>) <span style="color:#f92672">/</span> <span style="color:#ae81ff">9</span>;
        printf(<span style="color:#e6db74">&#34;%d</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">%d</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, fahr, celsius);
    }

}
</code></pre></div><pre><code>0	-17
20	-6
40	4
60	15
80	26
100	37
120	48
140	60
160	71
180	82
200	93
220	104
240	115
260	126
280	137
300	148
</code></pre>
<h1 id="arrays">Arrays</h1>
<h2 id="character-arrays">Character Arrays</h2>
<p>In this next section, we will focus on arrays and their implementation in C. This brings up an interesting topic: there is no such thing as a string at this level, rather, strings are implemented as arrays of characters. So we can defined a string by defining an array and assigning its elements as the characters of string like &lsquo;bananas&rsquo;.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdio.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>() {

    <span style="color:#66d9ef">char</span> mystr[<span style="color:#ae81ff">7</span>] <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;bananas&#34;</span>;
    printf(<span style="color:#e6db74">&#34;The size of &#39;%s&#39; is %zu byte(s)</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, mystr, <span style="color:#66d9ef">sizeof</span>(mystr));

}
</code></pre></div><pre><code>The size of 'bananas' is 7 byte(s)
</code></pre>
<h2 id="integer-arrays">Integer Arrays</h2>
<p>Arrays of integers are defined in a similar way; however, you cannot print the entire array as we did with the character array above. You have to iterate through the array and call printf() for each element.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdio.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>() {

    <span style="color:#66d9ef">int</span> ndigits <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>;
    <span style="color:#66d9ef">int</span> i;
    <span style="color:#66d9ef">int</span> digits[ndigits];

    <span style="color:#66d9ef">for</span> (i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;=</span> ndigits; i<span style="color:#f92672">++</span>){

        digits[i] <span style="color:#f92672">=</span> i;
        printf(<span style="color:#e6db74">&#34;%d</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, digits[i]);

    }    
}
</code></pre></div><pre><code>0
1
2
3
4
5
</code></pre>
<h1 id="control-flow">Control Flow</h1>
<p>Another indispensible tool in C programming is the use of control-flow that will determine the behavior of the program given certain inputs. One useful example of this involves using control flow to determine whether a variable is an integer or alphabetical character. This kind of control flow could be very useful when reading raw data from files and parsing the content.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdio.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;ctype.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>(){

   <span style="color:#66d9ef">int</span> var1 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;a&#39;</span>;
   <span style="color:#66d9ef">int</span> var2 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;5&#39;</span>;


   <span style="color:#75715e">/* Check variable 1 */</span>
   <span style="color:#66d9ef">if</span>(isdigit(var1)) {
      printf(<span style="color:#e6db74">&#34;var1 = |%c| is a digit</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, var1);
   } <span style="color:#66d9ef">else</span> <span style="color:#66d9ef">if</span> (isalpha(var1)){
      printf(<span style="color:#e6db74">&#34;var1 = |%c| is an alphabetical character</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, var1);
   }

   <span style="color:#75715e">/* Check variable 2 */</span>
   <span style="color:#66d9ef">if</span>(isdigit(var2)){
      printf(<span style="color:#e6db74">&#34;var2 = |%c| is a digit</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, var2);
   } <span style="color:#66d9ef">else</span> <span style="color:#66d9ef">if</span> (isalpha(var2)){
      printf(<span style="color:#e6db74">&#34;var2= |%c| is an alphabetical character</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, var2);
   }
}
</code></pre></div><pre><code>var1 = |a| is an alphabetical character
var2 = |5| is a digit
</code></pre>
<h1 id="functions--arguments">Functions &amp; Arguments</h1>
<p>I really like how the C Programming Language textbook describes the philosophy of a function. The author writes: &ldquo;With properly defined functions, it is possible to ignore <em>how</em> a job is done; knowing <em>what</em> is done is sufficient. Thus far, we&rsquo;ve utilized functions like printf(), isdigit(), etc.; now, we&rsquo;d like to define some functions of our own. When defining user functions in C, we have to use a <em>function prototype</em> which is typically one line of code that includes three things: the function&rsquo;s return type, name, and arguments. For example if we want to define a function that performs multiplication, it&rsquo;s prototype would look like: float sqrt(float m, float n);. Then, we can write out the body of the function and invoke it in main.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdio.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
<span style="color:#66d9ef">float</span> <span style="color:#a6e22e">mult</span>(<span style="color:#66d9ef">float</span> m, <span style="color:#66d9ef">float</span> n);

<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>(){

    <span style="color:#66d9ef">float</span> m, n, p;
    m <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>;
    n <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>;
    p <span style="color:#f92672">=</span> mult(m,n);
    printf(<span style="color:#e6db74">&#34;The product is: %f&#34;</span>, p);

}

<span style="color:#66d9ef">float</span> <span style="color:#a6e22e">mult</span>(<span style="color:#66d9ef">float</span> m, <span style="color:#66d9ef">float</span> n){

    <span style="color:#66d9ef">float</span> p;
    p <span style="color:#f92672">=</span> m<span style="color:#f92672">*</span>n;
    <span style="color:#66d9ef">return</span>(p);


}
</code></pre></div><pre><code>The product is: 10.000000
</code></pre>
<h1 id="pointers-and-address-arithmetic">Pointers and Address Arithmetic</h1>
<h1 id="pointers">Pointers</h1>
<p>A pointer in C is a variable that contains the address of another variable. To really understand pointers and why
they are useful, it is necessary to understand how RAM in a computer is organized. RAM is typically an array of memory cells which are numbered consecutively. That address is usually in hexadecimal format. To define a pointer, we precede the pointer name with an asterisk. If b is the variable containing the pointer and type is the data type of the variable that b will point to. For example, we can assign the address of a variable a to another variable b. Also, we can access and modify what is stored in a via the <em>indirection</em> or <em>dereferencing</em> operator This is best shown by example:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdio.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>

<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>(){

    <span style="color:#66d9ef">int</span> a, c, <span style="color:#f92672">*</span>b;

    a <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>;
    b <span style="color:#f92672">=</span> <span style="color:#f92672">&amp;</span>a;

    printf(<span style="color:#e6db74">&#34;The variable a is located at: %p</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, b);
    printf(<span style="color:#e6db74">&#34;The contents of a is: %d</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, <span style="color:#f92672">*</span>b);

    c <span style="color:#f92672">=</span> <span style="color:#f92672">*</span>b;
    <span style="color:#f92672">*</span>b <span style="color:#f92672">+=</span> <span style="color:#ae81ff">5</span>;
    <span style="color:#f92672">++*</span>b;

    printf(<span style="color:#e6db74">&#34;The contents of a is: %d</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, <span style="color:#f92672">*</span>b);
    printf(<span style="color:#e6db74">&#34;The contents of c is: %d&#34;</span>, c);

}

</code></pre></div><pre><code>The variable a is located at: 0x7ffe7b87f988
The contents of a is: 5
The contents of a is: 11
The contents of c is: 5
</code></pre>
<p>As you can see, we can assign the address of a to the pointer b. Then, we can copy what is contained in a to another variable c by using the indirection operator. After that, we modify a using the same operator, keeping c intact. Moving on, pointers become especially important when passing variables to a function you want to modify the original variables. In C, arguments are passed to functions <em>by value</em> meaning that when you pass, say, an integer to a function you pass only a <em>copy</em> of that integer to the function. Therefore, the function has no way of modifying the variable itself. There is a good example of how to reconcile this issue with pointers in the C Programming Language textbook. We will define a function swap(), which will take to variables and swap their values. First, we will try it the wrong way and then we will show how pointers make it work correctly.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdio.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
<span style="color:#66d9ef">void</span> <span style="color:#a6e22e">swap</span>(<span style="color:#66d9ef">int</span> x, <span style="color:#66d9ef">int</span> y){

    <span style="color:#66d9ef">int</span> temp;
    temp <span style="color:#f92672">=</span> x;
    x <span style="color:#f92672">=</span> y;
    y <span style="color:#f92672">=</span> temp;

}


<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>(){

    <span style="color:#66d9ef">int</span> x,y;
    x <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>;
    y <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>;

    swap(x, y);
    printf(<span style="color:#e6db74">&#34;The variable x contains: %d</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, x);
    printf(<span style="color:#e6db74">&#34;The variable y contains: %d</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, y);

}
</code></pre></div><pre><code>The variable x contains: 1
The variable y contains: 2
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c">As you can see, nothing happened. Now let<span style="color:#960050;background-color:#1e0010">&#39;</span>s try it the correct way by using pointers to x and y.
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdio.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
<span style="color:#66d9ef">void</span> <span style="color:#a6e22e">swap</span>(<span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span>px, <span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span>py){

    <span style="color:#66d9ef">int</span> temp;
    temp <span style="color:#f92672">=</span> <span style="color:#f92672">*</span>px;
    <span style="color:#f92672">*</span>px <span style="color:#f92672">=</span> <span style="color:#f92672">*</span>py;
    <span style="color:#f92672">*</span>py <span style="color:#f92672">=</span> temp;

}


<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>(){

    <span style="color:#66d9ef">int</span> x,y;
    x <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>;
    y <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>;

    swap(<span style="color:#f92672">&amp;</span>x, <span style="color:#f92672">&amp;</span>y);
    printf(<span style="color:#e6db74">&#34;The variable x contains: %d</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, x);
    printf(<span style="color:#e6db74">&#34;The variable y contains: %d</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, y);

}
</code></pre></div><pre><code>The variable x contains: 2
The variable y contains: 1
</code></pre>
<h1 id="address-arithmetic">Address Arithmetic</h1>
<p>In its most basic form, address arithmetic allows you to define a pointer to a particular location in memory and then increment that pointer to arrive at neighboring memory locations. This is especially useful if you want to allocate a block of memory addresses for storage. In the code below, we will allocate a block of memory allocbuf that will fit ALLOCSIZE characters. The user can then call the function alloc() to allocate chunks of allocbuf for their storage needs.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#define ALLOCSIZE 10000
</span><span style="color:#75715e"></span>
<span style="color:#66d9ef">static</span> <span style="color:#66d9ef">char</span> allocbuf[ALLOCSIZE]; <span style="color:#75715e">/* array of characters */</span>
<span style="color:#66d9ef">static</span> <span style="color:#66d9ef">char</span> <span style="color:#f92672">*</span>allocp <span style="color:#f92672">=</span> <span style="color:#f92672">&amp;</span>allocbuf[<span style="color:#ae81ff">0</span>]; <span style="color:#75715e">/* initialize pointer to start of allocbuf */</span>

<span style="color:#66d9ef">char</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">alloc</span>(<span style="color:#66d9ef">int</span> n){

    <span style="color:#66d9ef">if</span>(allocbuf <span style="color:#f92672">+</span> ALLOCSIZE <span style="color:#f92672">-</span> allocp <span style="color:#f92672">&gt;=</span> n){ <span style="color:#75715e">/* check if n chars will fit */</span>
        allocp <span style="color:#f92672">+=</span> n;
        <span style="color:#66d9ef">return</span> allocp <span style="color:#f92672">-</span> n;

    } <span style="color:#66d9ef">else</span> {

        <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">0</span>; <span style="color:#75715e">/* signal that there is no space */</span>
    }

}

<span style="color:#66d9ef">void</span> <span style="color:#a6e22e">afree</span>(<span style="color:#66d9ef">char</span> <span style="color:#f92672">*</span>p){

    <span style="color:#66d9ef">if</span> (p <span style="color:#f92672">&gt;=</span> allocbuf <span style="color:#f92672">&amp;&amp;</span> p <span style="color:#f92672">&lt;</span> allocbuf <span style="color:#f92672">+</span> ALLOCSIZE){

        allocp <span style="color:#f92672">=</span> p;

    }

}
</code></pre></div><p>Notice the alloc() checks first to see if n characters will fit in allocbuf. If their request can be fulfilled, n is added to the pointer allocp and allocp - n is returned so the user has the starting point for their block of memory. Recall that allocp is a global variable so successive calls to alloc() will affect allocp permanently. Finally, afree() can be used to free memory beyond a memory location p. It does this by simply reassigning the pointer allocp to the memory location beyond which memory should be freed. These functions are implemented in the standard library (but more robustly) as malloc() and free().</p>
]]></content>
        </item>
        
        <item>
            <title>Intro to FFT</title>
            <link>/posts/introduction-to-fast-fourier-transforms-fft/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/introduction-to-fast-fourier-transforms-fft/</guid>
            <description>import sys import numpy as np import matplotlib import scipy from IPython.display import Image from IPython.core.display import HTML print(&#39;Python version:\n{}\n&#39;.format(sys.version)) print(&#39;Numpy version:\t\t{}&#39;.format(np.__version__)) print(&#39;matplotlib version:\t{}&#39;.format(matplotlib.__version__)) print(&#39;Scipy version:\t\t{}&#39;.format(scipy.__version__)) Python version: 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0] Numpy version:	1.16.2 matplotlib version:	3.0.3 Scipy version:	1.2.1  Digital Signals Before we dive into the details of Fourier transformations, we need to review some fundamental concepts in signal processing. Recall that when we measure an analog signal e.</description>
            <content type="html"><![CDATA[<pre><code class="language-code" data-lang="code">import sys
import numpy as np
import matplotlib
import scipy
from IPython.display import Image
from IPython.core.display import HTML

print('Python version:\n{}\n'.format(sys.version))
print('Numpy version:\t\t{}'.format(np.__version__))
print('matplotlib version:\t{}'.format(matplotlib.__version__))
print('Scipy version:\t\t{}'.format(scipy.__version__))
</code></pre><pre><code>Python version:
3.7.3 (default, Mar 27 2019, 22:11:17)
[GCC 7.3.0]

Numpy version:		1.16.2
matplotlib version:	3.0.3
Scipy version:		1.2.1
</code></pre>
<h1 id="digital-signals">Digital Signals</h1>
<p>Before we dive into the details of Fourier transformations, we need to review some fundamental concepts in signal processing. Recall that when we measure an analog signal e.g. intensity, voltage, pressure, etc., our measurement device makes use of an Analog to Digital Converter (ADC). The ADC converts the continous time  continuous amplitude signal to a discrete time and discrete amplitude by sampling the analog signal at a frequency referred to as the <em>sampling rate</em> and quantizing the measured amplitudes.</p>
<p>If the sampling rate $f_{s}$ is not sufficiently large, we end up with a poor approximation to the original signal: high frequency components within the signal will be missed at low sampling rates. This can be made more precise by the sampling theorem which states:</p>
<p>\begin{equation*}
f_{s} &gt; 2f_{m}
\end{equation*}</p>
<p>where $f_{m}$ is the maximum frequency or that can be reliably recorded and is sometimes called the *nyquist frequency* or *folding frequency*.</p>
<h1 id="frequency-resolution-and-the-fft">Frequency Resolution and the FFT</h1>
<p>The Fast Fourier Transform (FFT) is an indispensible tool in signal processing as it allows you to decompose a signal into its frequency components. In other words, if we have a digital signal in the time domain, the FFT can convert that signal into the frequency domain. For example, in the acoustic case, the FFT could allow you to extract the frequencies of notes making up a musical chord played into a microphone. In general, for a quantized digital signal $x_{n}$ with $N$ samples the FFT is defined as:</p>
<p>\begin{equation*}
X(k) = FFT[x_{n}] = \sum_{n=0}^{N-1} x_{n}\exp{-\frac{j2\pi kn}{N}}, k=0,1,&hellip;,N-1
\end{equation*}</p>
<p>where $k$ is a discrete frequency index. For each value of $k$, we sum over all $N$ samples putting $k$ into the argument of the exponential. The resulting value is a complex number $X(k)$ of which we can calculate the magnitude:</p>
<p>\begin{equation*}
|X(k)| = \sqrt{X_{R}^{2}(k) + X_{I}^{2}(k)}
\end{equation*}</p>
<p>and phase:</p>
<p>\begin{equation*}
\phi(k) = \arctan(\frac{X_{I}(k)}{X_{R}(k)})
\end{equation*}</p>
<p>Notice that we set the number of samples for $k$ to be equal to that of $x_{n}$. Also, the frequencies start at 0Hz and increment by $k\frac{f_{s}}{{N}}$ up to $\frac{N}{N-1}f_{s}$ Hz. For example if we have a 16-point CD quality audio sample ($f_{s}$=44.1kHz), we will have a frequency spectrum from 0 to 41.3 kHz. Recall, we said that the max frequency that can be reliably detected for a given sampling rate is $f_{s} &gt; 2f_{m}$ but the FFT produces frequencies all the way up to $\frac{N}{N-1}f_{s}$ Hz. This is why the max frequency is sometimes called the folding frequency: at the point $f_{s} = 2f_{m}$, the magnitude spectrum *folds* or repeats itself. Let&rsquo;s see this in an example.</p>
<h1 id="fft-example-1">FFT Example 1</h1>
<p>In this example, we are going to define a function simple_fft() that takes in four parameters: freq, fft_size, nsamples, and period. The parameter fft_size determines the frequency resolution of the frequency domain. In general, the frequency resolution is inversely proportional to the sampling rate and directly proportional to the fft_size. Therefore, at high sampling rates, you need larger FFT sizes to accurately resolve frequency components. Let&rsquo;s use simple_fft() to generate a 100 Hz sine wave sampled at 1 kHz over 100ms and take a 2048 point FFT.</p>
<pre><code class="language-code" data-lang="code">import matplotlib.pyplot as plt
import numpy as np
from numpy.fft import fft
from scipy.signal import find_peaks

def simple_fft(freq=20,
               fft_size=2048,
               nsamples=50,
               period=1):

    sample_rate = nsamples/period
    tres = 1/sample_rate #time resolution
    fres = sample_rate/fft_size #frequency resolution

    # &quot;&quot;&quot;
    # ~~~~~~Generate signal, do FFT~~~~~
    # &quot;&quot;&quot;

    t = np.linspace(0, period, nsamples)
    x = np.sin(2*np.pi*freq*t)
    f = np.arange(fft_size)*fres
    mag = np.abs(fft(x,n=fft_size))
    peaks, props = find_peaks(mag, height=.5*mag.max())
    peaks = fres*peaks

    # &quot;&quot;&quot;
    # ~~~~~~Plot results~~~~~
    # &quot;&quot;&quot;

    fig, ax = plt.subplots(1, 2, figsize=(12,5))
    ax[0].plot(t, x)
    ax[0].set_xlabel('Time', fontsize=14)
    ax[0].set_ylabel('Amplitude', fontsize=14)
    ax[1].plot(f, mag)
    ax[1].set_xlabel('Frequency (Hz)', fontsize=14)
    ax[1].set_ylabel('a.u.', fontsize=14)
    plt.show()

    # &quot;&quot;&quot;
    # ~~~~~~Print results~~~~~
    # &quot;&quot;&quot;

    tres = tres*1e4
    mag[fft_size//2:] = 0

    print('#'*50)
    print('Time Resolution: %s ms/step' % tres)
    print('Frequency Resolution: %s Hz/step' % fres)
    print('Set Frequency: %s Hz' % freq)
    print('Measured Frequency: %s Hz' % peaks[0])


sample_rate = 1000 #Hz
period = .1 #sec
nsamples = sample_rate*period

simple_fft(freq=100,
           fft_size=2048,
           nsamples=nsamples,
           period=period)
</code></pre><pre><code>/home/cwseitz/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: object of type &lt;class 'float'&gt; cannot be safely interpreted as an integer.
</code></pre>
<p><img src="introduction-to-fast-fourier-transforms-fft_files/introduction-to-fast-fourier-transforms-fft_3_1.png" alt="png"></p>
<pre><code>##################################################
Time Resolution: 10.0 ms/step
Frequency Resolution: 0.48828125 Hz/step
Set Frequency: 100 Hz
Measured Frequency: 101.07421875 Hz
</code></pre>
<h1 id="fft-example-2">FFT Example 2</h1>
<p>This time we will use modify simple_fft() to superimpose 3 frequencies and try and resolve them in the frequency domain. Consider what happens when you play a C major triad consisting of notes C, E, and G on a piano. If we start at middle C, we are superimposing three sinusoids with fourth-order frequencies 261, 329, and 392 Hz. Let&rsquo;s take a look at these waveforms and their sum over a 10ms time window with a 44.1kHz sample rate:</p>
<pre><code class="language-code" data-lang="code">import matplotlib.pyplot as plt
import numpy as np
from numpy.fft import fft

def simple_fft(freq=[10, 20, 30],
               fft_size=2048,
               nsamples=50,
               period=1):

    sample_rate = nsamples/period
    tres = 1/sample_rate #time resolution
    fres = sample_rate/fft_size #frequency resolution

    # &quot;&quot;&quot;
    # ~~~~~~Generate signal, do FFT~~~~~
    # &quot;&quot;&quot;

    t = np.linspace(0, period, nsamples)
    x = np.sin(2*np.pi*freq[0]*t) + np.sin(2*np.pi*freq[1]*t) + np.sin(2*np.pi*freq[2]*t)
    f = np.arange(fft_size)*fres
    mag = np.abs(fft(x,n=fft_size))/fft_size
    peaks, props = find_peaks(mag, height=.5*mag.max())
    peaks = fres*peaks

    # &quot;&quot;&quot;
    # ~~~~~~Plot results~~~~~
    # &quot;&quot;&quot;

    fig, ax = plt.subplots(1, 2, figsize=(12,5))
    ax[0].plot(t, x)
    ax[0].set_xlabel('Time', fontsize=14)
    ax[0].set_ylabel('Amplitude', fontsize=14)
    ax[1].plot(f, mag)
    ax[1].set_xlabel('Frequency (Hz)', fontsize=14)
    ax[1].set_ylabel('a.u.', fontsize=14)
    plt.show()

    # &quot;&quot;&quot;
    # ~~~~~~Print results~~~~~
    # &quot;&quot;&quot;

    tres = tres*1e4
    mag[fft_size//2:] = 0

    print('#'*50)
    print('Time Resolution: %s ms/step' % tres)
    print('Frequency Resolution: %s Hz/step' % fres)
    print('Set Frequencies: %s Hz' % freq)
    print('Measured Frequencies: %s Hz' % peaks)


sample_rate = 1000 #Hz
period = .1 #sec
nsamples = sample_rate*period

simple_fft(freq=[261,329,392],
           fft_size=2048,
           nsamples=nsamples,
           period=period)
</code></pre><pre><code>/home/cwseitz/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: object of type &lt;class 'float'&gt; cannot be safely interpreted as an integer.
</code></pre>
<p><img src="introduction-to-fast-fourier-transforms-fft_files/introduction-to-fast-fourier-transforms-fft_5_1.png" alt="png"></p>
<pre><code>##################################################
Time Resolution: 10.0 ms/step
Frequency Resolution: 0.48828125 Hz/step
Set Frequencies: [261, 329, 392] Hz
Measured Frequencies: [263.18359375 332.51953125 396.484375   603.515625   667.48046875
 736.81640625] Hz
</code></pre>
]]></content>
        </item>
        
        <item>
            <title>Langevin dynamics</title>
            <link>/posts/brownian-motion-the-langevin-equation/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/brownian-motion-the-langevin-equation/</guid>
            <description>Introduction In this post I would like to model the interaction of a particle with its environment. In principle, if we could specify all the forces on a particle by its environment in a deterministic way, we could just add up all the components of the forces and write Newton&amp;rsquo;s law of motion and solve. In the real world, we have no way of predicted those forces and have to use a stochastic variant of Newton&amp;rsquo;s law of motion called the Langevin equation.</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>In this post I would like to model the interaction of a particle with its environment. In principle, if we could specify all the forces on a particle by its environment in a deterministic way, we could just add up all the components of the forces and write Newton&rsquo;s law of motion and solve. In the real world, we have no way of predicted those forces and have to use a stochastic variant of Newton&rsquo;s law of motion called the <strong>Langevin equation</strong>.</p>
<h1 id="the-langevin-equation">The Langevin Equation</h1>
<p>The Langevin equation is a first-order differential equation which predicts the diffusion of a particle experiencing friction as well as a stochastic driving force. As stated above, it is a modified form of Newton&rsquo;s equation of motion:</p>
<p>\begin{align}
m\frac{dv}{dt} = \xi (t) - \gamma v(t)
\end{align}</p>
<p>The first term in the Langevin equation $\xi(t)$ is a stochastic force (which will be shown to be normally distributed) and the second term $\gamma v(t)$ is a damping force proportional to the velocity of the particle. To better understand it, let&rsquo;s subject it to different conditions and take a look at its solution.</p>
<h1 id="the-damped-solution">The Damped Solution</h1>
<p>First, we consider the the simplest possible case by setting $\xi (t) = 0$ for all $t$. This reduces the Langevin equation to a form for which the solution is already known:</p>
<p>\begin{equation*}
\frac{dv}{dt} = \frac{\gamma}{m} v(t) \rightarrow v(t) = v(0)  e^{-\frac{t}{\tau_{B}}}
\end{equation*}</p>
<p>It is common to refer the ratio $\frac{m}{\gamma}$ as the Brownian timescale for relaxation, $\tau_{B}$. From our solution, we see that, in the presence of damping, $v \rightarrow 0$ as $t \rightarrow \infty$. Short and sweet!</p>
<h1 id="the-dampeddriven-solution">The Damped/Driven Solution</h1>
<p>Our satisfaction from the damped solution may be premature if we want to consider a realistic scenario. If our particle is in thermal equilibium with some kind of bath at non-zero temperature, it should be occasionally be kicked around by other particles. From thermodynamics, we know that the average velocity of a particle as a function of temperature is given by the equipartition theorem:</p>
<p>\begin{equation*}
\langle v^{2}(t) \rangle \propto \frac{k_{B}T}{m}
\end{equation*}</p>
<p>But when we average the square of our solution to the Langevin equation:</p>
<p>\begin{equation*}
\langle v^{2}(t) \rangle = \frac{1}{t} \int_{0}^{t} v^{2}(0)  e^{-2\frac{t}{\tau_{B}}}dt = \frac{\tau_{B}v_{0}^{2}}{2t}(1 - e^{-2\frac{t}{\tau_{B}}})
\end{equation*}</p>
<p>which goes to zero at long times. We can speculate that $\xi (t)$, which we have ignored in this case, is what reconciles this conflict by representing the interaction of the particle with a thermal bath. So, we proceed by lifting our constraint that $\xi(t) = 0$ but we still need more information about it. We can usually make the following assumptions:</p>
<ol>
<li>$\langle \xi(t) \rangle = 0$</li>
<li>It is independent of position - the iteraction with its environment is the same everywhere</li>
<li>$\xi(t)$ is not correlated with itself at very short time-spans.</li>
</ol>
<p>We can find the driven-damped solution by adding to the damped solution a series of infinitesimal kicks, each of which then decays with time. An integral sums over all those kicks, weighting each one by an exponential factor based on the time t−s that has passed since it occurred.</p>
<p>\begin{equation*}
v(t) = v(0)  e^{-\frac{t}{\tau_{B}}} + \frac{1}{m}\int_{0}^{t} \xi(s)e^{-(t-s)/\tau_{B}}ds
\end{equation*}</p>
<p>As before, we can use the equipartition theorem but we first need $\langle v^{2}(t) \rangle$:</p>
<p>\begin{equation*}
\langle v^{2}(t) \rangle = \frac{1}{m}\int_{0}^{t} \xi(s)e^{-(t-s)/\tau_{B}}ds
\end{equation*}</p>
<p>\begin{equation*}
lim_{t \to \infty} \langle v^2(t) \rangle = \frac{1}{m^2} \int_0^{\infty} \int_0^{\infty} e^{-\frac{\gamma}{m}(2t-t&rsquo;-t&rsquo;')} \langle \xi(t&rsquo;)\xi(t&rsquo;') \rangle dt&rsquo; dt&rsquo;&rsquo;
\end{equation*}</p>
<p>\begin{split}\begin{array}{rcl}
lim_{t \to \infty} \langle v^2(t) \rangle &amp;=&amp; \frac{1}{m^2} \int_{r=0}^{\infty} \int_{s=-\infty}^{\infty} e^{-\frac{\gamma}{m}(2r+s)} \langle \xi(0)\xi(s) \rangle dr ds \<br>
&amp;=&amp; \frac{1}{m^2} \left( \int_0^{\infty} e^{-\frac{\gamma}{m}2r} dr \right) \left( \int_{-\infty}^{\infty} e^{-\frac{\gamma}{m}s} \langle \xi(0)\xi(s) \rangle ds \right) \<br>
&amp;=&amp; \frac{1}{2 \gamma m} \int_{-\infty}^{\infty} e^{-\frac{\gamma}{m}s} \langle \xi(0)\xi(s) \rangle ds
\end{array}\end{split}</p>
<p>If we make the additional assumption that the timescale over which the random force is correlated with itself is much smaller than $\tau_{B}$ - the timescale on which friction operates, then we can make a further simplification:</p>
<p>\begin{equation*}
2 \gamma kT = \int_{-\infty}^{\infty} \langle R(0)R(s) \rangle ds
\end{equation*}</p>
<p>This result is called the <em>fluctuation-dissipation theorem</em> which relates $T, \gamma, and \xi$. Any system in contact with a heat bath will experience both a stochastic force and friction - you cannot have one without the other.</p>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Learning-theory</title>
            <link>/posts/learning-theory/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/learning-theory/</guid>
            <description>Free lunch A prominent question in deep learning is whether or not a universal learning algorithm exists. Many have argued for the no free lunch theorem which argues that there must be some innate system in biological brains that facilitates interpretation of natural language. In other words there must be some constraint on the space of functions of the input.
On the other hand, the free lunch theorem says that there need not be such a bias or constraint on the space of possible functions.</description>
            <content type="html"><![CDATA[<h3 id="free-lunch">Free lunch</h3>
<p>A prominent question in deep learning is whether or not a universal learning algorithm exists. Many have argued for the no free lunch theorem which argues that there must be some innate system in biological brains that facilitates interpretation of natural language. In other words there must be some constraint on the space of functions of the input.</p>
<p>On the other hand, the free lunch theorem says that there need not be such a bias or constraint on the space of possible functions. Rather, the function is completely random</p>
<h3 id="frequentist-vs-bayesian">Frequentist vs. Bayesian</h3>
<p>It will be important to distinguish the frequentist and bayesian points of view. Frequentist guarantees don&rsquo;t make any assumptions about the prior distribution over the models while bayesian methods do assume a prior distribution.</p>
<h3 id="the-occam-guarantee">The Occam guarantee</h3>
<p>Consider a classifier $f$ written in a programming language of your choice and let $|f|$ be the number of bits needed to represent $f$. We have the following usual expressions for the test and training loss</p>
<p>\begin{eqnarray*}
{\cal L}(f)  &amp; = &amp;  E_{(x,y)\sim \mathrm{Pop}};{\cal L}(f,x,y) \<br>
\hat{{\cal L}}(f) &amp; = &amp; E_{(x,y)\sim \mathrm{Train}};{\cal L}(f,x,y)
\end{eqnarray*}</p>
<p>where ${\cal L}(f)$ is the expectation of the loss over the entire population and $\hat{{\cal L}}(f)$ is the expectation over the training subset. The Occam guarantee tells us that there is an upper bound on the expected loss computed over the entire population. That upper bound is a function of the expected loss on the training subset. This has implications for generalization after training on only a subset of the population.</p>
<p>$${\cal L}(f) \leq \frac{10}{9}\left(\hat{{\cal L}}(f) + \frac{5L_{max}}{N_\mathrm{Train}}\left((\ln 2)|f| +\ln\frac{1}{\delta}\right)\right)$$</p>
<p>Notice the penalty term which is a function of the number of bits to encode our classifier (thanks Occam). Further, we can write this guarantee in a probabilistic form where we replace the number of bits used to represent the classifier in a particular language with a prior probability over the space of possible functions</p>
<p>\begin{eqnarray*}
{\cal L}(f) \leq \frac{10}{9}{\hat{\cal L}(f) + \frac{5 L_\mathrm{max}}{N_\mathrm{Train}}{- \ln \delta P(f)}}
\end{eqnarray*}</p>
<p>so we find the optimum $h$ by driving the training loss + penalty towards this lower bound</p>
<p>\begin{eqnarray*}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
f^* &amp; = &amp; {\argmin_f \hat{\cal L}(f) + \frac{5 L_\mathrm{max}}{N_\mathrm{Train}}{- \ln P(f)}}
\end{eqnarray*}</p>
<p>Importantly, the Occam guarantee doesn&rsquo;t make any assumptions about the prior $P(f)$ as we did in the Bayesian approach for regularization. That is, it doesn&rsquo;t assume that the sample was generated by drawing a function from the prior and then generating the sample from the function.</p>
<h3 id="pac-bayes-guarantee">PAC-Bayes guarantee</h3>
<p>A major problem with the Occam guarantee is that it assumes we can write down the number of bits it takes to construct a model i.e. the space of models is discrete. For continuous models, we can no longer specify how many bits it takes to encode a model $f$.</p>
<p>For a posterior (informed) distribution over the space of models $q$ from which we can draw a model $f$</p>
<p>For the entire population,</p>
<p>\begin{eqnarray*}
L(q) &amp; =  &amp;E_{f \sim q}{L(f)} \<br>
\end{eqnarray*}</p>
<p>and for the training set</p>
<p>\begin{eqnarray*}
\hat{L}(q) &amp; =  &amp;E_{f \sim q}{\hat{L}(f)}
\end{eqnarray*}</p>
<p>and we ultimately want to modify the prior distribution to approximate the posterior with our training data. The PAC-Bayes guarantee tells us that</p>
<p>$$L(q) \leq \frac{1}{1-\frac{1}{2\lambda}}({\hat{L}(q) + \frac{\lambda L_{max}}{N_\mathrm{Train}}){KL(q,p) + \ln \frac{1}{\delta}}}$$</p>
<p>This is the bound that is compatible with deep learning because we are always learning continuous parameters.</p>
<h3 id="example">Example</h3>
<p>Let us take the case where the prior is a Gaussian centered around the initialization point $\Phi_{init}$ and the posterior is also a Gaussian centered around some other point in the space of models.</p>
<h3 id="implicit-regularization">Implicit regularization</h3>
<h3 id="double-descent">Double descent</h3>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Matplotlib colormaps</title>
            <link>/posts/matplotlib-colormaps/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/matplotlib-colormaps/</guid>
            <description>Choosing a colormap in Matplotlib   Sequential: change in lightness and often saturation of color incrementally, often using a single hue; should be used for representing information that has ordering.
  Diverging: change in lightness and possibly saturation of two different colors that meet in the middle at an unsaturated color; should be used when the information being plotted has a critical middle value, such as topography or when the data deviates around zero</description>
            <content type="html"><![CDATA[<h1 id="choosing-a-colormap-in-matplotlib">Choosing a colormap in Matplotlib</h1>
<ol>
<li>
<p><strong>Sequential</strong>: change in lightness and often saturation of color incrementally, often using a single hue; should be used for representing information that has ordering.</p>
</li>
<li>
<p><strong>Diverging</strong>: change in lightness and possibly saturation of two different colors that meet in the middle at an unsaturated color; should be used when the information being plotted has a critical middle value, such as topography or when the data deviates around zero</p>
</li>
<li>
<p><strong>Cyclic</strong>: change in lightness of two different colors that meet in the middle and beginning/end at an unsaturated color; should be used for values that wrap around at the endpoints, such as phase angle, wind direction, or time of day.</p>
</li>
<li>
<p><strong>Qualitative</strong>: often are miscellaneous colors; should be used to represent information which does not have ordering or relationships.</p>
</li>
</ol>
<p>**Note: The above paragraph and code snippets below were derived from <a href="https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html">here</a></p>
<pre><code class="language-code" data-lang="code">import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib import cm
from collections import OrderedDict

cmaps = OrderedDict()
def plot_color_gradients(cmap_category, cmap_list, nrows):
    fig, axes = plt.subplots(nrows=nrows)
    fig.subplots_adjust(top=0.95, bottom=0.01, left=0.2, right=0.99)
    axes[0].set_title(cmap_category + ' colormaps', fontsize=14)

    for ax, name in zip(axes, cmap_list):
        ax.imshow(gradient, aspect='auto', cmap=plt.get_cmap(name))
        pos = list(ax.get_position().bounds)
        x_text = pos[0] - 0.01
        y_text = pos[1] + pos[3]/2.
        fig.text(x_text, y_text, name, va='center', ha='right', fontsize=10)

    # Turn off *all* ticks &amp; spines, not just the ones with colormaps.
    for ax in axes:
        ax.set_axis_off()

</code></pre><h1 id="sequential-colormaps">Sequential Colormaps</h1>
<pre><code class="language-code" data-lang="code">cmaps['Sequential'] = [
                        'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds',
                        'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu',
                        'GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn'
                      ]
</code></pre><pre><code class="language-code" data-lang="code">nrows = max(len(cmap_list) for cmap_category, cmap_list in cmaps.items())
gradient = np.linspace(0, 1, 256)
gradient = np.vstack((gradient, gradient))

for cmap_category, cmap_list in cmaps.items():
    plot_color_gradients(cmap_category, cmap_list, nrows)
</code></pre><p><img src="matplotlib-colormaps_files/matplotlib-colormaps_4_0.png" alt="png"></p>
<h1 id="more-sequential-colormaps">More Sequential Colormaps</h1>
<pre><code class="language-code" data-lang="code">cmaps = OrderedDict()
cmaps['Sequential (2)'] = [
                        'binary', 'gist_yarg', 'gist_gray', 'gray', 'bone', 'pink',
                        'spring', 'summer', 'autumn', 'winter', 'cool', 'Wistia',
                        'hot', 'afmhot', 'gist_heat', 'copper'
                          ]

nrows = max(len(cmap_list) for cmap_category, cmap_list in cmaps.items())
gradient = np.linspace(0, 1, 256)
gradient = np.vstack((gradient, gradient))

for cmap_category, cmap_list in cmaps.items():
    plot_color_gradients(cmap_category, cmap_list, nrows)
</code></pre><p><img src="matplotlib-colormaps_files/matplotlib-colormaps_6_0.png" alt="png"></p>
<h1 id="diverging-colormaps">Diverging Colormaps</h1>
<pre><code class="language-code" data-lang="code">cmaps = OrderedDict()
cmaps['Diverging'] = [
                        'PiYG', 'PRGn', 'BrBG', 'PuOr', 'RdGy', 'RdBu',
                        'RdYlBu', 'RdYlGn', 'Spectral', 'coolwarm', 'bwr', 'seismic'
                     ]

nrows = max(len(cmap_list) for cmap_category, cmap_list in cmaps.items())
gradient = np.linspace(0, 1, 256)
gradient = np.vstack((gradient, gradient))

for cmap_category, cmap_list in cmaps.items():
    plot_color_gradients(cmap_category, cmap_list, nrows)
</code></pre><p><img src="matplotlib-colormaps_files/matplotlib-colormaps_8_0.png" alt="png"></p>
<h1 id="cyclic-colormaps">Cyclic Colormaps</h1>
<pre><code class="language-code" data-lang="code">cmaps = OrderedDict()
cmaps['Cyclic'] = ['twilight', 'twilight_shifted', 'hsv']

nrows = max(len(cmap_list) for cmap_category, cmap_list in cmaps.items())
gradient = np.linspace(0, 1, 256)
gradient = np.vstack((gradient, gradient))

for cmap_category, cmap_list in cmaps.items():
    plot_color_gradients(cmap_category, cmap_list, nrows)
</code></pre><p><img src="matplotlib-colormaps_files/matplotlib-colormaps_10_0.png" alt="png"></p>
<h1 id="qualitative-colormaps">Qualitative Colormaps</h1>
<pre><code class="language-code" data-lang="code">cmaps = OrderedDict()
cmaps['Qualitative'] = [
                        'Pastel1', 'Pastel2', 'Paired', 'Accent',
                        'Dark2', 'Set1', 'Set2', 'Set3',
                        'tab10', 'tab20', 'tab20b', 'tab20c'
                       ]

nrows = max(len(cmap_list) for cmap_category, cmap_list in cmaps.items())
gradient = np.linspace(0, 1, 256)
gradient = np.vstack((gradient, gradient))

for cmap_category, cmap_list in cmaps.items():
    plot_color_gradients(cmap_category, cmap_list, nrows)
</code></pre><p><img src="matplotlib-colormaps_files/matplotlib-colormaps_12_0.png" alt="png"></p>
<h1 id="miscellaneous-colormaps">Miscellaneous Colormaps</h1>
<pre><code class="language-code" data-lang="code">cmaps = OrderedDict()
cmaps['Miscellaneous'] = [
                        'flag', 'prism', 'ocean', 'gist_earth', 'terrain', 'gist_stern',
                        'gnuplot', 'gnuplot2', 'CMRmap', 'cubehelix', 'brg',
                        'gist_rainbow', 'rainbow', 'jet', 'nipy_spectral', 'gist_ncar'
                         ]

nrows = max(len(cmap_list) for cmap_category, cmap_list in cmaps.items())
gradient = np.linspace(0, 1, 256)
gradient = np.vstack((gradient, gradient))

for cmap_category, cmap_list in cmaps.items():
    plot_color_gradients(cmap_category, cmap_list, nrows)
</code></pre><p><img src="matplotlib-colormaps_files/matplotlib-colormaps_14_0.png" alt="png"></p>
<p>To make use of one of the above colormaps, we can create a numpy linspace object with min_color, max_color and num_color parameters. This allows to slice the colormap and choose how many colors to choose in the slice.</p>
<pre><code class="language-code" data-lang="code">fig, ax = plt.subplots()
viridis = cm.get_cmap('rainbow', 12)
color_ind = np.linspace(0, 0.5, 3)
min_color = 0; max_color = 1; num_color = 5
x = np.linspace(min_color, max_color, num_color)
y = [x, 2*x, 3*x]

viridis = viridis(color_ind)
for i,j in enumerate(y):
    ax.plot(x,j, color=viridis[i])
plt.show()
</code></pre><p><img src="matplotlib-colormaps_files/matplotlib-colormaps_16_0.png" alt="png"></p>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>MSD in different scenarios</title>
            <link>/posts/mean-squared-displacement-msd-in-different-scenarios/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/mean-squared-displacement-msd-in-different-scenarios/</guid>
            <description>The Diffusion Equation In order to adequately describe a system of diffusing particles, we need to specify the density of particles at each point in space and how that density changes with time. In more mathematical terms, we must specify the surface $\rho(x,t)$ which $x$ is an arbitrary dimension of space. This surface can be found by solving the diffusion equation, a partial differential equation that relates the time derivative of the density of particles to the second spatial derivative of the density:</description>
            <content type="html"><![CDATA[<h1 id="the-diffusion-equation">The Diffusion Equation</h1>
<p>In order to adequately describe a system of diffusing particles, we need to specify the density of particles at each point in space and how that density changes with time. In more mathematical terms, we must specify the surface $\rho(x,t)$ which $x$ is an arbitrary dimension of space. This surface can be found by solving the <em>diffusion equation</em>, a partial differential equation that relates the time derivative of the density of particles to the second spatial derivative of the density:</p>
<p>\begin{align}
\frac{\partial\rho}{\partial t} = D\frac{\partial^{2}\rho}{\partial x^{2}}
\end{align}</p>
<p>where $D$ is the so-called diffusion coefficient. In Einstein&rsquo;s paper on Brownian motion, he showed that a solution to the diffusion equation was:</p>
<p>\begin{align}
\rho (x,t) = \frac{1}{\sqrt{4\pi Dt}}\exp{\frac{-x^{2}}{4Dt}}
\end{align}</p>
<p>which can be confirmed by plugging in $\rho(t)$ to both sides of the diffusion equation. Let&rsquo;s take a look at the time dependence of this distribution:</p>
<pre><code class="language-code" data-lang="code">import matplotlib.pyplot as plt
import numpy as np
from scipy.integrate import quad

def gaussian(x, t, D=1):
    a = 1/np.sqrt(4*np.pi*D*t)
    return a*np.exp(-(x**2)/(4*D*t))


D = 1
x = np.linspace(-10, 10, 1000)
t = np.linspace(1, 10, 10)

for t_i in t:
    g = gaussian(x, t_i, D)
    plt.plot(x,g)
    int_params = quad(gaussian, -np.inf, np.inf, args=(t_i, D))
    print('The integral is: %s' % str(round(int_params[0], 2)))

plt.show()
</code></pre><pre><code>The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
</code></pre>
<p><img src="mean-squared-displacement-msd-in-different-scenarios_files/mean-squared-displacement-msd-in-different-scenarios_1_1.png" alt="png"></p>
<h1 id="brownian-msd">Brownian MSD</h1>
<p>Furthermore, the mean squared displacement (MSD) could be derived from this result by first starting with the definition of MSD:</p>
<p>\begin{align}
\mathbf{MSD(t)} = \langle (x - x_{0})^{2} \rangle
\end{align}</p>
<p>if we expand this definition we have:</p>
<p>\begin{align}
\mathbf{MSD(t)} = \langle x^{2} \rangle + \langle x_{0}^{2} \rangle - 2x_{0}\langle x \rangle
\end{align}</p>
<p>Assuming $x_{0} = 0$, we can simply calculate $\langle x^{2} \rangle$ and $\langle x \rangle$, and we will be left with an analytical expression for the MSD for a particle undergoing Brownian motion. Let&rsquo;s start with $\langle x^{2} \rangle$:</p>
<p>\begin{align}
\langle x^{2} \rangle = \frac{1}{\sqrt{4\pi Dt}}\int_{-\infty}^{+\infty} x^{2}\exp{\frac{-x^{2}}{4Dt}}dx
\end{align}</p>
<p>It can be shown that a general solution to an equation of this form is:</p>
<p>\begin{align}
\int_{-\infty}^{+\infty} x^{2}\exp{-sx^{2}}dx = \frac{\sqrt{\pi}}{2}s^{\frac{-3}{2}}
\end{align}</p>
<p>Utilizing that result, we see that the solution for our case is:</p>
<p>\begin{align}
\langle x^{2} \rangle = \frac{\sqrt{\pi}}{2}\frac{(4Dt)^{\frac{-3}{2}}}{(4\pi Dt)^{\frac{1}{2}}} = 2Dt
\end{align}</p>
<p>In the end, we are left with the following expression for the MSD:</p>
<p>\begin{align}
\mathbf{MSD(t)} = 2Dt
\end{align}</p>
<h1 id="brownian-msd-with-drift">Brownian MSD with Drift</h1>
<p>The probability distribution for particle position in the presence of brownian motion + drift is the first case we will see where the MSD is not a linear function of time. Drift is defined as translation at a constant velocity which means the distribution is no longer centered around $x = 0$ for all $t$. Rather, the distribution is centered around the position $vt$ where $v$ is the drift velocity. The modified distribution looks like this:</p>
<p>\begin{align}
\rho (x,t) = \frac{1}{\sqrt{4\pi Dt}}\exp{\frac{-(x-vt)^{2}}{4Dt}}
\end{align}</p>
<pre><code class="language-code" data-lang="code">import matplotlib.pyplot as plt
import numpy as np

def gaussian(x, t, D=1):
    a = 1/np.sqrt(4*np.pi*D*t)
    return a*np.exp(-(x**2)/(4*D*t))

D = 1; v = 1
x = np.linspace(-10, 20, 1000)
t = np.linspace(1, 10, 10)

for t_i in t:
    g = gaussian(x-v*t_i, t_i, D)
    plt.plot(x,g)
    int_params = quad(gaussian, -np.inf, np.inf, args=(t_i, D))
    print('The integral is: %s' % str(round(int_params[0], 2)))

plt.show()
</code></pre><pre><code>The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
The integral is: 1.0
</code></pre>
<p><img src="mean-squared-displacement-msd-in-different-scenarios_files/mean-squared-displacement-msd-in-different-scenarios_4_1.png" alt="png"></p>
<p>Clearly, the distribution widens and translates to the right as time progresses. Now, if we once again calculate $\langle x^{2} \rangle$:</p>
<p>\begin{align}
\langle x^{2} \rangle = \frac{1}{\sqrt{4\pi Dt}}\int_{-\infty}^{+\infty} x^{2}\exp{\frac{-(x-vt)^{2}}{4Dt}}dx
\end{align}</p>
<p>If we make the substitution $u = x-vt$, we can rewrite the integral as:</p>
<p>\begin{align}
\langle x^{2} \rangle = \frac{1}{\sqrt{4\pi Dt}}\int_{-\infty}^{+\infty} (u+vt)^{2}\exp{\frac{-u^{2}}{4Dt}}dx
\end{align}</p>
<p>If we expand out the $(u+vt)^{2}$ term, we will be left with three integrals. The first will be the same problem we solved above with a change of variables, the second will be zero (it is a product of even and odd functions), and the third integral $\frac{1}{\sqrt{4\pi Dt}}\int_{-\infty}^{+\infty} v^{2}t^{2}\exp{\frac{-u^{2}}{4Dt}}du = v^{2}t^{2}$ since the distribution is normalized. To summarize, in the presence of constant drift, the MSD has the form:</p>
<p>\begin{align}
\mathbf{MSD(t)} = 2Dt + v^{2}t^{2}
\end{align}</p>
<p>Since it&rsquo;s not as obvious what this function looks like, let&rsquo;s plot it.</p>
<pre><code class="language-code" data-lang="code">import matplotlib.pyplot as plt
import numpy as np

def msd_drift(t, v_drift, diff_coeff):
    return 2*diff_coeff*t + (v_drift**2)*(t**2)

t = np.linspace(0, 10, 100)
v_drifts = np.arange(1, 5, 1)
diff_coeffs = np.arange(1, 5, 1)

for diff_coeff in diff_coeffs:
    plt.plot(t, msd_drift(t, v_drifts[0], diff_coeff))
plt.show()

for v_drift in v_drifts:
    plt.plot(t, msd_drift(t, v_drift, diff_coeffs[0]))
plt.show()
</code></pre><p><img src="mean-squared-displacement-msd-in-different-scenarios_files/mean-squared-displacement-msd-in-different-scenarios_6_0.png" alt="png"></p>
<p><img src="mean-squared-displacement-msd-in-different-scenarios_files/mean-squared-displacement-msd-in-different-scenarios_6_1.png" alt="png"></p>
<h1 id="anomalous-diffusion">Anomalous Diffusion</h1>
<p>Another scenario where the MSD is not a linear function of time is the case of <em>anomolous diffusion</em>. There are two main types of anomolous diffusion: sub-diffusion and super-diffusion. Sub-diffusion is frequently observed when studying crowded systems - a common definition is the tendency of particles not to diffuse due to random trapping. Super-diffusion, on the other hand, occurs when a particle randomly takes very long steps. The mathematics behind anomalous diffusion requires quite a bit of context and in some cases doesn&rsquo;t exist. For this reason, most experimentalists use the fact that $MSD \propto Dt^{\alpha}$ where $\alpha$ is a constant. Thus, the MSD is a power law function of time where sub-diffusion occurs when $\alpha &lt; 1$, brownian motion is the case that $\alpha = 1$ and super-diffusion occurs when $\alpha &gt; 1$.</p>
<pre><code class="language-code" data-lang="code">import matplotlib.pyplot as plt
import numpy as np

def anom_msd(t, alpha):
    return 4*D*t**alpha

alphas = [0.5, 1, 1.3]
t = np.linspace(1, 10, 10)

for alpha in alphas:
    plt.plot(t, anom_msd(t, alpha))

</code></pre><p><img src="mean-squared-displacement-msd-in-different-scenarios_files/mean-squared-displacement-msd-in-different-scenarios_8_0.png" alt="png"></p>
]]></content>
        </item>
        
        <item>
            <title>Network programming in C</title>
            <link>/posts/network-programming-with-c-and-pcap/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/network-programming-with-c-and-pcap/</guid>
            <description>#include &amp;lt;pcap.h&amp;gt;#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;errno.h&amp;gt;#include &amp;lt;sys/socket.h&amp;gt;#include &amp;lt;netinet/in.h&amp;gt;#include &amp;lt;arpa/inet.h&amp;gt;#include &amp;lt;netinet/if_ether.h&amp;gt;#include &amp;lt;net/ethernet.h&amp;gt;#include &amp;lt;netinet/ether.h&amp;gt; /* * workhorse function, we will be modifying this function */ void my_callback(u_char *args,const struct pcap_pkthdr* pkthdr,const u_char* packet) { } int main(int argc,char **argv) { char *dev; char errbuf[PCAP_ERRBUF_SIZE]; pcap_t* descr; struct bpf_program fp; /* hold compiled program */ bpf_u_int32 maskp; /* subnet mask */ bpf_u_int32 netp; /* ip */ u_char* args = NULL; /* Options must be passed in as a string because I am lazy */ if(argc &amp;lt; 2){ fprintf(stdout,&amp;#34;Usage: %s numpackets \&amp;#34;options\&amp;#34;\n&amp;#34;,argv[0]); return 0; } /* grab a device to peak into.</description>
            <content type="html"><![CDATA[<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;pcap.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdio.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdlib.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;errno.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;sys/socket.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;netinet/in.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;arpa/inet.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;netinet/if_ether.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;net/ethernet.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;netinet/ether.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
<span style="color:#75715e">/*
</span><span style="color:#75715e"> * workhorse function, we will be modifying this function
</span><span style="color:#75715e"> */</span>
<span style="color:#66d9ef">void</span> <span style="color:#a6e22e">my_callback</span>(u_char <span style="color:#f92672">*</span>args,<span style="color:#66d9ef">const</span> <span style="color:#66d9ef">struct</span> pcap_pkthdr<span style="color:#f92672">*</span> pkthdr,<span style="color:#66d9ef">const</span> u_char<span style="color:#f92672">*</span> packet)
{
}


<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>(<span style="color:#66d9ef">int</span> argc,<span style="color:#66d9ef">char</span> <span style="color:#f92672">**</span>argv)
{
    <span style="color:#66d9ef">char</span> <span style="color:#f92672">*</span>dev;
    <span style="color:#66d9ef">char</span> errbuf[PCAP_ERRBUF_SIZE];
    pcap_t<span style="color:#f92672">*</span> descr;
    <span style="color:#66d9ef">struct</span> bpf_program fp;      <span style="color:#75715e">/* hold compiled program     */</span>
    bpf_u_int32 maskp;          <span style="color:#75715e">/* subnet mask               */</span>
    bpf_u_int32 netp;           <span style="color:#75715e">/* ip                        */</span>
    u_char<span style="color:#f92672">*</span> args <span style="color:#f92672">=</span> NULL;

    <span style="color:#75715e">/* Options must be passed in as a string because I am lazy */</span>
    <span style="color:#66d9ef">if</span>(argc <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">2</span>){
        fprintf(stdout,<span style="color:#e6db74">&#34;Usage: %s numpackets </span><span style="color:#ae81ff">\&#34;</span><span style="color:#e6db74">options</span><span style="color:#ae81ff">\&#34;\n</span><span style="color:#e6db74">&#34;</span>,argv[<span style="color:#ae81ff">0</span>]);
        <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">0</span>;
    }

    <span style="color:#75715e">/* grab a device to peak into... */</span>
    dev <span style="color:#f92672">=</span> pcap_lookupdev(errbuf);
    <span style="color:#66d9ef">if</span>(dev <span style="color:#f92672">==</span> NULL)
    { printf(<span style="color:#e6db74">&#34;%s</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>,errbuf); exit(<span style="color:#ae81ff">1</span>); }

    <span style="color:#75715e">/* ask pcap for the network address and mask of the device */</span>
    pcap_lookupnet(dev,<span style="color:#f92672">&amp;</span>netp,<span style="color:#f92672">&amp;</span>maskp,errbuf);

    <span style="color:#75715e">/* open device for reading. NOTE: defaulting to
</span><span style="color:#75715e">     * promiscuous mode*/</span>
    descr <span style="color:#f92672">=</span> pcap_open_live(dev,BUFSIZ,<span style="color:#ae81ff">1</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>,errbuf);
    <span style="color:#66d9ef">if</span>(descr <span style="color:#f92672">==</span> NULL)
    { printf(<span style="color:#e6db74">&#34;pcap_open_live(): %s</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>,errbuf); exit(<span style="color:#ae81ff">1</span>); }


    <span style="color:#66d9ef">if</span>(argc <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">2</span>)
    {
        <span style="color:#75715e">/* Lets try and compile the program.. non-optimized */</span>
        <span style="color:#66d9ef">if</span>(pcap_compile(descr,<span style="color:#f92672">&amp;</span>fp,argv[<span style="color:#ae81ff">2</span>],<span style="color:#ae81ff">0</span>,netp) <span style="color:#f92672">==</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
        { fprintf(stderr,<span style="color:#e6db74">&#34;Error calling pcap_compile</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>); exit(<span style="color:#ae81ff">1</span>); }

        <span style="color:#75715e">/* set the compiled program as the filter */</span>
        <span style="color:#66d9ef">if</span>(pcap_setfilter(descr,<span style="color:#f92672">&amp;</span>fp) <span style="color:#f92672">==</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
        { fprintf(stderr,<span style="color:#e6db74">&#34;Error setting filter</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>); exit(<span style="color:#ae81ff">1</span>); }
    }

    <span style="color:#75715e">/* ... and loop */</span>
    pcap_loop(descr,atoi(argv[<span style="color:#ae81ff">1</span>]),my_callback,args);

    fprintf(stdout,<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">finished</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>);
    <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">0</span>;
}
</code></pre></div>]]></content>
        </item>
        
        <item>
            <title>Optical instrumentation</title>
            <link>/posts/optical-instrumentation/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/optical-instrumentation/</guid>
            <description>Optical Instrumentation This post is dedicated to the explanation of the core physical properties of commonly used optical devices such as the camera, microscope, and telescope. Each device is specially designed to achieve a particular purpose and we will show how that is achieved using ray optics.
The Camera Modern DSLR cameras come with a wide selection of lenses of varying focal lengths, each having a specific purpose. Typically, lenses with larger focal lengths are used for imaging objects far way and shorter focal lengths are used for close-ups.</description>
            <content type="html"><![CDATA[<h1 id="optical-instrumentation">Optical Instrumentation</h1>
<p>This post is dedicated to the explanation of the core physical properties of commonly used optical devices such as the camera, microscope, and telescope. Each device is specially designed to achieve a particular purpose and we will show how that is achieved using ray optics.</p>
<h1 id="the-camera">The Camera</h1>
<p>Modern DSLR cameras come with a wide selection of lenses of varying focal lengths, each having a specific purpose. Typically, lenses with larger focal lengths are used for imaging objects far way and shorter focal lengths are used for close-ups. But why does the focal length determine the &ldquo;range&rdquo; of the camera and what happens if you use an inappropriate lens for given imaging scenario? The answer to this question lies in what, in optics, is called <em>depth of field</em>. In simple terms, the depth of field is the range in object space that can be imaged with high fidelity.</p>
<p>Now, if we consider an imaging setup where a lens rests a distance $s_{0}&lsquo;$ from the camera sensor, an object that focuses perfectly at the sensor would lie at</p>
<p>\begin{equation*}
s_{0} = \frac{s_{0}&lsquo;f}{s_{0}'-f}
\end{equation*}</p>
<p>In optics terms, we have found the conjugate point to the sensor in object space. Now, notice that objects nearer to the the lens than $s_{0}$ will focus beyond the sensor and objects outside of $s_{0}$ will focus before the sensor. Indeed, this is why the camera has a depth of field in the first place. To determine the depth of field we need to define a threshold distance from the sensor, such that if an object focuses at a distance exceeding this threshold that object is considered &lsquo;out of focus&rsquo;. Let&rsquo;s call that threshold distance is $x$ which means that objects must focus in the region $s_{0}&rsquo; - x$ to $s_{0}&rsquo; + x$ to be considered in focus. Often times this parameter $x$ is called the *depth of focus* and if you find the conjugate points to $s_{0}&rsquo; - x$ to $s_{0}&rsquo; + x$ in object space, you have the depth of field. We do this by again plugging the variables into the thin-lens equation:</p>
<p>\begin{equation*}
s_{1} = \frac{(s_{0}&rsquo; + x)f}{s_{0}&rsquo; + x - f} = \frac{s_{0}f(f + \frac{fd}{D})}{f^{2} + \frac{fds_{0}}{D}}
\end{equation*}</p>
<p>\begin{equation*}
s_{2} = \frac{(s_{0}&rsquo; - x)f}{s_{0}&rsquo; - x - f} = \frac{s_{0}f(f - \frac{fd}{D})}{f^{2} - \frac{fds_{0}}{D}}
\end{equation*}</p>
<p>where we have named the conjugate points $s_{1}$ and $s_{2}$. Armed with these two equations, we need to use additional properties of the system to find the depth of focus $x$. Consider the angle $\alpha$ between the optical axis and the ray passing through an extreme end of the lens and object point $s_{0}&lsquo;$. If the lens has a diameter $D$ and the parameter $d$ is defined to be the leg of a triangle opposite to $\alpha$ and $x$ is the base of that same triangle, we have that:</p>
<p>\begin{equation*}
\tan(\alpha) = \frac{D}{s_{0}} = \frac{d}{x}
\end{equation*}</p>
<p>so we see that $x = \frac{ds_{0}}{D}$. We have only exchanged one unknown for another but we now have all the relevant parameters involved now. The value of $d$ is often called the *blurring parameter* and is simply a number that can be picked based on the desired image quality. Now, let&rsquo;s subsitute $x$ into the equation above and do some algebra to find the depth of field:</p>
<p>\begin{equation*}
\Delta s = \frac{2f^{3}ds_{0}}{D(f^{4}-f^{2}(d/D)^{2}s_{0}^{2}}
\end{equation*}</p>
<p>Some important practical takeaways from this are that the depth of field increases for decreasing focal length and longer shooting distances. Of course, you can&rsquo;t (or shouldn&rsquo;t) tweak object distances in photography; you change the distance between the lens and sensor $s_{0}&lsquo;$. However, in this form, the equation tells you what the depth of field is when a particular object of interest is in focus. Furthermore, as the ratio $\frac{f}{D}$ which is often called the *relative aperture* or *f-stop* number is increased, the depth of field increases. In turn, smaller lens diameters give you increased depth of field but at the same time the field of view and total intensity is decreased. In summary, the depth of field is determined by two main parameters: the distance to an object of interest and the relative aperture $\frac{f}{D}$.</p>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Photon statistics</title>
            <link>/posts/photon-statistics/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/photon-statistics/</guid>
            <description>import sys import numpy as np import matplotlib import scipy from IPython.display import Image from IPython.core.display import HTML print(&#39;Python version:\n{}\n&#39;.format(sys.version)) print(&#39;Numpy version:\t\t{}&#39;.format(np.__version__)) print(&#39;matplotlib version:\t{}&#39;.format(matplotlib.__version__)) print(&#39;Scipy version:\t\t{}&#39;.format(scipy.__version__)) Python version: 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0] Numpy version:	1.16.2 matplotlib version:	3.0.3 Scipy version:	1.2.1  Quantum nature of light Perhaps the most interesting of the three noise sources mentioned above is shot noise as it is not really noise at all.</description>
            <content type="html"><![CDATA[<pre><code class="language-code" data-lang="code">import sys
import numpy as np
import matplotlib
import scipy
from IPython.display import Image
from IPython.core.display import HTML

print('Python version:\n{}\n'.format(sys.version))
print('Numpy version:\t\t{}'.format(np.__version__))
print('matplotlib version:\t{}'.format(matplotlib.__version__))
print('Scipy version:\t\t{}'.format(scipy.__version__))
</code></pre><pre><code>Python version:
3.7.3 (default, Mar 27 2019, 22:11:17)
[GCC 7.3.0]

Numpy version:		1.16.2
matplotlib version:	3.0.3
Scipy version:		1.2.1
</code></pre>
<h1 id="quantum-nature-of-light">Quantum nature of light</h1>
<p>Perhaps the most interesting of the three noise sources mentioned above is <em>shot noise</em> as it is not really noise at all. Rather, shot noise arises because light is made up of particles and the number of those particles arriving at the detector fluctuates according to a statistical distribution. This ultimately stems from the fact that, in quantum mechanics, we cannot explicitly specify the lifetime of the excited state of an electron and therefore cannot predict the arrival time of a fluorescent photon. Instead, we can only specify the probability distribution over all the possible lifetimes or the probability of observing some number of photons at a given time.</p>
<h1 id="poisson-and-exponential-distributions">Poisson and Exponential Distributions</h1>
<p>Two key probability distributions in photonics are the <strong>Poisson distribution</strong> and the <strong>exponential distribution</strong>. Both of these distrubutions fall under the umbrella of Poisson processes and are just two different ways of the describing the same Poisson process. The Poisson distribution is discrete and provides the probability of observing N events in a fixed time interval. On the other hand, the exponential distribution is continuous and provides the probability of a given time interval between events in a Poisson process. In photonics, the Poisson distribution gives us the probability of observing N photons during the exposure time. The exponential distribution tells us the probability a photon will be emitted as a function of time. Let&rsquo;s look at the Poisson distribution first:</p>
<p>\begin{equation*}
P(n,\mu_{p}) = \frac{\mu_{p}^{n}e^{-\mu_{p}}}{n!}
\end{equation*}</p>
<p>where \( n \) is the number of photons observed and \( \mu_{p} \) is the expected number of photons to be observed. One important feature of the Poisson distribution is that  \( \mu_{p}\) can be written as the product \( \mu_{p} = \lambda t_{exp} \) where \( \lambda \) is the probability of observing a photon per unit time and \(t_{exp} \) is how long you take your measurement. One important feature of the Poisson distribution is that the variance is equal to the mean or \( \mu_{p} = \sigma_{p}^{2} \) where \( \sigma_{p} = \delta n \) , which is characteristic of all Poisson processes. So, we should expect to see higher variability in the number of detected photons for higher intensities and for longer exposure times. Let&rsquo;s take a look at the form of the Poisson distribution for different values of \( \lambda \) keeping \(t_{exp} \) fixed at 1.</p>
<pre><code class="language-code" data-lang="code">import matplotlib.pyplot as plt
import numpy as np
import math
from scipy.special import factorial

def poisson(n, mu_p):
    fact = factorial(n)
    p = (mu_p**n)*math.exp(-mu_p)/fact
    return p

n = np.linspace(0,100,100)
for i in range(5, 85, 10):
    p = poisson(n, i)
    plt.plot(n,p, label=str(i))

plt.xlabel('n', fontsize=12)
plt.ylabel('P(n)', fontsize=12)
plt.legend()
plt.show()
</code></pre><p><img src="photon-statistics_files/photon-statistics_2_0.png" alt="png"></p>
<pre><code class="language-code" data-lang="code">import matplotlib.pyplot as plt
import numpy as np
import math
from scipy.special import factorial

def exponential(t, tau):
    p = np.exp(-t/tau)
    return p

t = np.linspace(0,100,100)
for i in range(5, 85, 10):
    p = exponential(t, i)
    plt.plot(t,p, label=str(i))

plt.xlabel('t', fontsize=12)
plt.ylabel('P(t)', fontsize=12)
plt.legend()
plt.show()
</code></pre><p><img src="photon-statistics_files/photon-statistics_3_0.png" alt="png"></p>
]]></content>
        </item>
        
        <item>
            <title>Python/C API</title>
            <link>/posts/optimizing-python-execution-with-the-pythonc-api/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/optimizing-python-execution-with-the-pythonc-api/</guid>
            <description>The Python/C API This post will cover one method for improving the performance of native Python code. Python is an interpreted language and is therefore not compiled directly. Naturally, the solution is to make use of direclty compiled code rather than interpreted code to achieve performance gains. In the python world, that is commonly achieved by making use of the Python/C API.
The Python/C API provides an interface between the Python interpreter and the C standard libarary as well as custom modules.</description>
            <content type="html"><![CDATA[<h1 id="the-pythonc-api">The Python/C API</h1>
<p>This post will cover one method for improving the performance of native Python code. Python is an interpreted language and is therefore not compiled directly. Naturally, the solution is to make use of direclty compiled code rather than interpreted code to achieve performance gains. In the python world, that is commonly achieved by making use of the Python/C API.</p>
<p>The Python/C API provides an interface between the Python interpreter and the C standard libarary as well as custom modules. The most common use of this API is to write extension C modules than can extend the python interpreter. This is particularly useful when execution speed is critical or an existing module(s) is written in C and needs to be invoked from Python.</p>
<p>We can get started by writing a module in C that provides an interface to the C library function fputs(). The declaration of fputs looks like this:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">int</span> fputs(<span style="color:#66d9ef">const</span> <span style="color:#66d9ef">char</span> <span style="color:#f92672">*</span>str, FILE <span style="color:#f92672">*</span>stream)
</code></pre></div><p>We can see that fputs takes an array of characters as well a pointer to a FILE object that identifies the stream where the string is to be written. Now, let&rsquo;s create a module called magicpants that will serve as a wrapper to the fputs() standard library function. In a file magicpants.c we define the following functions.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;Python.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>

<span style="color:#66d9ef">static</span> PyObject <span style="color:#f92672">*</span><span style="color:#a6e22e">magicpants_fputs</span>(PyObject <span style="color:#f92672">*</span>self, PyObject <span style="color:#f92672">*</span>args) {
    <span style="color:#66d9ef">char</span> <span style="color:#f92672">*</span>str, <span style="color:#f92672">*</span>filename <span style="color:#f92672">=</span> NULL;
    <span style="color:#66d9ef">int</span> bytes_copied <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;

    <span style="color:#75715e">/* Parse arguments */</span>
    <span style="color:#66d9ef">if</span>(<span style="color:#f92672">!</span>PyArg_ParseTuple(args, <span style="color:#e6db74">&#34;ss&#34;</span>, <span style="color:#f92672">&amp;</span>str, <span style="color:#f92672">&amp;</span>filename)) {
        <span style="color:#66d9ef">return</span> NULL;
    }

    FILE <span style="color:#f92672">*</span>fp <span style="color:#f92672">=</span> fopen(filename, <span style="color:#e6db74">&#34;w&#34;</span>);
    bytes_copied <span style="color:#f92672">=</span> fputs(str, fp);
    fclose(fp);

    <span style="color:#66d9ef">return</span> PyLong_FromLong(bytes_copied);
}

<span style="color:#66d9ef">static</span> PyMethodDef MagicpantsMethods[] <span style="color:#f92672">=</span> {
    {<span style="color:#e6db74">&#34;fputs&#34;</span>, magicpants_fputs, METH_VARARGS, <span style="color:#e6db74">&#34;Python interface for fputs C library function&#34;</span>},
    {NULL, NULL, <span style="color:#ae81ff">0</span>, NULL}
};


<span style="color:#66d9ef">static</span> <span style="color:#66d9ef">struct</span> PyModuleDef magicpantsmodule <span style="color:#f92672">=</span> {
    PyModuleDef_HEAD_INIT,
    <span style="color:#e6db74">&#34;magicpants&#34;</span>,
    <span style="color:#e6db74">&#34;Python interface for the fputs C library function&#34;</span>,
    <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>,
    MagicpantsMethods
};

PyMODINIT_FUNC <span style="color:#a6e22e">PyInit_magicpants</span>(<span style="color:#66d9ef">void</span>) {
    <span style="color:#66d9ef">return</span> PyModule_Create(<span style="color:#f92672">&amp;</span>magicpantsmodule);
}

</code></pre></div><p>There are a total of four functions that make up our Python extension module written in C. The first function <em>magicpants_fputs</em> is the function that will be invoked by the user. It calls the fputs() C function and allows the user to write a Python string object to a file. At this point, it is critical to address the declaration</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">static</span> PyObject <span style="color:#f92672">*</span><span style="color:#a6e22e">magicpants_fputs</span>(PyObject <span style="color:#f92672">*</span>self, PyObject <span style="color:#f92672">*</span>args){}
</code></pre></div><p>Notice that the function is set to return the PyObject type. Everything you can touch in Python is a PyObject in C. That includes lists, dictionaries, sockets, files, integers, strings, functions, classes, you name it. If you can touch it in Python, it’s a PyObject in C. In addition, the function takes PyObjects as arguments which are parsed by the following chunk of code:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">/* Parse arguments */</span>
<span style="color:#66d9ef">if</span>(<span style="color:#f92672">!</span>PyArg_ParseTuple(args, <span style="color:#e6db74">&#34;ss&#34;</span>, <span style="color:#f92672">&amp;</span>str, <span style="color:#f92672">&amp;</span>filename)) {
    <span style="color:#66d9ef">return</span> NULL;
}
</code></pre></div><p>After that, fputs() is invoked and we return the number of bytes written with <em>PyLong_FromLong</em> which of course is a Python object.</p>
<p>The second function is called the method mapping table:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">static</span> PyMethodDef MagicpantsMethods[] <span style="color:#f92672">=</span> {
    {<span style="color:#e6db74">&#34;fputs&#34;</span>, magicpants_fputs, METH_VARARGS, <span style="color:#e6db74">&#34;Python interface for fputs C library function&#34;</span>},
    {NULL, NULL, <span style="color:#ae81ff">0</span>, NULL}
};
</code></pre></div><p>It is a structure that contains the following information:</p>
<p><strong>ml_name</strong> − This is the name of the function as the Python interpreter presents when it is used in Python programs.</p>
<p><strong>ml_meth</strong> − This must be the address to a function that has any one of the signatures described in previous section.</p>
<p><strong>ml_flags</strong> − This tells the interpreter which of the three signatures ml_meth is using.</p>
<p><strong>ml_doc</strong> − This is the docstring for the function, which could be NULL if you do not feel like writing one.</p>
<p>The third function defines the module itself:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">static</span> <span style="color:#66d9ef">struct</span> PyModuleDef magicpantsmodule <span style="color:#f92672">=</span> {
    PyModuleDef_HEAD_INIT,
    <span style="color:#e6db74">&#34;magicpants&#34;</span>,
    <span style="color:#e6db74">&#34;Python interface for the fputs C library function&#34;</span>,
    <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>,
    MagicpantsMethods
};
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c">The fourth simply initializes the C extension
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c">PyMODINIT_FUNC <span style="color:#a6e22e">PyInit_magicpants</span>(<span style="color:#66d9ef">void</span>) {
    <span style="color:#66d9ef">return</span> PyModule_Create(<span style="color:#f92672">&amp;</span>magicpantsmodule);
}

</code></pre></div><p>Finally, to call our C functions, we can install our module to our current environment by creating the following setup.py file in the same directory as magicpants.c</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c">from distutils.core import setup, Extension

def main()<span style="color:#f92672">:</span>
    setup(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;magicpants&#34;</span>,
          version<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;1.0.0&#34;</span>,
          description<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Python interface for the fputs C library function&#34;</span>,
          author<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Clayton Seitz&#34;</span>,
          author_email<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;cwseitz@uchicago.edu&#34;</span>,
          ext_modules<span style="color:#f92672">=</span>[Extension(<span style="color:#e6db74">&#34;magicpants&#34;</span>, [<span style="color:#e6db74">&#34;magicpants.c&#34;</span>])])

<span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;__main__&#34;</span><span style="color:#f92672">:</span>
    main()

</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c">python setup.py install
python
<span style="color:#f92672">&gt;&gt;&gt;</span> import magicpants
<span style="color:#f92672">&gt;&gt;&gt;</span> magicpants.fputs(<span style="color:#e6db74">&#34;You now have magical pants&#34;</span>, <span style="color:#e6db74">&#34;magicpants.txt&#34;</span>)
</code></pre></div><p>If you are saving a python script to call this, be sure to name it something other than magicpants.py to avoid any conflicts</p>
]]></content>
        </item>
        
        <item>
            <title>RC frequency response</title>
            <link>/posts/frequency-response-of-an-rc-circuit/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/frequency-response-of-an-rc-circuit/</guid>
            <description>Frequency response of an RC circuit The RC circuit can behave in different ways, depending on how we probe it. To achieve a low-pass configuration, we can probe the voltage across the capacitor. In that configuration, high frequencies are bled to ground through the cap. If we decide to swap the components like the figure the right, we have a high-pass filter, where low frequencies are bled to ground instead.</description>
            <content type="html"><![CDATA[<h1 id="frequency-response-of-an-rc-circuit">Frequency response of an RC circuit</h1>
<p>The RC circuit can behave in different ways, depending on how we probe it. To achieve a low-pass configuration, we can probe the voltage across the capacitor. In that configuration, high frequencies are bled to ground through the cap. If we decide to swap the components like the figure the right, we have a high-pass filter, where low frequencies are bled to ground instead.</p>
<!-- raw HTML omitted -->
<p>Left on its own, the current through the circuit is exactly the same for both scenarios and can be found in another post on LRC analysis:</p>
<p>\begin{align}
I = \frac{V_{in}}{R + \frac{1}{j\omega C}}
\end{align}</p>
<p>We use this expression when examining both the low-pass and high-pass cases even though the wiring appears different. It it is interesting to note that you can wire the two devices in series with the source and whether you measure the voltage over the resistor or the capacitor determines whether it is a high-pass or low-pass circuit, respectively.</p>
<h1 id="rc-low-pass-filter-lpf">RC Low-Pass Filter (LPF)</h1>
<p>Ultimately we want to come up with the <em>transfer function</em> for an RC low-pass circuit. The transfer function $H(\omega)$ is simply the ratio of the output and input voltages as a function of frequency. Determining what that function is requires that we utilize the <em>impedance</em> for the RC device.</p>
<p>\begin{align}
H(\omega) = \frac{V_{out}}{V_{in}}
\end{align}</p>
<p>Using the current from above we can write:</p>
<p>\begin{align}
V_{out} = IX_{C} = \frac{V_{in}}{j\omega C(R + \frac{1}{j\omega C})}
\end{align}</p>
<p>Since the transfer function is only the ratio of output to input</p>
<p>\begin{align}
H(\omega) = \frac{1}{1 + j\omega RC}
\end{align}</p>
<p>Notice that the transfer function is complex. We need to find its magnitude which is commonly referred to as the <em>gain</em> of the circuit.</p>
<p>\begin{align}
|H(\omega)| = \frac{1}{\sqrt{1 + (\omega RC)^{2}}}
\end{align}</p>
<p>Now, we can plot the gain as a function of frequency.</p>
<pre><code class="language-code" data-lang="code">import numpy as np
import matplotlib.pyplot as plt

def rc_transfer(w, R=0.1, C=0.1):
    h = 1/np.sqrt(1+(w*R*C)**2)
    return h

w = np.linspace(0, 10e4, 100)
h = rc_transfer(w, R=22e3, C=2.2e-9)

plt.plot(w, h)
plt.ylabel('Gain')
plt.xlabel('Angular Frequency')
plt.show()
</code></pre><p><img src="frequency-response-of-an-rc-circuit_files/frequency-response-of-an-rc-circuit_1_0.png" alt="png"></p>
<h1 id="rc-high-pass-filter-hpf">RC High-Pass Filter (HPF)</h1>
<p>Again, we want to come up with the transfer function this time for a RC high-pass circuit. The only difference is that the output voltage is measured accross the resistor this time:</p>
<p>\begin{align}
V_{out} = \frac{V_{in}R}{R + \frac{1}{j\omega C}}
\end{align}</p>
<p>\begin{align}
H(\omega) = \frac{R}{R + \frac{1}{j\omega C}} = \frac{j\omega RC}{1 + j\omega RC}
\end{align}</p>
<p>As before, we use the complex form of the transfer function to calculate the gain:</p>
<p>\begin{align}
|H(\omega)| = \frac{\omega RC}{\sqrt{1 + (\omega RC)^{2}}}
\end{align}</p>
<p>Now, we can plot the gain as a function of frequency.</p>
<pre><code class="language-code" data-lang="code">import numpy as np
import matplotlib.pyplot as plt

def rc_transfer(w, R=0.1, C=0.1):
    h = w*R*C/np.sqrt(1+(w*R*C)**2)
    return h

w = np.linspace(0, 10e4, 100)
h = rc_transfer(w, R=22e3, C=2.2e-9)

plt.plot(w, h)
plt.ylabel('Gain')
plt.xlabel('Angular Frequency')
plt.show()
</code></pre><p><img src="frequency-response-of-an-rc-circuit_files/frequency-response-of-an-rc-circuit_3_0.png" alt="png"></p>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Recurrent neural networks</title>
            <link>/posts/recurrent-neural-networks/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/recurrent-neural-networks/</guid>
            <description>Time as Depth Recurrent neural networks differ from typical feedforward networks (like CNNs) in that a single set of parameters $A$ is used repeatedly rather than multiple sets of parameters stacked in space as in a MLP. This particularly useful for applications like language modeling where each word in a sentence comes at a particular time.
Below it can be seen that the same transformation $A$ is used in sequence and that transformation can be itself an MLP or whatever architecture is necessary.</description>
            <content type="html"><![CDATA[<h3 id="time-as-depth">Time as Depth</h3>
<p>Recurrent neural networks differ from typical feedforward networks (like CNNs) in that a single set of parameters $A$ is used repeatedly rather than multiple sets of parameters stacked in space as in a MLP. This particularly useful for applications like language modeling where each word in a sentence comes at a particular time.</p>
<p>Below it can be seen that the same transformation $A$ is used in sequence and that transformation can be itself an MLP or whatever architecture is necessary. At each time-step, $A$ takes in an input $x_{t}$ and the output of the previous transformation $h_{t-1}$ which is referred to as the *hidden state*.</p>
<!-- raw HTML omitted -->
<p>This sort of architecture has proven to be useful in for data that has temporal order like language modeling. Each hidden state $h_{t}$ is a function of all of the previous states which is precisely what you want when building an **autoregressive model**.</p>
<p>\begin{eqnarray}
P_{\Phi}(w_{t}|w_{0},..,w_{t-1}) = \Pi_{t=0}^{T} P_{\Phi}(w_{t}|w_{0}&hellip;w_{t-1})
\end{eqnarray}</p>
<p>Although I haven&rsquo;t defined exactly how we compute $h$, I would like to motivate the use of RNNs by writing down how the realize the equation above in a model we can actually build</p>
<p>\begin{equation*}
\DeclareMathOperator*{\softmax}{softmax}
P_{\Phi}(w_{t}|w_{0},..,w_{t-1}) = \underset{w_{t}}{\softmax} e[w_{t},I]h[t-1,I]
\end{equation*}</p>
<p>where the vector $e[w_{t},I]$  is the *embedding* of the word $w$ and the hidden state of the previous operation $h[t-1,I]$ to predict a probability distribution for the word $w_{t}$. In practice, the transformation $A$ is composed of two-input linear threshold units where the hidden state $h$ at a time $t$ is computed as</p>
<p>\begin{equation*}
h[b,t,j] = \sigma(W^{h,h}[j,I]h[b,t-1, j] + W^{x,h}[j,K]x[b,t,K] - B[j])
\end{equation*}</p>
<p>You can see that it is a sum of linear transformations of $h$ and $x$ each with their own distinct matrices $W$ compared to a threshold.</p>
<h3 id="the-gated-rnn">The Gated RNN</h3>
<p>One very useful feature of RNNs is that they can pass information across time and have a somewhat primitive form of <strong>memory</strong>. The kind of memory an RNN has might be described as a data-dependent data flow. By this we mean that architecture retains the important parts of the data and can filter the rest. One implementation of that if the gated RNN (GRNN).</p>
<p>\begin{equation*}
h[b,t,j] = G[b,t,j]\odot h[b,t-1, j] + (1-G[b,t,j])\odot R[b,t,j]
\end{equation*}</p>
<p>This gate determines whether to remember a value or to replace it in a data-dependent way. $R[b,t,j]$ is the replacement value while $G[b,t,j]$ is the gate which are both computed using a two-input linear threshold unit</p>
<p>\begin{eqnarray}
R[b,t,j] &amp;=&amp; \tanh(W^{h,R}[j,I]h[b,t-1, j] + W^{x,R}[j,K]x[b,t,K] - B^{R}[j]) \<br>
G[b,t,j] &amp;=&amp; \sigma(W^{h,G}[j,I]h[b,t-1, j] + W^{x,G}[j,K]x[b,t,K] - B^{G}[j]) \<br>
\end{eqnarray}</p>
<h3 id="bidirectional-rnns">Bidirectional RNNs</h3>
<p>Another useful architecture especially for machine translation is the bidirectional RNN. In this setup, you compute the hidden states in both directions and concatenate the results to make predictions</p>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Regularization</title>
            <link>/posts/regularization/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/regularization/</guid>
            <description>Error rate vs. Loss I need to make an important distinct before proceeding. The loss function, which we typically take to be the cross-entropy loss, is fundamentally distinct from the error-rate. The error-rate is the fraction of testing, validation, or testing samples that we correctly predict. This is an important metric for assessing the performance of a model and also things such as overfitting.
Regularization A major downfall of deep networks is that they often fail to generalize.</description>
            <content type="html"><![CDATA[<h3 id="error-rate-vs-loss">Error rate vs. Loss</h3>
<p>I need to make an important distinct before proceeding. The loss function, which we typically take to be the cross-entropy loss, is fundamentally distinct from the error-rate. The error-rate is the fraction of testing, validation, or testing samples that we correctly predict. This is an important metric for assessing the performance of a model and also things such as overfitting.</p>
<h3 id="regularization">Regularization</h3>
<p>A major downfall of deep networks is that they often fail to generalize. Models can be trained to perform quite well on a batch of test data but their performance dwindles when using the same model to predict a validation or test sample. This is often called overfitting. We would like a better way to train our models so that we can bring the validation error rate closer to the testing error rate i.e. to prevent overfitting. One way to achieve this is through <em>regularization</em> which defines the search for an optimum model $\Phi^{*}$ such that not all models have equal probability. This is made possible by first making the following observations</p>
<p>\begin{eqnarray*}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\Phi^* &amp; = &amp; \argmax_\Phi;p(\Phi | (x_1,y_1),\ldots,(x_n,y_n)) \<br>
\<br>
&amp; = &amp; \argmax_\Phi;p(\Phi,;(x_1,y_1),\ldots,(x_n,y_n)) \<br>
\<br>
&amp; = &amp; \argmax_\Phi;p(\Phi)P((x_1,y_1),\ldots,(x_n,y_n);|;\Phi) \<br>
\<br>
&amp; = &amp; \argmax_\Phi ; p(\Phi);\prod_i \mathcal{Pop}(x_i)P_\Phi(y_i|x_i) \<br>
\<br>
&amp; = &amp; \argmax_\Phi ; p(\Phi);\prod_i P_\Phi(y_i|x_i)
\end{eqnarray*}</p>
<p>where we refer to $p(\Phi)$ as the model-prior probability and constraints on that probability define the following different forms of regularization.</p>
<h3 id="l1-regularization">L1 Regularization</h3>
<p>L1 regularization gets its name from the fact that we use the L1 norm of the parameter vector $\Phi$ to define our model-prior. For L1 regularization, we define the prior to be Poisson and plug it into the last expression we derived above</p>
<p>\begin{eqnarray*}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
p(\Phi) &amp; \propto &amp; e^{-\lambda ||\Phi||_1} ;;;;;;;;||\Phi||_1 = \sum_i |\Phi_i| \<br>
\<br>
\Phi^* &amp; = &amp; \argmax_\Phi ; ;;p(\Phi) \prod_i P_\Phi(y_i|x_i) \<br>
\<br>
\Phi^* &amp; = &amp; \argmin_\Phi ; ;;\left(\sum_i; -\ln P_\Phi(y_i|x_i)\right) ;+ ; ;\lambda||\Phi||_1 \<br>
\<br>
\Phi^* &amp; = &amp; \argmin_\Phi ; ;;\hat{\cal L}(\Phi) ;+ ; ;\frac{\lambda}{N_{\mathrm{Train}}}||\Phi||_1
\end{eqnarray*}</p>
<p>Notice that we take a negative log and divided by $N$ to transform it into something that looks like an average cross-entropy loss over the training set $\hat{\mathcal{L}}$ with an extra term to give us our new objective which is optimized as follows</p>
<p>\begin{eqnarray*}
\Phi_i &amp; = &amp; \Phi_i - \eta \left(\hat{g}_i + \frac{\lambda}{N_{\mathrm{Train}}};\mathrm{sign}(\Phi_i)\right)
\end{eqnarray*}</p>
<p>For such an objective, $\Phi^*_i = 0 $ when $|g_i| &lt;  \lambda/N_{\mathrm{Train}}$ and $g_i = -(\lambda/N_{\mathrm{Train}}) \mathrm{sign}(\Phi_i)$ otherwise.</p>
<h3 id="l2-regularization">L2 Regularization</h3>
<p>For L2 regularization, which is often called shrinkage, we define the model-prior to be Gaussian and use the L2 norm of the parameter vector. The argument is very similar to above and it can be shown that the objective and update equation under a Gaussian prior is</p>
<p>\begin{eqnarray*}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\Phi^* &amp; = &amp; \argmin_\Phi ; ;;\hat{\cal L}(\Phi) ;+ ; ;\frac{1}{2N\sigma^2} ||\Phi||^2
\end{eqnarray*}</p>
<p>$$\Phi_{i+1} = \Phi_i - \eta\hat{g}_i  - \frac{\eta}{N\sigma^2}\Phi$$</p>
<p>Now we can see why this is called shrinkage</p>
<p>$${ \Phi_{i+1}} = \Phi_i - \eta\hat{g} - \frac{\eta}{N\sigma^2}\Phi_i;;;; = {\Phi_i - \eta\hat{g} - \gamma\Phi_i}$$</p>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Simulating a transformer in LT-spice</title>
            <link>/posts/simulating-a-transformer-in-ltspice/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/simulating-a-transformer-in-ltspice/</guid>
            <description>Simulating a transformer in LTSpice In LTSpice, there is no transformer component per say; however, a transformer is really just a pair of inductors. This means that we can simulate a transformer in spice by creating two or more inductors and specifying their mutual inductance via a spice directive. Before we do that, recall that the voltage ratio of the primary and secondary windings of a transformer is given by:</description>
            <content type="html"><![CDATA[<h1 id="simulating-a-transformer-in-ltspice">Simulating a transformer in LTSpice</h1>
<p>In LTSpice, there is no transformer component per say; however, a transformer is really just a pair of inductors. This means that we can simulate a transformer in spice by creating two or more inductors and specifying their mutual inductance via a spice directive. Before we do that, recall that the voltage ratio of the primary and secondary windings of a transformer is given by:</p>
<p>\begin{align}
\frac{V_{2}}{V_{1}} = \frac{N_{2}}{N_{1}}
\end{align}</p>
<p>where $N_{i}$ is the number of turns of that winding. But in LTSpice, we control the inductance $L$, so we have to use the relation of inductance to the number of turns:</p>
<p>\begin{align}
L = \frac{N^{2}\mu A}{I}
\end{align}</p>
<p>This means that, for a given voltage ratio, we need an inductance ratio that satisfies:</p>
<p>\begin{align}
\frac{V_{2}}{V_{1}} \propto \sqrt{\frac{L_{2}}{L_{1}}}
\end{align}</p>
<p>Let&rsquo;s say we want a step-up transformer with a voltage ratio of 10 i.e. an inductance ratio of 100. We can realize this with a pair of 1mH and 100mH inductors. We will drive the primary winding of this transformer with a $10V$ AC signal with frequency 60Hz through a resistance $R_{2} = 10\Omega$. The secondary also has a series resistance $R_{1} = 100\Omega$. The primary winding of the transformer is really just an RL circuit with total impedance:</p>
<p>\begin{align}
|Z| = \sqrt{R^{2} + (\omega L)^{2}} = 10\Omega
\end{align}</p>
<p>The impedance of the inductor alone is:</p>
<p>\begin{align}
X_{L} = \omega L = 3.75 \Omega
\end{align}</p>
<p>Knowing the current through the primary winding:</p>
<p>\begin{align}
I = \frac{V}{|Z|} = 1A
\end{align}</p>
<p>so the voltage across the inductor is $375mV$ which is roughly what we observe in the plot below. Now, since we have chosen inductances for a voltage ratio of 100, we should have an output voltage of 3.75V, which is the case. The last thing to note is the half-cycle phase shift between the input and output voltages - food for thought.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Solving an LRC circuit</title>
            <link>/posts/solving-an-lrc-circuit/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/solving-an-lrc-circuit/</guid>
            <description>The LRC Circuit Kirchoff&amp;rsquo;s voltage rule written for an LRC circuit driven at angular frequency $\omega$:
\begin{align} L\frac{dI}{dt} + IR + \frac{1}{C}\int I dt = Ve^{i\omega t} \end{align}
which can be differentiated to give:
\begin{align} LI&amp;rsquo;&amp;rsquo; + RI&amp;rsquo; + \frac{1}{C}I = Ve^{i\omega t} \end{align}
which is second-order differential equation with constant coefficient driven by a complex exponential. The general solution for an equation of this form is:
\begin{align} I(t) = We^{i\omega t} \end{align}</description>
            <content type="html"><![CDATA[<h1 id="the-lrc-circuit">The LRC Circuit</h1>
<p>Kirchoff&rsquo;s voltage rule written for an LRC circuit driven at angular frequency $\omega$:</p>
<p>\begin{align}
L\frac{dI}{dt} + IR + \frac{1}{C}\int I dt = Ve^{i\omega t}
\end{align}</p>
<p>which can be differentiated to give:</p>
<p>\begin{align}
LI&rsquo;&rsquo; + RI&rsquo; + \frac{1}{C}I = Ve^{i\omega t}
\end{align}</p>
<p>which is second-order differential equation with constant coefficient driven by a complex exponential. The general solution for an equation of this form is:</p>
<p>\begin{align}
I(t) = We^{i\omega t}
\end{align}</p>
<p>Plugging $I(t)$ in an rearranging gives the following value for W:</p>
<p>\begin{align}
W = \frac{V}{R + j\omega L + \frac{1}{j\omega C}}
\end{align}</p>
<p>The term in the denomenator is a complex number called the <em>impedance</em>. Basically, the impedance is a generalized resistance that applies to capacitors and inductors as well as resistors. We might as well write out the impedance and find its magnitude and phase:</p>
<p>\begin{align}
Z = {R + j(\omega L - \frac{1}{\omega C})}
\end{align}</p>
<p>\begin{align}
|Z|^{2} = R^{2} + (\omega L - \frac{1}{\omega C})^{2}
\end{align}</p>
<p>\begin{align}
\phi = \arctan{\frac{\omega L - \frac{1}{\omega C}}{R}}
\end{align}</p>
<p>Given the magnitude of the impedance, we can find the current through our LRC circuit:</p>
<p>\begin{align}
I = \frac{ Ve^{i\omega t + \phi}}{\sqrt{R^{2} + (\omega L - \frac{1}{\omega C})^{2}}}
\end{align}</p>
<p>notice the phase shift $\phi$. Finally, we can find the voltage drop across each of the components. The resistor is easy, the voltage drop is simply $IR$. However, the inductor and capacitor are a little more complicated. The drop across the inductor can be found via the terms we put in our original differential equation:</p>
<p>\begin{align}
V_{L} = L\frac{dI}{dt} = \frac{ i\omega VLe^{i\omega t + \phi}}{\sqrt{R^{2} + (\omega L - \frac{1}{\omega C})^{2}}}
\end{align}</p>
<p>\begin{align}
V_{C} = \frac{\int Idt}{C} = \frac{ -iVe^{i\omega t + \phi}}{\omega C\sqrt{R^{2} + (\omega L - \frac{1}{\omega C})^{2}}}
\end{align}</p>
<p>Notice the phase of these complex voltages. The voltage across the inductor leads the voltage on the resistor by 90 degrees since it is a purely real resistance. The voltage across the resistor then leads the capacitor by 90 degrees. Each of these voltages oscillates with an angular frequency $\omega$ with a phase shift $\phi$ relative to the source voltage.</p>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Stochastic gradient descent</title>
            <link>/posts/stochastic-gradient-descent/</link>
            <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
            
            <guid>/posts/stochastic-gradient-descent/</guid>
            <description>Stochastic gradient descent (SGD) The purpose of stochastic gradient descent is to update the model parameters of a neural network so as to reduce a loss function. We do that by computing the gradient of that loss function, averaging over a batch, and tweaking model parameters proportional to that average gradient
$$\Delta\Phi = - \eta \hat{g}$$
where $\hat{g}$ is defined to be the average gradient of the loss over the batch.</description>
            <content type="html"><![CDATA[<h3 id="stochastic-gradient-descent-sgd">Stochastic gradient descent (SGD)</h3>
<p>The purpose of stochastic gradient descent is to update the model parameters of a neural network so as to reduce a loss function. We do that by computing the gradient of that loss function, averaging over a batch, and tweaking model parameters proportional to that average gradient</p>
<p>$$\Delta\Phi = - \eta \hat{g}$$</p>
<p>where $\hat{g}$ is defined to be the average gradient of the loss over the batch. We also define $g$ which is the ideal average gradient of the loss for the population distribution</p>
<p>\begin{eqnarray*}
\hat{g} &amp; = &amp; E_{(x,y) \sim \mathrm{Batch}};\nabla_\Phi;\mathrm{\mathcal{L}}(\Phi,x,y) \<br>
\<br>
g &amp; = &amp; E_{(x,y) \sim \mathrm{Pop}};\nabla_\Phi;\mathrm{\mathcal{L}}(\Phi,x,y) \<br>
\end{eqnarray*}</p>
<h3 id="the-thermodynamics-of-sgd">The thermodynamics of SGD</h3>
<p>A common analogy used to explain SGD is that the model $\Phi$ is a particle bouncing around in a higher dimensional space where each parameter defines a dimension. In this model, that space is endowed with a landscape or <em>potential</em> which, in deep learning, is the loss function. SGD is then the process of moving the particle through that higher dimensional space stochastically until it approximately reaches a global minimum of the loss function. This brings us to the parameter $\eta$, called the <strong>learning rate</strong> which, in our particle analogy, determines proportionality of the step size of the particle in our higher dimensional space to the average gradient of the loss.</p>
<h3 id="learning-rate-as-temperature">Learning rate as temperature</h3>
<p>The learning rate can be interpreted as a temperature parameter. For larger learning rates the particle bounces around the higher dimensional space faster. If we run for a long time at a large learning rate we converge to a noisy (hot) stationary distribution with a high loss value. At a lower learning rate we converge to a cooler stationary distribution with a lower loss value.</p>
<p>It is common to train networks by starting hot and then reducing the learning rate so we converge to a lower loss value. This is often called the temperature schedule of the training.</p>
<h3 id="minibatching">Minibatching</h3>
<p>SGD also has to take into account that training is typically done on batches of training points.</p>
<p>\begin{eqnarray*}
\Delta\Phi_{t+1} &amp;=&amp; -\eta \hat{g}_t
\<br>
\hat{g}_t &amp;=&amp; \frac{1}{B} \sum_b \hat{g}_{t,b}
\end{eqnarray*}</p>
<p>where $\hat{g}_{t,b}$ is the average gradient for a particular batch element at time $t$. We use minibatching because the gradients will be smoother after averaging. However, when we use the average gradient over the batch, the step size is proportional to $\frac{1}{B}$, thereby reducing the the effect learning rate or temperature. However, we can make the temperature independent of the batch size with the following observations when $B=1$</p>
<p>\begin{eqnarray*}
\Phi_{t+1} &amp; = &amp;  \Phi_{t} - \eta_0;\nabla_\Phi {\cal L}(t,\Phi_{t}) \<br>
\<br>
\Phi_{t+B} &amp; = &amp;  \Phi_{t} - \sum_{b=0}^{B-1} ;\eta_0;\nabla_\Phi {\cal L}(t+b,\Phi_{t+b-1}) \<br>
\<br>
&amp; \approx &amp; \Phi_t - \eta_0 \sum_b \nabla_\Phi {\cal L}(t+b,\Phi_t) \<br>
\<br>
&amp; = &amp; \Phi_t - B\eta_0; \hat{g}_t
\end{eqnarray*}</p>
<p>so now we compute updates as $\Phi_t - B\eta_0; \hat{g}<em>t$ for some learning rate $\eta</em>{0}$.</p>
<h3 id="momentum">Momentum</h3>
<p>The concept of momentum in deep learning was developed to incorporate more information than just the gradient of the loss for the most recent time step when determining how to adjust model parameters.</p>
<p>\begin{eqnarray*}
{\color{red} v_t} &amp; {\color{red} =} &amp; {\color{red} \mu v_{t-1} + \eta * \hat{g}_t} ;;;\mbox{$\mu$ is typically .9 or .99}\<br>
\<br>
{\color{red} \Phi_{t+1}} &amp; {\color{red} =} &amp; {\color{red} \Phi_t -  v_t} \<br>
\end{eqnarray*}</p>
<p>So you can see that the momentum has the original term proportional to the average gradient, but we have added a drag term $\mu v_{t-1}$ with frictional coefficient $\mu$. For $\mu$ close to 1, we retain almost all information from the previous steps allowing previous steps to *guide* future ones. This raises questions on how the parameters $\mu$ affects the effective learning rate but it turns out that we can make the learning rate independent</p>
<p>\begin{eqnarray*}
\eta = (1-\mu)B\eta_0
\end{eqnarray*}</p>
<p>the temperature will be essentially determined by $\eta_0$ independent of the choice of the momentum parameter $\mu$ or the batch size $B$.</p>
<h3 id="momentum-as-a-running-average">Momentum as a running average</h3>
<p>For $t \geq N$, consider the average of the $N$ most recent values.</p>
<p>\begin{eqnarray*}
\overline{x}_t &amp;=&amp; \frac{1}{N} ;; \sum_{k = 0}^{N-1}; x_{t-k}\<br>
&amp;\approx&amp; (1-\frac{1}{N})\hat{x}_{t-1} + (\frac{1}{N})x_t
\end{eqnarray*}</p>
<p>which is essentially forgetting an old term and bringing in a new one. Another interpretation is that the first term determines how much of the previous running average we remember and the second term is how to incorporate the newest value. But that&rsquo;s exactly we want out of the momentum so we use this to approximate the momentum as a running average</p>
<p>\begin{eqnarray*}
v_t &amp; = &amp; \mu v_{t-1} + {\eta \hat{g}_t}
\<br>
&amp; = &amp; \left(1-\frac{1}{N}\right) v_{t-1} + {\frac{1}{N}(N\eta \hat{g}_t)}
\end{eqnarray*}</p>
<p>which is just a running average of $N\eta \hat{g}_t$.Alternatively, we can consider a direct running average of the gradient.</p>
<p>$$\tilde{g}<em>t = \left(1-\frac{1}{N}\right)\tilde{g}</em>{t-1} + \left(\frac{1}{N}\right) \hat{g}_t$$</p>
<p>The running average of $N\eta\hat{g}$ is the same as $N\eta$ times the running average of $\hat{g}$.  Hence</p>
<p>$$v_t = N \eta \tilde{g}_t$$</p>
<p>So we can simply compute the running average of the gradient multiplied by these constants to obtain the momentum. Updates to the model parameters with momentum are then computed by</p>
<p>\begin{eqnarray*}
\Phi_{t+1} &amp; = &amp; \Phi_t -  N \eta \tilde{g}_t
\end{eqnarray*}</p>
<h3 id="gradient-flow">Gradient flow</h3>
<p>In stochastic gradient descent, we have a model vector $\Phi$ in parameter space that is changing position in a non-deterministic way &ndash; we can only predict a distribution for these changes. In gradient flow, we consider the limit where the learning rate goes to zero or the model changes infinitely slowly, which approximates a continuous change in $\Phi$. In that case, we can actually differentiate $\Phi$.</p>
<p>\begin{eqnarray*}
\frac{d\Phi}{dt} = -g(\Phi)
\end{eqnarray*}</p>
<h3 id="stationary-distributions">Stationary distributions</h3>
<h3 id="langevin-dynamics-of-sgd">Langevin dynamics of SGD</h3>
<p>In statistical mechanics, we often write down continuous time stochastic differential equations to describe the motion of a particle diffusing through a viscous medium at non-zero temperature.</p>
<p>\begin{align}
m\frac{dv}{dt} = \xi (t) - \gamma v(t)
\end{align}</p>
<p>where there is a stochastic parameter defined by a stationary distribution. We can show that langevin dynamics apply when the stationary distribution follows a Boltzmann distribution. However, we will also show that, for stochastic gradient descent, the stationary distribution is not a Boltzmann distribution.</p>
<p>If we consider a learning rate $\eta$ that is constant but still very small so that we can work in continuous time where $\Delta t = N\eta$. Although we still want $N$ and therefore $\Delta t$ to be large so that we are averaging over a large set of updates. Assuming, at the same time, the mean gradient $g(\Phi)$ is approximately constant over the interval $\Delta t = N \eta$ we have</p>
<p>$$\Phi(t + \Delta t)  \approx \Phi(t) -g(\Phi)\Delta t + \eta \sum_{i=1}^N (g(\Phi) - \hat{g}_i)$$</p>
<p>where we have added and subtracted the true gradient $g(\Phi)$. Applying the law of large numbers which says that when we average a big sum, the distribution of the average becomes gaussian, the last term is just a gaussian distribution</p>
<p>\begin{eqnarray*}
\Phi(t + \Delta t) &amp; \approx &amp; \Phi(t) -g(\Phi)\Delta t + \epsilon \sqrt{\Delta t};;;;;; \epsilon \sim {\cal N}(0,{\color{red} \eta}\Sigma)
\end{eqnarray*}</p>
<p>The first is a <strong>gradient flow</strong> component while the second is a stochastic component arising from our estimates of the gradient or a kind of <strong>diffusion flow</strong>.</p>
<pre><code class="language-code" data-lang="code">
</code></pre>]]></content>
        </item>
        
    </channel>
</rss>
