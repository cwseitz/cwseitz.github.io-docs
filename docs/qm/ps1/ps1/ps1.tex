\documentclass[12pt]{article}
\usepackage{amsmath} % AMS Math Package
\usepackage{bm}
\usepackage{amsthm} % Theorem Formatting
\usepackage{amssymb}    % Math symbols such as \mathbb
\usepackage{graphicx} % Allows for eps images
\usepackage[dvips,letterpaper,margin=1in,bottom=0.7in]{geometry}
\usepackage{tensor}
\usepackage{amsmath}
\usepackage{siunitx}
\usepackage{physics}

\newtheorem{p}{Problem}
\usepackage{cancel}
\newtheorem*{lem}{Lemma}
\theoremstyle{definition}
\newtheorem*{dfn}{Definition}
 \newenvironment{s}{%\small%
        \begin{trivlist} \item \textbf{Solution}. }{%
            \hspace*{\fill} $\blacksquare$\end{trivlist}}%


\begin{document}

{\noindent\Huge\bf  \\[0.5\baselineskip] {\fontfamily{cmr}\selectfont  Homework 1}         }\\[2\baselineskip] % Title
{ {\bf \fontfamily{cmr}\selectfont Quantum Mechanics}\\ {\textit{\fontfamily{cmr}\selectfont     August 29th, 2022}}}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    {\large \textsc{Clayton Seitz}
\\[1.4\baselineskip] 

\begin{p}
Problem 1.3 from Sakurai
\end{p}

\begin{s} 

\vspace{0.2in}
Let $A=S_x$ and $B=S_y$. The variance $\langle(\Delta S_x)^{2}\rangle$ in state $\ket{+}_{x}$ must be zero since $\ket{+}_{x}$ is an eigenvector of $S_{x}$  

\begin{align*}
\langle(\Delta S_x)^{2}\rangle &=  \langle S_x^{2}\rangle - \langle S_{x}\rangle^{2}\\
&= \bra{+}_{x} S_x^{2} \ket{+}_{x} - \left(\bra{+}_{x} S_x \ket{+}_{x}\right)^{2}\\
&= \frac{\hbar^{2}}{4} - \frac{\hbar^{2}}{4} = 0
\end{align*}

Therefore, the LHS of the above inequality is zero. The commutator $[S_{x},S_{y}] = i\hbar S_z$ and 

\begin{align*}
\langle S_z \rangle &= \bra{+}_{x} S_z \ket{+}_{x} = 0\\
\end{align*}

Clearly the inequality is satisfied since both sides are zero. Now let $A=S_z$ and $B=S_y$. Since the state is prepared in $\ket{+}_x$, the variance $\langle(\Delta S_z)^{2}\rangle$ is

\begin{align*}
\langle(\Delta S_z)^{2}\rangle &=  \langle S_z^{2}\rangle - \langle S_{z}\rangle^{2}\\
&= \bra{+}_{x} S_z^{2} \ket{+}_{x} - \left(\bra{+}_{x} S_z \ket{+}_{x}\right)^{2}\\
\end{align*}

\begin{align*}
S_{z}\ket{+}_{x} &= \frac{\hbar}{2}\left(\ket{+}\bra{+} - \ket{-}\bra{-}\right)\frac{1}{\sqrt{2}}(\ket{+}+\ket{-})\\
&= \frac{\hbar}{2\sqrt{2}}(\ket{+}-\ket{-}) = \frac{\hbar}{2}\ket{-}_{x}
\end{align*}

and it can be shown by applying it again that $S_{z}^{2}\ket{+}_{x} = \left(\frac{\hbar}{2}\right)^{2}\ket{+}_{x}$. Also, in general, $\bra{+}_{x} S_z \ket{+}_{x} = 0$ which gives us 

\begin{align*}
\langle(\Delta S_z)^{2}\rangle = \left(\frac{\hbar}{2}\right)^{2}
\end{align*}

and the variance must be the same for $S_{y}$

\vspace{0.2in}
The commutator $[S_{z},S_{y}] = -i\hbar S_x$ and $\langle S_x \rangle = \frac{\hbar}{2}$. The inequality then reads 

\begin{align*}
\left(\frac{\hbar}{2}\right)^{2}\left(\frac{\hbar}{2}\right)^{2} &\geq \frac{1}{4}|\langle[S_{z},S_{y}]\rangle|^{2}\\
&= \frac{\hbar^{2}}{4}|\langle S_{x}\rangle|^{2}\\
&= \left(\frac{\hbar}{2}\right)^{2}\left(\frac{\hbar}{2}\right)^{2}
\end{align*}

which is satisfied by the equality.


\end{s}

\begin{p}
Problem 1.4 from Sakurai
\end{p}

\begin{s} 


\begin{align*}
\mathrm{Tr}(X) &= \mathrm{Tr}(a_{0}) + \mathrm{Tr}\left(\sum_k a_k\sigma_k\right)\\
&= 2a_{0}
\end{align*}

\begin{align*}
\mathrm{Tr}(\sigma_{k}X) &= \mathrm{Tr}\left(\sigma_{k}a_{0} + \sigma_{k}\sum_j a_{j}\sigma_j\right)\\
&= \mathrm{Tr}\left(\sigma_{k}a_{0} + \sum_j a_{j}\sigma_{k}\sigma_j\right)\\
&= \mathrm{Tr}\left(\sum_j a_{j}\sigma_{k}\sigma_j\right)
\end{align*}

We can write out the equation $X = a_{0} + \bold{\sigma}\cdot a$ explicitly

\begin{align*}
X =
\begin{pmatrix}
a_0 + a_3 & a_1 - ia_3\\
a_1+ia_2 & a_0 - a_3
\end{pmatrix}
\end{align*}

Thus we have four equations involving $X_{ij}$'s and $a_k$ for $k = (1,2,3)$. We can manipulate those four equations to show that

\begin{align*}
a_0 &= \frac{X_{11}+X_{22}}{2}\\
a_1 &= \frac{X_{12}+X_{21}}{2}\\
a_2 &= i\frac{X_{12}-X_{21}}{2}\\
a_3 &= \frac{X_{11}-X_{22}}{2}
\end{align*}


\end{s}

\begin{p}
Problem 1.5 from Sakurai
\end{p}

\begin{s} 

To simplify the notation, let $\theta = \phi/2$. The matrix exponential can be expanded as a power series

\begin{align*}
\exp(i(\bm{\sigma}\cdot\bm{\hat{n}})\theta) &= I + i\theta(\bm{\sigma}\cdot\bm{\hat{n}}) + \frac{(i\theta(\bm{\sigma}\cdot\bm{\hat{n}}))^{2}}{2!} + \frac{(i\theta(\bm{\sigma}\cdot\bm{\hat{n}}))^{3}}{3!} + ...\\
&= I + i\theta(\bm{\sigma}\cdot\bm{\hat{n}}) - \frac{\theta^{2}}{2!} + \frac{\theta^{3}(\bm{\sigma}\cdot\bm{\hat{n}})}{3!} + ...\\
&= \left(I - \frac{\theta^{2}}{2!}+...\right) + i(\bm{\sigma}\cdot\bm{\hat{n}})\left(\theta - \frac{\theta^{3}}{3!} +...\right)\\
&= \cos\theta I + i(\bm{\sigma}\cdot\bm{\hat{n}})\sin\theta
\end{align*}

and similarly $\exp(-i(\bm{\sigma}\cdot\bm{\hat{n}})\theta) = \cos\theta I - i(\bm{\sigma}\cdot\bm{\hat{n}})\sin\theta$. We can use this result to write $\exp(\pm i(\bm{\sigma}\cdot\bm{\hat{n}})\theta)$ out more explicitly:

\begin{align*}
\exp(i(\bm{\sigma}\cdot\bm{\hat{n}})\theta) &=
\begin{pmatrix}
\cos\theta + in_{z}\sin\theta & (-in_{x}+n_{y})\sin\theta\\
(in_{x}-n_{y})\sin\theta & \cos\theta - in_{z}\sin\theta 
\end{pmatrix}
\end{align*}

\begin{align*}
\exp(-i(\bm{\sigma}\cdot\bm{\hat{n}})\theta) &=
\begin{pmatrix}
\cos\theta - in_{z}\sin\theta & (-in_{x}-n_{y})\sin\theta\\
(-in_{x}+n_{y})\sin\theta & \cos\theta + in_{z}\sin\theta 
\end{pmatrix}
\end{align*}

Now, we were given the transformation

\begin{align*}
\bm{\sigma}\cdot \bm{a}' = \exp\left(\frac{i\bm{\sigma}\cdot\bm{\hat{n}}\phi}{2}\right)\bm{\sigma}\cdot \bm{a} \exp\left(-\frac{i\bm{\sigma}\cdot\bm{\hat{n}}\phi}{2}\right)
\end{align*}

and would like to show that

\begin{align*}
\mathrm{det}(\bm{\sigma}\cdot \bm{a}' ) &= \mathrm{det}(\bm{\sigma}\cdot \bm{a} )
\end{align*}

To see this, notice that the determinant of $\mathrm{det}(\bm{\sigma}\cdot \bm{a}')$ can be written as a product of three determinants. The two determinants coming from terms $\exp(\pm i(\bm{\sigma}\cdot\bm{\hat{n}})\theta)$ will multiply to unity 

\begin{align*}
\mathrm{det}(\exp(i(\bm{\sigma}\cdot\bm{\hat{n}})\theta)) \cdot \mathrm{det}(\exp(- i(\bm{\sigma}\cdot\bm{\hat{n}})\theta)) = 1
\end{align*}

Leaving only $\mathrm{det}(\bm{\sigma}\cdot \bm{a} )$. In the case that $\mathbf{\hat{n}} = \mathbf{\hat{z}}$, the matrices $\exp(\pm i(\bm{\sigma}\cdot\bm{\hat{n}})\theta)$  reduce to 

\begin{align*}
\exp(i(\bm{\sigma}\cdot\bm{\hat{z}})\theta) &=
\begin{pmatrix}
\exp(i\theta) & 0\\
0 & \exp(-i\theta)
\end{pmatrix}
\end{align*}

\begin{align*}
\exp(-i(\bm{\sigma}\cdot\bm{\hat{z}})\theta) &=
\begin{pmatrix}
\exp(-i\theta) & 0\\
0 & \exp(i\theta)
\end{pmatrix}
\end{align*}

Now using these matrices above in some simple matrix operations and substituting back $\phi = 2\theta$, we can show that

\begin{align*}
\exp(i(\bm{\sigma}\cdot\bm{\hat{z}})\theta) \; \sigma_{z}\;\exp(-i(\bm{\sigma}\cdot\bm{\hat{z}})\theta) = \sigma_{z}
\end{align*}

\begin{align*}
\exp(i(\bm{\sigma}\cdot\bm{\hat{z}})\theta) \; \sigma_{x}\;\exp(-i(\bm{\sigma}\cdot\bm{\hat{z}})\theta)
&= \sigma_{x}\cos \phi - \sigma_{y}\sin \phi
\end{align*}

\begin{align*}
\exp(i(\bm{\sigma}\cdot\bm{\hat{z}})\theta) \; \sigma_{y}\;\exp(-i(\bm{\sigma}\cdot\bm{\hat{z}})\theta)
&= \sigma_{x}\sin \phi + \sigma_{y}\cos \phi
\end{align*}

which means that $a_{z}' = a_{z}$, $a_{y}' = a_{x}\sin\phi + a_{y}\cos\phi$, and $a_{x}' = a_{x}\cos\phi - a_{y}\sin\phi$. This is a rotation about $\mathbf{\hat{z}}$ by an angle $\phi$.



\end{s}

\begin{p}
Problem 1.8 from Sakurai
\end{p}

\begin{s} 

\begin{equation*}
A(\ket{i} + \ket{j}) = i\ket{i} + j\ket{j}
\end{equation*}

If we have degenerate eigenvalues i.e., $i=j$ then

\begin{equation*}
A(\ket{i} + \ket{j}) = i(\ket{i} + \ket{j})
\end{equation*}

and $\ket{i} + \ket{j}$ is also an eigenvector of $A$

\end{s}

\begin{p}
Problem 1.10 from Sakurai
\end{p}

\begin{s} 
We will make use of the following outer-product representations of the spin operators
\begin{align*}
S_{x} &= \frac{\hbar}{2}\left(\ket{+}\bra{-} + \ket{-}\bra{+}\right)\\
S_{y} &= \frac{i\hbar}{2}\left(-\ket{+}\bra{-} + \ket{-}\bra{+}\right)\\
S_{z} &= \frac{\hbar}{2}\left(\ket{+}\bra{+} - \ket{-}\bra{-}\right)
\end{align*}

\begin{align*}
[S_{x},S_{y}] &= \frac{i\hbar^{2}}{4}\left(\ket{+}\bra{-} + \ket{-}\bra{+}\right)\left(-\ket{+}\bra{-} + \ket{-}\bra{+}\right)\\
&- \frac{i\hbar^{2}}{4}\left(-\ket{+}\bra{-} + \ket{-}\bra{+}\right)\left(\ket{+}\bra{-} + \ket{-}\bra{+}\right)\\
&= \frac{i\hbar^{2}}{4}\left(\ket{+}\bra{+} - \ket{-}\bra{-}\right) + \frac{i\hbar^{2}}{4}\left(\ket{+}\bra{+} - \ket{-}\bra{-}\right)\\
&= \frac{i\hbar^{2}}{2}\left(\ket{+}\bra{+} - \ket{-}\bra{-}\right)\\
&= i\hbar S_{z}
\end{align*}

Flipping the order of the commutator always flips the sign of the result i.e. $[S_{i},S_{j}] = -[S_{j},S_{i}]$. Thus for $[S_y,S_x]$ we would get $-i\hbar S_{z}$.

\begin{align*}
[S_{y},S_{z}] &= \frac{i\hbar^{2}}{4}\left(-\ket{+}\bra{-} + \ket{-}\bra{+}\right)\left(\ket{+}\bra{+} - \ket{-}\bra{-}\right)\\
&- \frac{i\hbar^{2}}{4}\left(\ket{+}\bra{+} - \ket{-}\bra{-}\right)\left(-\ket{+}\bra{-} + \ket{-}\bra{+}\right)\\
&= \frac{i\hbar^{2}}{4}\left(\ket{+}\bra{-} + \ket{-}\bra{+}\right) -  \frac{i\hbar^{2}}{4}\left(-\ket{+}\bra{-} - \ket{-}\bra{+}\right)\\
&=  \frac{i\hbar^{2}}{2}\left(\ket{+}\bra{-} + \ket{-}\bra{+}\right)\\
&= i\hbar S_{x}
\end{align*}

\begin{align*}
[S_{z},S_{x}] &= \frac{\hbar^{2}}{4}\left(\ket{+}\bra{+} - \ket{-}\bra{-}\right)\left(\ket{+}\bra{-} + \ket{-}\bra{+}\right)\\
&- \frac{\hbar^{2}}{4}\left(\ket{+}\bra{-} + \ket{-}\bra{+}\right)\left(\ket{+}\bra{+} - \ket{-}\bra{-}\right)\\
&= \frac{\hbar^{2}}{4}\left(-\ket{+}\bra{-} + \ket{-}\bra{+}\right) -\frac{\hbar^{2}}{4}\left(\ket{+}\bra{-} - \ket{-}\bra{+}\right)\\
&= -\frac{\hbar^{2}}{2}\left(-\ket{+}\bra{-} + \ket{-}\bra{+}\right)\\
&= i\hbar S_{y}
\end{align*}

When $i=j$ we will always have $\{S_{i},S_{j}\} = 2S_{i}^{2} = \frac{\hbar^{2}}{2}$ since $S_{i}^{2} = I \;\;\forall i$. Therefore, for the anticommutator relations, all we need to prove is that $S_{i}S_{j} = -S_{j}S_{i}$ when $i\neq j$. In fact, this is obvious from the third line of each of the above expressions. The terms are always identical up to a sign flip, which is why we always get a factor of $\frac{\hbar^{2}}{2}$ in the fourth line of each of them. Therefore, it is always true that $S_{i}S_{j} = -S_{j}S_{i}$ for $i\neq j$

\end{s}

\begin{p}
Problem 1.11 from Sakurai
\end{p}

\begin{s} 

We would like to find a representation for the state $\ket{\mathbf{S}\cdot\hat{n}; +}$ in the $S_{z}$ basis. We first write the operator $\mathbf{S}\cdot\hat{n}$ explicitly in this basis

\begin{align*}
\mathbf{S}\cdot\hat{n} &= \sin\beta\cos\alpha \; S_{x} +\sin\beta\sin\alpha\;S_{y} + \cos\beta\; S_{z}\\
&= \frac{\hbar}{2}\begin{pmatrix}
\cos\beta & \sin\beta\exp(-i\alpha)\\
\sin\beta\exp(i\alpha) & -\cos\beta
\end{pmatrix}
\end{align*}

As usual, we find the eigenvalues of this operator by solving the characteristic equation:

\begin{align*}
\mathrm{det}\left(\mathbf{S}\cdot\hat{n} - \lambda I\right) &= \left(\frac{\hbar}{2}\cos\beta - \lambda\right)\left(-\frac{\hbar}{2}\cos\beta - \lambda\right) - \frac{\hbar^{2}}{4}\sin^{2}\beta\\
&= \lambda^{2} - \frac{\hbar^{2}}{4} = 0
\end{align*}

Therefore $\lambda = \pm \frac{\hbar}{2}$ as expected. Let $\psi_{1}$ and $\psi_{2}$ represent the components of the eigenket $\ket{\mathbf{S}\cdot\hat{n}; +}$ of this operator. We then need to solve the following system for the components $\psi_{1}$ and $\psi_{2}$

\begin{align*}
\psi_{1}\cos\beta+\psi_{2}\sin\beta\exp(-i\alpha) &= \psi_{1}\\
\psi_{1}\sin\beta\exp(i\alpha) - \psi_{2}\cos\beta &= \psi_{2}
\end{align*}

We need to validate that $\psi_{1} = \cos\frac{\beta}{2}$ and $\psi_{2} = \sin\frac{\beta}{2}\exp(i\alpha)$ is a solution.


\end{s}




\end{document}