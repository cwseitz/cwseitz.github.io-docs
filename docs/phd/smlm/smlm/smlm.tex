% Latex template: mahmoud.s.fahmy@students.kasralainy.edu.eg
% For more details: https://www.sharelatex.com/learn/Beamer

%\documentclass{beamer}					% Document class
% Aspect ratio
\documentclass[aspectratio=169]{beamer}

\setbeamertemplate{footline}[text line]{%
  \parbox{\linewidth}{\vspace*{-8pt}\hfill\insertshortauthor\hfill\insertpagenumber}}
\setbeamertemplate{navigation symbols}{}

\usepackage[english]{babel}				% Set language
\usepackage[utf8x]{inputenc}			% Set encoding

\mode<presentation>						% Set options
{
  \usetheme{default}					% Set theme
  \usecolortheme{default} 				% Set colors
  \usefonttheme{default}  				% Set font theme
  \setbeamertemplate{caption}[numbered]	% Set caption to be numbered
}

% Uncomment this to have the outline at the beginning of each section highlighted.
%\AtBeginSection[]
%{
%  \begin{frame}{Outline}
%    \tableofcontents[currentsection]
%  \end{frame}
\usepackage{graphicx}					% For including figures
\usepackage{booktabs}					% For table rules
\usepackage{hyperref}	
\usepackage{tikz-network}				% For cross-referencing
\usepackage[absolute,overlay]{textpos}
\usepackage{bm}
\usepackage[font=small,labelfont=bf]{caption}				% For cross-referencing

\title{Some theory for single molecule localization microscopy}	% Presentation title
\author{Clayton W. Seitz}								% Presentation author
\date{\today}									% Today's date	

\begin{document}

\begin{frame}
\begin{table}[]
\begin{tabular}{lcc}
\multicolumn{3}{l}{\textbf{Table 1 - Right Heart Catheterization}}                                                \\ \hline
\textbf{Hemodynamic Parameters} & \multicolumn{2}{c}{\textbf{Pressure (mmHg)}}                                    \\
Right atrium                    & \multicolumn{2}{c}{19}                                                          \\
Right ventricle (mean)          & \multicolumn{2}{c}{46/8 (18)}                                                   \\
Pulmonary artery (mean)         & \multicolumn{2}{c}{45/23 (30)}                                                  \\
Pulmonary capillary wedge       & \multicolumn{2}{c}{14}                                                          \\
                                & \multicolumn{1}{l}{}                    & \multicolumn{1}{l}{}                  \\
                                & \textbf{Thermodilution}                 & \textbf{Fick}                         \\
Cardiac output                  & 5.21 $\mathrm{L/min}$                              & 7.5 $\mathrm{L/min}$                             \\
Cardiac index                   & 2.7 $\mathrm{L/min/m^2}$        & 3.8 $\mathrm{L/min/m^2}$      \\
PVR                             & 256.2 $\mathrm{dyne/sec/cm^{-5}}$ & 178 $\mathrm{dyne/sec/cm^{-5}}$
\end{tabular}
\end{table}
\end{frame}

% Title page
% This page includes the informations defined earlier including title, author/s, affiliation/s and the date
\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Photoswitching as a Markov jump process}
\begin{equation*}
G_{ij} = \mathrm{Pr}\left(X(t+dt)=\omega_{i}, | \;X(t)=\omega_{j}\right)
\end{equation*}

Let the state space for the process $X(t)$ be $\Omega = \{0_{0},0_{1},0_{2},1,2\}$. The generator matrix for such a process reads

\begin{equation*}
G = 
\begin{pmatrix}
\lambda_{00} & \lambda_{0 0_{1}} & 0 & \lambda_{01} & \mu_{0}\\
0 & \lambda_{0_{1}0_{1}} & \lambda_{0_{1}0_{2}} & \lambda_{0_{1}1} & \mu_{1}\\
0 & 0 & \lambda_{0_{2}0_{2}} & \lambda_{0_{2}1} & \mu_{2}\\
\lambda_{10} & 0 & 0 & \lambda_{11} & \mu_{0}\\
0 & 0 & 0 & 0 & 0
\end{pmatrix}
\end{equation*}
\end{frame}

\begin{frame}{Photoswitching as a Markov jump process}
\begin{equation*}
\frac{\partial P(\omega_{i})}{\partial t} = \sum_{j}G_{ji}P(\omega_{j},t) - G_{ij}P(\omega_{i},t)
\end{equation*}
\begin{equation*}
P(\bm{\omega}, t) = \exp(W P(\omega))
\end{equation*}

The matrix $W$ for the 4-state system presented before reads

\begin{equation*}
W = 
\begin{pmatrix}
-\sigma_{0} & \lambda_{0 0_{1}} & 0 & \lambda_{01} & \mu_{0}\\
0 & -\sigma_{0_{1}} & \lambda_{0_{1}0_{2}} & \lambda_{0_{1}1} & \mu_{1}\\
0 & 0 & -\sigma_{0_{2}} & \lambda_{0_{2}1} & \mu_{2}\\
\lambda_{10} & 0 & 0 & -\sigma_{1} & \mu_{0}\\
0 & 0 & 0 & 0 & 0
\end{pmatrix}
\end{equation*}

\end{frame}


\begin{frame}{Integrated isotropic gaussian point spread function}

Let $G(x,y)$ be a normalized isotropic Gaussian density over the pixel array
\begin{equation*}
\mathrm{G}(x,y) = \frac{1}{2\pi\sigma^{2}}e^{-\frac{(x-x_{0})^{2}+(y-y_{0})^{2}}{2\sigma^{2}}}
\end{equation*}
We can integrate this continuous density over pixels. Let $(x_{k},y_{k})$ be the center of $k$
\begin{equation*}
\lambda_{k} = \int_{x_{k}-\frac{1}{2}}^{x_{k}+\frac{1}{2}}G(x)dx \int_{y_{k}-\frac{1}{2}}^{y_{k}+\frac{1}{2}} G(y)dy
\end{equation*}
which gives the probability a photon arrives at pixel $k$ per unit time
\end{frame}

\begin{frame}

Recall that $\mathrm{erf}(z) = \frac{2}{\sqrt{\pi}}\int_{0}^{t}e^{-t^{2}}dt$ 

\begin{align*}
\lambda_{k}(x) &= \frac{1}{2}\left(\mathrm{erf}\left(\frac{x_{k}+\frac{1}{2}-x_{0}}{\sqrt{2}\sigma}\right) -\mathrm{erf}\left(\frac{x_{k}-\frac{1}{2}-x_{0}}{\sqrt{2}\sigma}\right)\right)\\
\lambda_{k}(y) &= \frac{1}{2}\left(\mathrm{erf}\left(\frac{y_{k}+\frac{1}{2}-y_{0}}{\sqrt{2}\sigma}\right) -\mathrm{erf}\left(\frac{y_{k}-\frac{1}{2}-y_{0}}{\sqrt{2}\sigma}\right)\right)
\end{align*}

The shot-noise limited signal is then
\begin{equation*}
\vec{S} = \left[\mathrm{Poisson}(\lambda_{1}), \mathrm{Poisson}(\lambda_{2}), ..., \mathrm{Poisson}(\lambda_{K})\right]
\end{equation*}

\end{frame}


\begin{frame}{Integrated anisotropic gaussian point spread function (astigmatism)}
Let $G(x,y)$ be a normalized anisotropic Gaussian density over the pixel array

\begin{equation}
\mathrm{G}(x,y) = \frac{1}{2\pi\sigma_{x}(z)\sigma_{y}(z)}e^{-\frac{(x-x_{0})^{2}}{2\sigma_{x}(z_{0})^{2}}+\frac{(y-y_{0})^{2}}{2\sigma_{y}(z_{0})^{2}}}
\end{equation}

A fairly simple model for $\sigma_{x}(z_{0})$ and $\sigma_{y}(z_{0})$ is

\begin{align*}
\sigma_{x}(z_{0}) &= \sigma_{0} + \alpha(z_{0}+z_{min})^{2}\\
\sigma_{y}(z_{0}) &= \sigma_{0} + \beta(z_{0}-z_{min})^{2}
\end{align*}

\end{frame}

\begin{frame}

In this case, we only need to make a small adjustment to the isotropic $\lambda_{k}$

\begin{align*}
\lambda_{k}(x) &= \frac{1}{2}\left(\mathrm{erf}\left(\frac{x_{k}+\frac{1}{2}-x_{0}}{\sqrt{2}\sigma_{x}}\right) -\mathrm{erf}\left(\frac{x_{k}-\frac{1}{2}-x_{0}}{\sqrt{2}\sigma_{x}}\right)\right)\\
\lambda_{k}(y) &= \frac{1}{2}\left(\mathrm{erf}\left(\frac{y_{k}+\frac{1}{2}-y_{0}}{\sqrt{2}\sigma_{y}}\right) -\mathrm{erf}\left(\frac{y_{k}-\frac{1}{2}-y_{0}}{\sqrt{2}\sigma_{y}}\right)\right)
\end{align*}

\end{frame}


\begin{frame}{Readout noise}

Due to readout noise, we measure

\begin{equation*}
\vec{H} = \vec{S} + \vec{\xi}
\end{equation*}
The distribution of $H_{k}$ is the convolution:
\begin{align*}
P(H_{k}|\theta) &= P(S_{k})\circledast P(\xi_{k})\\
&= A\sum_{q=0}^{\infty} \frac{1}{q!}e^{-\mu_{k}}\mu_{k}^{q}\frac{1}{\sqrt{2\pi}\sigma_{k}}e^{-\frac{(H_{k}-g_{k}q-o_{k})}{2\sigma_{k}^{2}}}
\end{align*}
where $P(\xi_{k}) = \mathcal{N}(o_{k},\sigma_{k}^{2})$ and $P(S_{k}) = \mathrm{Poisson}(g_{k}\mu_{k})$. In practice, this expression is difficult to work with, so we look for an approximation. Notice that 

\begin{align*}
\xi_{k} - o_{k} + \sigma_{k}^{2} \sim \mathcal{N}(\sigma_{k}^{2},\sigma_{k}^{2}) \approx \mathrm{Poisson}(\sigma_{k}^{2})
\end{align*}

\end{frame}

\begin{frame}{The model log likelihood}
Since $H_{k} = S_{k} + \xi_{k}$, we transform $H_{k}' = H_{k} - o_{k} + \sigma_{k}^{2}$, which is distributed according to 

\begin{align*}
H_{k}' \sim \mathrm{Poisson}(\mu_{k}')\;\;\;\mu_{k}' = g_{k}\mu_{k} + \sigma_{k}^{2}
\end{align*}
Since each Poisson r.v. is independent, the negative log likelihood reads
\begin{align*}
\ell(\vec{H}) &= -\log \prod_{k} \frac{e^{-\left(\mu_{k}'\right)}\left(\mu_{k}'\right)^{n_{k}}}{n_{k}!}\\
&= \sum_{k}  \log n_{k}! + \mu_{k}' - n_{k}\log\left(\mu_{k}'\right)\\
&\approx \sum_{k}  n_{k}\log n_{k} + \mu_{k}' - n_{k}\log\left(\mu_{k}'\right)
\end{align*}

\end{frame}

\begin{frame}{The Cramer-Rao bound}

On the previous slide, we defined the log-likelihood $\ell(\vec{H}|\theta)$. From this we can compute the Fisher information matrix $I(\theta)$

\begin{align*}
\frac{\partial \ell}{\partial \theta_{i}} &= \frac{\partial}{\partial \theta_{i}} \sum_{k}  x_{k}\log x_{k} + \mu_{k}' - x_{k}\log\left(\mu_{k}'\right)\\
&= \sum_{k} \frac{\partial \mu_{k}'}{\partial\theta_{i}} \left(\frac{\mu_{k}'-x_{k}}{\mu_{k}'}\right)
\end{align*}

\begin{equation*}
I_{ij}(\theta) = \underset{\theta}{\mathbb{E}}\left(\sum_{k}\frac{\partial \mu_{k}'}{\partial\theta_{i}}\frac{\partial \mu_{k}'}{\partial\theta_{j}} \left(\frac{\mu_{k}'-x_{k}}{\mu_{k}'}\right)^{2}\right) = \sum_{k}\frac{1}{\mu_{k}'}\frac{\partial \mu_{k}'}{\partial\theta_{i}}\frac{\partial \mu_{k}'}{\partial\theta_{j}}
\end{equation*}

\end{frame}

\begin{frame}{The Cramer-Rao bound}
To compute the bound, it turns out all we need is the Jacobian $J_{\mu}$

\begin{equation*}
J = \left(\frac{\partial \mu_{k}}{\partial x_{0}},\frac{\partial \mu_{k}}{\partial y_{0}},\frac{\partial \mu_{k}}{\partial z_{0}},\frac{\partial \mu_{k}}{\partial \sigma_{x}},\frac{\partial \mu_{k}}{\partial \sigma_{y}},\frac{\partial \mu_{k}}{\partial \sigma_{0}}\right)
\end{equation*}

Let's first compute gradients for spatial coordinates. Define $\beta_{k} = g_{k}\gamma\Delta t N_{0}$ such that $\mu_{k}' = \beta_{k}\lambda_{k}$

\begin{equation*}
J_{x_{0}} = \beta_{k}\lambda_{y}\frac{\partial \lambda_{x}}{\partial x_{0}} \;\; J_{y_{0}} = \beta_{k}\lambda_{x}\frac{\partial \lambda_{y}}{\partial y_{0}}\;\;\; J_{z_{0}}  = \frac{\partial \mu_{k}'}{\partial \sigma_{x}}\frac{\partial \sigma_{x}}{\partial z_{0}} + \frac{\partial \mu_{k}'}{\partial \sigma_{y}}\frac{\partial \sigma_{y}}{\partial z_{0}}
\end{equation*}


\end{frame}

\begin{frame}{The Cramer-Rao bound}

\begin{align*}
J_{x_{0}} &= \beta_{k}\lambda_{y}\frac{\partial \lambda_{x}}{\partial x_{0}} \\
&= \frac{\beta_{k}\lambda_{y}}{2}\frac{\partial}{\partial x_{0}}\left(\mathrm{erf}\left(\frac{x_{k}+\frac{1}{2}-x_{0}}{\sqrt{2}\sigma_{x}}\right) -\mathrm{erf}\left(\frac{x_{k}-\frac{1}{2}-x_{0}}{\sqrt{2}\sigma_{x}}\right)\right)\\
&= \frac{\beta_{k}\lambda_{y}}{\sqrt{2\pi}\sigma_{x}}\left(\mathrm{exp}\left(\frac{(x_{k}-\frac{1}{2}-x_{0})^{2}}{2\sigma_{x}^{2}}\right) -\mathrm{exp}\left(\frac{(x_{k}+\frac{1}{2}-x_{0})^{2}}{2\sigma_{x}^{2}}\right)\right)
\end{align*}

\end{frame}

\begin{frame}{The Cramer-Rao bound}

\begin{align*}
J_{y_{0}} &= \beta_{k}\lambda_{x}\frac{\partial \lambda_{y}}{\partial y_{0}} \\
&= \frac{\beta_{k}\lambda_{x}}{2}\frac{\partial}{\partial y_{0}}\left(\mathrm{erf}\left(\frac{y_{k}+\frac{1}{2}-y_{0}}{\sqrt{2}\sigma_{y}}\right) -\mathrm{erf}\left(\frac{y_{k}-\frac{1}{2}-y_{0}}{\sqrt{2}\sigma_{y}}\right)\right)\\
&= \frac{\beta_{k}\lambda_{x}}{\sqrt{2\pi}\sigma_{y}}\left(\mathrm{exp}\left(\frac{(y_{k}-\frac{1}{2}-y_{0})^{2}}{2\sigma_{y}^{2}}\right) -\mathrm{exp}\left(\frac{(y_{k}+\frac{1}{2}-y_{0})^{2}}{2\sigma_{y}^{2}}\right)\right)
\end{align*}

\end{frame}

\begin{frame}{The Cramer-Rao bound}

\begin{align*}
J_{\sigma_{x}} &= \beta_{k}\lambda_{y}\frac{\partial \lambda_{x}}{\partial \sigma_{x}} \\
&= \frac{\beta_{k}\lambda_{y}}{2}\frac{\partial}{\partial \sigma_{x}}\left(\mathrm{erf}\left(\frac{x_{k}+\frac{1}{2}-x_{0}}{\sqrt{2}\sigma_{x}}\right) -\mathrm{erf}\left(\frac{x_{k}-\frac{1}{2}-x_{0}}{\sqrt{2}\sigma_{x}}\right)\right)\\
&= \frac{\beta_{k}\lambda_{y}}{\sqrt{2\pi}}\left(\frac{\left(x-x_{0}-\frac{1}{2}\right) e^{-\frac{\left(x-x_{0}-\frac{1}{2}\right)^2}{2 \sigma_{x} ^2}}}{\sigma_{x} ^2}-\frac{ \left(x-x_{0}+\frac{1}{2}\right) e^{-\frac{\left(x-x_{0}+\frac{1}{2}\right)^2}{2 \sigma_{x} ^2}}}{\sigma_{x} ^2}\right)
\end{align*}



\end{frame}

\begin{frame}{The Cramer-Rao bound}

\begin{align*}
J_{\sigma_{y}} &= \beta_{k}\lambda_{x}\frac{\partial \lambda_{y}}{\partial \sigma_{y}} \\
&= \frac{\beta_{k}\lambda_{x}}{2}\frac{\partial}{\partial \sigma_{y}}\left(\mathrm{erf}\left(\frac{y_{k}+\frac{1}{2}-y_{0}}{\sqrt{2}\sigma_{y}}\right) -\mathrm{erf}\left(\frac{y_{k}-\frac{1}{2}-y_{0}}{\sqrt{2}\sigma_{y}}\right)\right)\\
&= \frac{\beta_{k}\lambda_{x}}{\sqrt{2\pi}}\left(\frac{\left(y-y_{0}-\frac{1}{2}\right) e^{-\frac{\left(y-y_{0}-\frac{1}{2}\right)^2}{2 \sigma_{y} ^2}}}{\sigma_{y} ^2}-\frac{ \left(y-y_{0}+\frac{1}{2}\right) e^{-\frac{\left(y-y_{0}+\frac{1}{2}\right)^2}{2 \sigma_{y} ^2}}}{\sigma_{y} ^2}\right)
\end{align*}

\end{frame}

\begin{frame}{The Cramer-Rao bound}

\begin{align*}
\sigma_{x}(z_{0}) &= \sigma_{0} + \alpha(z_{0}+z_{min})^{2}\\
\sigma_{y}(z_{0}) &= \sigma_{0} + \beta(z_{0}-z_{min})^{2}
\end{align*}

\begin{equation*}
\frac{\partial\sigma_{x}}{\partial z_{0}} = 2\alpha(z_{0}+z_{min})\;\;\; \frac{\partial\sigma_{y}}{\partial z_{0}} = 2\beta(z_{0}-z_{min})
\end{equation*}


\end{frame}

\begin{frame}{Bayesian localization with stochastic gradient langevin dynamics}
$$dw = - \nabla L(w) dt + \epsilon \sqrt{\eta dt}, \quad \epsilon \sim \mathcal N(0, \sigma^2), \eta \propto dt$$
Our goal is to sample from the stationary distribution of the above SDE. To do that, we will use Stochastic Gradient Langevin Dynamics (SGLD), an algorithm commonly used to sample from the parameter's posterior -- this is unlike MLE, whose goal is to simply minimize the objective $L$, which can be seen as finding the modes of the parameter's posterior
\end{frame}



\end{document}