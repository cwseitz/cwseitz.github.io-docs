
\documentclass[aspectratio=169]{beamer}
\setbeamertemplate{navigation symbols}{}

\usepackage{subfigure,epsfig,amsfonts}
\usepackage{beamerthemeshadow}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{siunitx}


\setbeamertemplate{footline}{}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{headline}
{%
  \leavevmode%
  \begin{beamercolorbox}[wd=.5\paperwidth,ht=2.5ex,dp=1.125ex]{section in head/foot}%
    \hbox to .5\paperwidth{\hfil\insertsectionhead\hfil}
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.5\paperwidth,ht=2.5ex,dp=1.125ex]{subsection in head/foot}%
    \hbox to .5\paperwidth{\hfil\insertsubsectionhead\hfil}
  \end{beamercolorbox}%
}

\begin{document}
\title{Statistical inference and memory in recurrent networks of spiking neurons}  
\author{Clayton Seitz}
\date{\today} 

\maketitle


\begin{frame}{Outline}
\tableofcontents
\end{frame}

\begin{frame}{The Hopfield Network}
\begin{figure}
\includegraphics[width=140mm]{hopfield}
\end{figure}
$>$ 23,000 citations in 2021
\end{frame}

\begin{frame}{The Hopfield Network}
\begin{figure}
\includegraphics[width=140mm]{hopfield-sketch}
\end{figure}
Recurrent artificial neural network which resembles a spin glass\\
The network stores binary patterns $\mathbf{\xi}$ as attractor states\\
Serves as content-addressable or associative memory
\end{frame}

\begin{frame}{The Hopfield Network}

\end{frame}

\begin{frame}{The Boltzmann Machine}

The stochastic counterpart of the Hopfield Network

\end{frame}

\begin{frame}{Review of Bayesian inference}

Recall Bayes theorem from fundamental probability theory

\begin{equation*}
P(A|B) = \frac{P(B|A)P(A)}{P(B)} = \frac{P(B|A)P(A)}{\int P(B|A)P(A)dA}
\end{equation*}
\vfill

$P(A|B)$ is called the posterior, $P(B|A)$ the likelihood, $P(A)$ the prior, and $P(B)$ the evidence
\vfill

\begin{equation*}
P(B) = \int P(B|A)P(A)dA
\end{equation*}

Calculating this integral is often intractable. Monte-Carlo Markov Chain (MCMC) methods and variational methods offer solutions

\end{frame}

\begin{frame}{Monte-Carlo Markov Chain (MCMC) to sample the posterior}

Monte Carlo methods estimate distributions by repeated sampling

\vfill
If calculating $P(B)$ is intractable and we require samples from the posterior $P(A|B )$ we can use MCMC
\vfill
A prominent hypothesis in neuroscience is that neurons use 

\end{frame}



\section{Biologically inspired neural networks}
\begin{frame}{The third generation of neural networks: spiking nets}

\begin{columns}
\column{0.5\linewidth}
\begin{figure}
\includegraphics[height=55mm, width=75mm]{figure-18}
\end{figure}
\column{0.5\linewidth}
\begin{itemize}
\item $\sim$ 16 billion neurons in cortex
\item A neuron receives on the order of $10^{3}$ to $10^{4}$ synaptic inputs
\item Neurons communicate via action potentials in an all-or-nothing fashion
\end{itemize}

\end{columns} 

\end{frame}

\begin{frame}{The third generation of neural networks: spiking nets}

\begin{itemize}
\item Post-synaptic potentials (PSPs) allow pre-synaptic action potentials to change post-synaptic membrane potential
\item PSPs can be positive or negative (excitatory or inhibitory)
\end{itemize}


\end{frame}

\begin{frame}{Integrate and fire (IF) neuron models}

\begin{figure}
\centering
\includegraphics[width=140mm]{figure-19-1}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=140mm]{figure-19-2}
\end{figure}

\begin{equation*}
\tau\dot{V}(t) = g_{\ell}(E - V) + g_{\ell}\cdot \psi(V) + I(t)
\end{equation*}


\end{frame}

\begin{frame}{Monte-Carlo simulation of uncoupled IF neurons}

When $\psi(V) = g_{\ell}\Delta_{T}\exp\left(\frac{V-V_{L}}{\Delta_{T}}\right)$ we have the exponential integrate and fire model

\begin{figure}
\centering
\includegraphics[width=140mm]{figure-3-1}
\end{figure}

Langevin equations have a corresponding Fokker-Planck equation 

\begin{equation*}
\frac{\partial P}{\partial t} = \frac{\sigma^{2}}{\tau}\frac{\partial^{2}P}{\partial V^{2}} + \frac{\partial}{\partial V}\left(\frac{V-E+\psi}{\tau}P\right)
\end{equation*}

\end{frame}


\begin{frame}{Synaptic coupling can induce correlations in spiking activity}

For special synaptic connectivity regimes dynamical variables can remain uncorrelated between neurons

\begin{figure}
\centering
\includegraphics[width=140mm]{figure-12-1}
\end{figure}

Uncorrelated neural activity captures irregular spiking seen \emph{in-vivo}

\end{frame}

\section{Synaptic connectivity as an internal model}
\begin{frame}{Predicting neuron correlations}
The linear response of $r(t)$ allows us to also estimate the matrix of cross-correlations $C_{kj}(\tau)$
from the synaptic connectivity $\mathcal{C}$
\begin{figure}
\centering
\includegraphics[width=110mm]{figure-20}
\end{figure}

This has important implications for brain-inspired machine learning

\end{frame}


\end{document}