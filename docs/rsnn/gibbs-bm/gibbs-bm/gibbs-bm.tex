

\documentclass{article}
\title{Gibbs sampling and the Boltzmann machine}
\author{C.W. Seitz}
\date{\today}

\usepackage{graphicx}
\usepackage{subfigure,epsfig,amsfonts}
\usepackage{amsmath}
\usepackage{siunitx}

\begin{document}
\maketitle

\section{Monte Carlo Methods}

The Monte Carlo method was invented by scientists working on the atomic bomb in the 1940s, who named it for the city in Monaco famed for its casinos and games of chance. Its core idea is to use random samples of parameters or inputs to explore the behavior of a complex system or process. The Monte Carlo methods are basically a class of computational algorithms that rely on repeated random sampling to obtain certain numerical results, and can be used to solve problems that have a probabilistic interpretation

\section{Markov Chains}

A sequence of random variables ($X_{0}, X_{1}, ..., X_{n}$) follows a Markov chain if the probability of arriving at a state $X_{n}$ is dependent only on the previous state $X_{n-1}$. That is, 

\begin{equation}
X_{n} \sim P(X_{n} | X_{0} ,..., X_{n-1}) = P(X_{n}|X_{n-1})
\end{equation} 

We say that the chain is time-homogeneous if the transition-density is independent of time. The probability of arriving at any particular state $X_{n}$ is then given by integrating over all possible paths to that state

\begin{equation}
P(X_{n}) = \int T(X_{n}| X_{n-1})P(X_{n-1})dx
\end{equation} 

which is known as the Chapman-Kolmogorov equation.

\subsection{Ergodicity}

Ergodicity expresses the idea that a stochastic process will eventually visit every state in the phase space $\chi$ that the system moves in. This implies that the statistics of the system can be deduced from a sufficiently long trajectory through $\chi$. Equivalently, a sufficiently large collection of random samples from a process can represent the average statistical properties of the entire process. This simultaneously implies that the statistics of the system's behavior is independent of the initial conditions, since we have not specified \emph{which} trajectory is under consideration. As a side note, the concept of ergodicity was cruicial for thermodynamics as it indicates that all possible microstates are equiprobable over a long period of time. Ergodic Markov chains are useful algorithmic tools in that, regardless of their initial state, they eventually reach a unique stationary distribution $\pi(x)$

\subsection{Detailed balance}

Detailed balance is a useful condition because it allows us to prove the existence of a stationary state. The condition states that the probability flux $X_{i}\rightarrow X_{j}$ exactly balances the flux $X_{j}\rightarrow X_{i}$ so that the net flux is zero. If $\pi$ is such a stationary distribution, then the detailed balance condition reads: 

\begin{equation}
\pi_{i}T(X_{i}|X_{j}) = \pi_{j}T(X_{j}|X_{i})
\end{equation} 

\section{Gibbs Sampling}

An arbitrary joint probability distribution can be expressed as $p(x,y) = p(x|y)p(y) = p(x|y)\int p(x,y)dx$ where $p(y)$ is called the marginal distribution of $y$. Suppose that we would like to sample from the distribution $p(x,y)$, but for some reason, we cannot. 

\section{The Hopfield Network and Boltzmann Machine}


\end{document}