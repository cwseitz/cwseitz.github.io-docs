\relax 
\@writefile{toc}{\contentsline {chapter}{Acknowledgments}{v}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Abstract}{vi}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Models of action potential generation}{1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Integrate-and-Fire Neuron Models}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}The Ornstein-Uhlenbeck Process}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}The Kramers-Moyal Expansion}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Fokker-Planck Solution for Unbounded Diffusion}{5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Splitting each path between $V_{R}$ and $\Theta $ into two segments. Taken from (Plesser 1999)\relax }}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Interspike-interval (ISI) Density}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Monte Carlo Simulations for a Sinusoidal Stimulus}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Self-organization of complex systems}{8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Synaptic plasticity as the basis for memory and learning}{9}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}A spatial model of cortical connectivity}{11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}A statistical framework for spatial connectivity}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}The two-dimensional Gaussian network}{13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces \textbf  {Synapse probabilities for gaussian connectivity} (a) Binomial probabilities for two identical gaussian kernels ($\sigma =1$) separated by a distance $|\Delta \mathbf  {r}_{ij}|$ and the probability of no synapse $\Gamma _{0}$ (left) and the corresponding multinomial probabilities (right). (b) Binomial probabilities for two different gaussian kernels ($\sigma _{1}=1, \sigma _{2}=2$) separated by a distance $|\Delta \mathbf  {r}_{ij}|$ and the probability of no synapse $\Gamma _{0}$ (left) and the corresponding multinomial probabilities (right). \relax }}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Homogeneous Gaussian networks}{15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces \textbf  {The homogeneous Gaussian network}. (A) An example homogeneous network containing $N=100$ neurons. (B) An example neuron extracted from (A) with outgoing synapses labeled in blue and incoming synapses labeled in red. (C,D) The ratio $\langle N_{ij}\rangle /N$ as a function parameters ($\sigma , \Gamma _{0}$) for a sparse network (C) and a network with variable sparsity (D). (E,F) The ratio $\langle N_{ij}\rangle /N$ for fixed $\sigma $ and variable sparsity. (G,H) Binomial probability maps for two nearby neurons expressed as a sum $p_{ij}+p_{ji}$ and product $p_{ij}p_{ji}$\relax }}{16}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces \textbf  {Shared connections in a homogeneous Gaussian network} (A,B,C) The average number of shared incoming or outgoing connections $\langle S_{ij}\rangle /N$ as a function of distance between two neurons $|\Delta r_{ij}|$ for three different values of the reach parameter $\sigma $.\relax }}{17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Excitatory-inhibitory Gaussian networks}{18}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces \textbf  {Average degree in an excitatory-inhibitory network} (A) Schematic illustrating the notation used for excitatory-excitatory, excitatory-inhibitory, inhibitory-excitatory, and inhibitory-inhibitory synapses. (B) An example dense excitatory-inihbitory network ($\Gamma _{0}=0.2$) and $p_{E} = 0.8$. (C) Average number of synapses in the dense network normalized to the target population size as a function of parameters $\sigma _{E}$ and $\sigma _{I}$. (D) An example sparse excitatory-inihbitory network ($\Gamma _{0}=0.8$) and $p_{E} = 0.8$. (E) Average number of synapses in the sparse network normalized to the target population size as a function of parameters $\sigma _{E}$ and $\sigma _{I}$.\relax }}{19}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Appendices}{20}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {A}The Kramers-Moyal expansion}{21}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibdata{ft2,master,refs}
\bibstyle{plain}
\@writefile{toc}{\contentsline {chapter}{References}{23}\protected@file@percent }
