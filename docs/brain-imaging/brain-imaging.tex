\begin{document}

\section{Principles of two-photon microscpy}

Here I summarize two-photon microscopy

\section{Designing an optical system}

I will start by summarizing the basic components that go into a modern two-photon imaging setup and then try to 
address what tradeoffs are present given different design choices. The main devices in any two-photon imaging setup
is, the specimen, laser, objective, scanning module, and detectors. Some modern systems also include adaptive optics (AO) 
which can correct for abberations (more on this later).

\subsection{The objective}

The objective lens is a critical component as it sets the resolution limit of the microscope. Three main parameters
characterize an objective: the magnification, numerical aperture (NA), field-of-view, depth-of-field, and working distance 
which are not independent. The overall intuition is that as we increase the magnification we decrease the field of view
and increase the numerical aperture. Resolution increases with NA, so as low magnification and NA we get lower resolution.

\subsubsection{Magnification}
 
Any lens has an associated magnification factor which is just the ratio of image height to object height and this
in turn determines the field-of-view. 

\subsubsection{Numerical aperture}

An upper limit on the resolution exists in the first place due to diffraction by the objective. 
An ideal point object in the object plane will transform according to the point spread function 
(PSF) of the objective lens. As such, a commonly used definition for the resolution of the objective
is given by 

\begin{equation}
R = \frac{\lambda}{2NA}
\end{equation} 

\begin{equation}
NA = nsin\theta
\end{equation}


where $R$ is the minimum resolvable distance between two points, $n$ is the index of refraction of the imaging medium, 
$\lambda$ is the wavelength of light used to excite the sample, and $\theta$ is one-half of the objective angular aperture. 
The objective will capture a cone of light emitted by the specimen and the half-angle of that cone is $theta$ as measured 
from the optical axis. For a "wider" cone, the NA increases resulting in a smaller $R$ i.e. higher resolution.
Notice that decreasing the working distance of the objective will increase the NA and therefore the resolution.
Also, the NA of the objective generally increases with the magnification.

\subsubsection{Field of View}

Field of View (FOV) is simply the diameter of the circle of light you see when looking into the microscope
and is determined by multiple factors. Utlimately, the size of the FOV is determined by the magnification of the microscope 
as well as the field-number of the objective. To calculate the field of view you simply divide the field number
by the magnification factor. Also note that a camera sensor is typically square so parts of the circular FOV will be 

\subsection{The detector}

The detection strategy used strongly depends on the desired application of the system. A detector should be chosen 
based upon its speed, dynamic range, frequency response, resolution, and signal to noise. Generally, we have to choose
between cameras like CCD, EMCCD, CMOS and APDS or PMTs. 

\subsection{Multi-region imaging}


The following paragraphs summarize the paper: Wide field-of-view, multi-region, two photon imaging of neuronal activity in the mammalian brain published
in Nature Biotechnology in 2016. Imaging multiple regions simulataneously could be very useful when studying projections from primary visual cortex
V1 to other higher visual areas (HVAs). The authors address the limitation of conventional two-photon scanning systems to a FOV of ~1mm^{2}. What 
design choice imposes that limitation? 


\section{Optimal sampling of neural populations}


\end{document}
