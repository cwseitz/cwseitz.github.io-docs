% Source: http://tex.stackexchange.com/a/5374/23931
\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\Hrule}{\rule{\linewidth}{0.3mm}}

\makeatletter% since there's an at-sign (@) in the command name
\renewcommand{\@maketitle}{%
  \parindent=0pt% don't indent paragraphs in the title block
  \centering
  {\Large \bfseries\textsc{\@title}}
  \HRule\par%
  \textit{\@author \hfill \@date}
  \par
}
\makeatother% resets the meaning of the at-sign (@)

\title{Statement of Purpose}
\author{Clayton W. Seitz}
\date{25 July, 2021}

\begin{document}
  \maketitle% prints the title block
\vspace{0.4in}

\indent As an undergraduate student studying physics, informatics, and mathematics at Indiana University, I consistently dreamt of becoming an inventor in the field of computing. In particular, I have always had a great interest in artificial intelligence and harnessing the apparent computational power of complex networks like those observed in the brain. Moving in this direction, I became a tutor in the physics department and joined a laboratory researching the application of tools from deep learning to image processing in biological research. As a student and, after graduation, as a researcher, I developed a computer vision software package for the extraction of quantitative measurements of various biological objects in video data captured via fluorescence microscopy. That experience also served as my first introduction to modern neuroscience, which ultimately led me to a computational neuroscience group at the University of Chicago. During my stay as a graduate student, I excelled in my coursework in deep learning, information theory, theoretical neuroscience, and neurobiology. These courses solidifed my interest in artificial intelligence and expanded my perspectives on its mathematical treatment.\\
\indent I have multiple academic accolades including the Cigital Scholarship from the School of Informatics, Computing and Engineering at Indiana University. I have also presented research on machine learning and computer vision in biological applications during undergraduate education. The transition to the graduate level defined a critical point in my academic career. I was able to use several analytical tools to solve problems in physics and engineering; however, it was not until I began to work full-time at Indiana that I gained perspective on the directions of the field. By the end of my stay there, neural networks became my primary research interest, which ultimately guided my transition to graduate school at the University of Chicago. There, my primary research focus was on biologically-plausible learning algorithms for networks of spiking neurons i.e. synaptic plasticity rules. In particular, I researched the orchestration of learning rules during memory formation while also considering the implementation of biologically-realistic neural networks in dedicated hardware. Currently, I am pursuing an opportunity where I can focus on research questions relevant to neuromorphic engineering and artificial intelligence.\\
\indent Perhaps the most obvious reason that developing biologically-realistic software and hardware architectures for artificial intelligence is that the human brain is an astonishingly efficient signal processor. Indeed, it can perform highly complex functions such as visual object recognition, classification, and language processing at very low power consumption. At the same time, hardware engineers developing the next wave of computer chips have observed a plateau in Moore's law due to hardware constraints. Neuromorphic computing leverages the putative architecture of cortical circuits which are particularly efficient since all computations are performed in-memory. Importantly, the connections in a cortical circuit are also dynamic, allowing for unsupervised online learning of new signals. As a graduate student, I hope to address some of engineering challenges related to neuromorphic computing such as the development of learning algorithms for neuromorphic chips as well as theoretical perspectives on the space of computations that can be achieved with spiking neurons. I believe that Electrical and Computer Engineering program at Purdue University is the optimal venue to perform this research. The Center for Brain-Inspired Computing and its distinguished affiliates such as Kaushik Roy and Anand Raghunathan would provide the necessary resources to perform cutting edge research in this domain.\\



\end{document}