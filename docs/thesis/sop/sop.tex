% Source: http://tex.stackexchange.com/a/5374/23931
\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\Hrule}{\rule{\linewidth}{0.3mm}}

\makeatletter% since there's an at-sign (@) in the command name
\renewcommand{\@maketitle}{%
  \parindent=0pt% don't indent paragraphs in the title block
  \centering
  {\Large \bfseries\textsc{\@title}}
  \HRule\par%
  \textit{\@author \hfill \@date}
  \par
}
\makeatother% resets the meaning of the at-sign (@)

\title{Statement of Purpose}
\author{Clayton W. Seitz}
\date{25 July, 2021}

\begin{document}
  \maketitle% prints the title block
\vspace{0.4in}

\indent Since I was an undergraduate student studying physics, informatics, and mathematics at Indiana University, I have dreamt of becoming an innovator in the fields of computer science and engineering. Throughout this time, my interest has been rooted in artificial intelligence and harnessing the computational power of complex networks like those observed in the brain. I began my academic journey in the computational sciences, focusing on programming paradigms, algorithms, and data structures. Later, I developed foundations in physics, became a tutor, and joined a research laboratory in the physics department. My role as a researcher was the application of tools from computer vision and machine learning to image processing for fluorescence microscopy. I played a major role in the development a computer vision software package for the extraction of quantitative measurements of various biological objects in video data. By the end of my undergraduate career, I had received the Hudson and Holland Scholarship, Cigital Scholarship from the Luddy School of Informatics, Computing and Engineering, Founders Scholar award, and presented research on machine learning and computer vision in biological applications on several occasions.\\
\\
\indent  The transition from the undergraduate to the graduate level defined a critical point in my academic career. As an undergraduate, I was able to use several analytical tools to solve problems in physics and engineering; however, it was not until I began to work full-time at Indiana University that I gained a more well-rounded perspective on computational research. By the end of my stay there, neural networks became my primary research interest, which ultimately guided my transition to graduate school at the University of Chicago. As a graduate student at UChicago, I excelled in coursework in deep learning, information theory, theoretical neuroscience, and neurobiology. These courses solidifed my interest in artificial intelligence and expanded my perspectives on its mathematical treatment. There my primary research focus was on biologically-plausible learning algorithms for networks of spiking neurons i.e. synaptic plasticity rules. In particular, I researched the orchestration of learning rules during memory formation while also considering the implementation of biologically-realistic neural networks in dedicated hardware. Currently, I am pursuing an opportunity where I can focus on research questions relevant to neuromorphic engineering and artificial intelligence.\\
\\
\indent Perhaps the most readily apparent reason that developing biologically-realistic software and hardware architectures for artificial intelligence is that the human brain is an astonishingly efficient signal processor. Indeed, the brain performs highly complex functions such as visual object recognition, classification, and language processing at very low power consumption. In principle, neuromorphic algorithms implemented in dedicated hardware can parallel the computational efficiency of cortical circuits by performing computations in-memory with model neurons and synapses. In the past I have been exposed to biophysical and attractor models of spiking neural networks and in the future I hope to utilize this training to model the dynamics of spiking neurons with the goal of  understanding the input-output relationship of a network based on its synaptic connectivity. I also hope to develop my understanding of the ability of a network to compress inputs via learning and store information reliably without `catastrophic forgetting'. Significant efforts have been made in the biophysical and neuroscience communities towards writing down differential equations that describe learning dynamics in cortical neurons but very few have implemented these rather sophisticated algorithms in hardware. I believe that Electrical and Computer Engineering program at Purdue University is the optimal venue to perform this research and implementation. The Center for Brain-Inspired Computing and its distinguished affiliates such as Kaushik Roy and Anand Raghunathan would provide the necessary resources to do so. Ultimately, I believe that my background in physics and computing make me a good fit for this program and that my strong research background and inspiration from neuroscience present a unique combination for innovative research.\\



\end{document}