

\documentclass{article}
\title{Bounding parameter uncertainty in single molecule localization}
\author{C.W. Seitz}
\date{\today}

\usepackage{graphicx}
\usepackage{subfigure,epsfig,amsfonts}
\usepackage{amsmath}
\usepackage{siunitx}
\usepackage{float}
\usepackage{bm}
\usepackage{natbib}
\bibliographystyle{unsrtnat}

\begin{document}
\maketitle

We will adopt the Gaussian PSF approximation (image function):

\begin{equation*}
q(x,y) = \frac{1}{2\pi\sigma^{2}}\exp\left(-\frac{(x-x_{0})^{2}+(y-y_{0})^{2}}{2\sigma^{2}}\right)
\end{equation*}

and define the number of photoelectrons at a pixel $k$ as a sum of three random variables

\begin{equation*}
H_{\theta,k} = S_{\theta,k} + B_{\theta,k} + W_{\theta,k}
\end{equation*}

where $S_{\theta,k}$ and $B_{\theta,k}$ are Poisson processes for signal and background while $W_{\theta,k}$ represents Gaussian noise of a CMOS array. Unless otherwise specified we will assume that $W_{k} \sim \mathcal{N}(m_{k},\sigma_{w,k}^{2})$. The mean of the variable $H_{\theta,k}$ is found by measuring $m_{k}$ and evaluating the following three equations

\begin{equation*}
\langle H_{\theta,k} \rangle = \mu_{\theta,k} + \beta_{k} + m_{k}
\end{equation*}

\begin{equation*}
\mu_{\theta,k} = \int_{t_{0}}^{t} \Lambda(\tau) \int_{C_{k}} q(x,y)dxdyd\tau
\end{equation*}

\begin{equation*}
\beta_{\theta,k} = \int_{t_{0}}^{t} \Lambda(\tau) \int_{C_{k}} b(x,y)dxdyd\tau
\end{equation*}

where $b(x,y)$ is a spatially dependent background function. $\Lambda(\tau)$ is the emission rate as a function of time which could, for example, be exponential decay for photobleaching. We now need to show the complete form of $P(H_{k})$ which requires that we first know $P(S_{k})$. Let's say that we have a fluorophore that emits photons according to a Poisson process with rate $\eta$ which therefore has mean $\mu = \eta\Delta t$ where $\Delta t$ is the exposure time. If that photon were to arrive at a particular CMOS pixel $k$, it can be detected with a probability equal to the quantum efficiency $0 \leq \gamma \leq 1$ of the detector. Given that the photon indeed arrives at pixel $k$, $S_{k}$ is then a product of two random variables

\begin{equation*}
M_{k} \sim \mathrm{Poisson}(\eta)\hspace{0.2in}N_{k} \sim \mathrm{Bern}(\gamma, 1-\gamma)
\end{equation*}

According to the first distribution, the probability $M_{k}$ photons will be detected in the exposure time $\Delta t$ is Poisson, which has the form 

\begin{equation*}
\mathrm{Poisson}(n; \eta) = \frac{\exp\left({-\eta\Delta t}\right)(\eta\Delta t)^{n}}{n!}
\end{equation*}

There are two variables: whether or not a photon was emitted and whether or not a photon can be detected. The number of detected photons is $S_{k} = M_{k}N_{k}$.

\begin{align*}
P(S_{k},M_{k},N_{k}) &= P(S_{k}|M_{k}=m_{k},N_{k}=n_{k})P(M_{k}|N_{k}=n_{k})P(N_{k}=n_{k})
\end{align*}

Note that $m_{k},s_{k} \in \Omega$ where $\Omega = \{z \in \mathbb{Z}: z \geq 0\}$ We can marginalize this distribution over $M_{k}$ and $N_{k}$

\begin{align*}
P(S_{k})  &= \sum_{m_{k}}\sum_{n_{k}} P(S_{k}|M_{k}=m_{k},N_{k}=n_{k})P(M_{k}|N_{k}n_{k})P(N_{k}=n_{k})
\end{align*}

Expanding this expression out over the support of $n_{k}$ gives

\begin{align*}
P(S_{k}) &= \sum_{m_{k}}P(S_{k}|M_{k}=m_{k},N_{k}=0)P(M_{k}|N_{k}=0)P(N_{k}=0)\\
&+ P(S_{k}|M_{k}=m_{k},N_{k}=1)P(M_{k}|N_{k}=1)P(N_{k}=1)
\end{align*}

At this point it is quite clear that we have

\begin{align*}
P(S_{k}) &= \sum_{m_{k}}\gamma\delta(s_{k}-m_{k})P(M_{k}=m_{k})+(1-\gamma)\delta(s_{k}) P(M_{k}=m_{k})\\
&= \gamma P(M_{k}) + \delta(s_{k})(1-\gamma)
\end{align*}

This result tells us that we reduce probability mass by a factor of $\gamma$ and inflate the value at zero by adding $1-\gamma$. Next, we can can use this to find the distribution over the corrupted signal $P(H_{k})$

To find $P(H_{k})$, we first evaluate the joint density $P(S_{k},H_{k})$
\vspace{0.1in}
\begin{align*}
P(S_{k},H_{k}) &= P(H_{k}|S_{k}=s)P(S_{k}=s)\\
&= \frac{1}{Z}\exp\left(-\frac{(H_{k}-g_{k}s-\mu_{k})^{2}}{\sigma_{k}^{2}}\right)\frac{\exp\left({-\Lambda_{k}}\right)\Lambda_{k}^{s}}{s!}
\end{align*}
\vspace{0.1in}

Marginalizing over $S_{k}$ gives the desired distribution over $H_{n}$

\begin{equation*}
P(H_{k}) = \frac{1}{Z}\sum_{s=0}^{\infty}\frac{\exp\left({-\Lambda_{k}}\right)\Lambda_{k}^{s}}{s!}\exp\left(-\frac{(H_{k}-g_{k}s-\mu_{k})^{2}}{\sigma_{k}^{2}}\right)
\end{equation*}



Consider the general prescripton of maxmimum likelihood parameter estimation:

\begin{align*}
\mathcal{E}_{\mathrm{MLE}}: \theta^{*} = \underset{\theta}{\mathrm{argmax}}\; \ell(\mathcal{D}|\theta)
\end{align*}

where $\ell = \log\mathcal{L}$ is the log-likelihood function\\
\vspace{0.1in}
Question: can we derive a theoretical lower bound on our uncertainty in $\theta^{*}$ for an arbitrary estimator $\mathcal{E}$?\\
\vspace{0.1in}
Start by defining the \emph{score} of $\ell$ with respect to $\theta$ as

\begin{align*}
\mathcal{S} = \underset{{x\sim p}}{\mathbb{E}}\left[\frac{\partial}{\partial\theta} \ell(x|\theta)\right]
\end{align*}

Since $x$ is a continuous random variable, we have to consider the average score


The Fisher Information $I(\theta)$ is defined as the variance of the score

\begin{align*}
I(\theta) = \underset{{x\sim p}}{\mathbb{E}}\left[\frac{\partial}{\partial\theta} \left(\ell(x|\theta)\right)\right]^{2} = \underset{{x\sim p}}{\mathbb{E}}\left[\frac{\partial^{2}}{\partial\theta^{2}} \left(\ell(x|\theta)\right)\right]
\end{align*}

for $x\in\mathcal{D}$. The variance takes this from because it can be shown that $\mathcal{S}=0$\\
\vspace{0.1in}
Intuitively, if the likelihood is insensitive changes in $\theta$, then $\mathcal{D}$ does not provide very much information about $\theta$\\

When there are many parameters, the Fisher Information (second moment of the score) is a covariance matrix

\begin{align*}
I_{ij}(\theta) = \underset{{x\sim p}}{\mathbb{E}}\left[\frac{\partial}{\partial\theta_{i}} \left(\ell(x|\theta)\right)\frac{\partial}{\partial\theta_{j}} \left(\ell(x|\theta)\right)\right]
\end{align*}




We have shown that the model for the number of photoelectrons at a pixel is

\begin{equation*}
P(H_{k}) = \frac{1}{Z}\sum_{s=0}^{\infty}\frac{\exp\left({-\Lambda_{k}}\right)\Lambda_{k}^{s}}{s!}\exp\left(-\frac{(H_{k}-g_{k}s-\nu_{k})^{2}}{\sigma_{k}^{2}}\right)
\end{equation*}

Notice that $\nu_{k}$ is dependent on $\int q(x,y)dxdy$ and therefore the PSF parameters $\theta = (\mu_{x},\mu_{y},\sigma)$. These can be plugged into the following Fisher information matrix

\begin{align*}
I_{ij}(\theta) &= \underset{{H\sim P}}{\mathbb{E}}\left[\frac{\partial}{\partial\theta_{i}} \left(\log \prod_{k} P(H_{k})\right)\frac{\partial}{\partial\theta_{j}} \left(\log \prod_{k} P(H_{k})\right)\right]\\
&= \underset{{H\sim P}}{\mathbb{E}}\sum_{k}\left[\frac{\partial}{\partial\theta_{i}} \log P(H_{k})\frac{\partial}{\partial\theta_{j}} \log P(H_{k})\right]
\end{align*}

We need to then calculate the derivatives with respect to the parameters $\theta_{i}$. 

Computing the mean value at a pixel involves computing an integral $ \int_{C_{k}} q(x,y)dxdy$. This integral is difficult to compute, but a 2D image is really just a 2D histogram. So if we can find the PSF $q(x,y)$ from the objective lens, we can use Monte Carlo integration (sample from the normalized PSF) and multiply by the emission rate $\nu$ to compute the mean of the Poisson process at a pixel $k$


\end{document}